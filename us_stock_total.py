import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from prophet import Prophet
from statsmodels.tsa.arima.model import ARIMA
from youtube_transcript_api import YouTubeTranscriptApi
from textblob import TextBlob
import requests
from datetime import datetime, timedelta
import time
import warnings
import re
from typing import Dict, List, Tuple
import json
import openai
from bs4 import BeautifulSoup
from urllib.parse import quote
from pytrends.request import TrendReq
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta

warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì„œí•™ê°œë¯¸ì˜ íˆ¬ì íƒêµ¬ìƒí™œ ğŸœğŸ”",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 0.25rem solid #1f77b4;
    }
    .buy-signal {
        background-color: #d4edda;
        color: #155724;
        padding: 0.75rem;
        border-radius: 0.25rem;
        border: 1px solid #c3e6cb;
    }
    .sell-signal {
        background-color: #f8d7da;
        color: #721c24;
        padding: 0.75rem;
        border-radius: 0.25rem;
        border: 1px solid #f5c6cb;
    }
    .hold-signal {
        background-color: #fff3cd;
        color: #856404;
        padding: 0.75rem;
        border-radius: 0.25rem;
        border: 1px solid #ffeaa7;
    }
</style>
""", unsafe_allow_html=True)


class SectorTreemapAnalyzer:
    """ì„¹í„°ë³„ íŠ¸ë¦¬ë§µ ë¶„ì„ í´ë˜ìŠ¤"""
    
    @staticmethod
    @st.cache_data(ttl=3600)  # 1ì‹œê°„ ìºì‹±
    def get_sp500_stocks() -> pd.DataFrame:
        """S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # Wikipediaì—ì„œ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
            tables = pd.read_html(url)
            sp500_df = tables[0]
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ì •ë¦¬
            sp500_df = sp500_df[['Symbol', 'Security', 'GICS Sector']]
            sp500_df.columns = ['symbol', 'company_name', 'sector']
            
            # ì„¹í„°ëª… ì •ë¦¬ (ê³µë°± ì œê±° ë° ê°„ì†Œí™”)
            sector_mapping = {
                'Information Technology': 'Technology',
                'Health Care': 'Healthcare', 
                'Financials': 'Financial',
                'Consumer Discretionary': 'Consumer_Discretionary',
                'Communication Services': 'Communication',
                'Industrials': 'Industrial',
                'Consumer Staples': 'Consumer_Staples',
                'Energy': 'Energy',
                'Materials': 'Materials',
                'Real Estate': 'Real_Estate',
                'Utilities': 'Utilities'
            }
            
            sp500_df['sector'] = sp500_df['sector'].map(sector_mapping).fillna(sp500_df['sector'])
            
            return sp500_df
            
        except Exception as e:
            st.error(f"S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            # ë°±ì—…ìš© ì£¼ìš” ì¢…ëª©ë“¤
            return pd.DataFrame({
                'symbol': ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'BRK-B', 'UNH', 'JNJ'],
                'company_name': ['Apple Inc.', 'Microsoft Corp.', 'Alphabet Inc.', 'Amazon.com Inc.', 'NVIDIA Corp.', 
                               'Meta Platforms Inc.', 'Tesla Inc.', 'Berkshire Hathaway Inc.', 'UnitedHealth Group Inc.', 'Johnson & Johnson'],
                'sector': ['Technology', 'Technology', 'Technology', 'Technology', 'Technology', 
                          'Technology', 'Technology', 'Financial', 'Healthcare', 'Healthcare']
            })
    
    @staticmethod
    @st.cache_data(ttl=1800)  # 30ë¶„ ìºì‹±
    def get_sector_market_data(sp500_df: pd.DataFrame, sector_name: str, top_n: int = 20) -> pd.DataFrame:
        """íŠ¹ì • ì„¹í„°ì˜ ì‹œê°€ì´ì•¡ ìƒìœ„ Nê°œ ì¢…ëª© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            # í•´ë‹¹ ì„¹í„° ì¢…ëª©ë“¤ í•„í„°ë§
            sector_stocks = sp500_df[sp500_df['sector'] == sector_name]['symbol'].tolist()
            
            if not sector_stocks:
                st.warning(f"{sector_name} ì„¹í„°ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            sector_data = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, symbol in enumerate(sector_stocks):
                try:
                    status_text.text(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘: {symbol} ({i+1}/{len(sector_stocks)})")
                    progress_bar.progress((i + 1) / len(sector_stocks))
                    
                    ticker = yf.Ticker(symbol)
                    info = ticker.info
                    hist = ticker.history(period="5d")  # ìµœê·¼ 5ì¼ ë°ì´í„°
                    
                    if hist.empty or len(hist) < 2:
                        continue
                    
                    # ì‹œê°€ì´ì•¡ì´ ì—†ê±°ë‚˜ 0ì¸ ê²½ìš° ìŠ¤í‚µ
                    market_cap = info.get('marketCap', 0)
                    if not market_cap or market_cap <= 0:
                        continue
                    
                    # ê°€ê²© ì •ë³´
                    current_price = hist['Close'].iloc[-1]
                    prev_price = hist['Close'].iloc[-2]
                    change_pct = ((current_price - prev_price) / prev_price) * 100
                    
                    # íšŒì‚¬ëª… ì •ë¦¬
                    company_name = info.get('shortName', info.get('longName', symbol))
                    if len(company_name) > 30:
                        company_name = company_name[:27] + "..."
                    
                    sector_data.append({
                        'symbol': symbol,
                        'company_name': company_name,
                        'sector': sector_name,
                        'market_cap': market_cap,
                        'market_cap_b': market_cap / 1e9,  # 10ì–µ ë‹¬ëŸ¬ ë‹¨ìœ„
                        'current_price': current_price,
                        'prev_price': prev_price,
                        'change_pct': change_pct,
                        'volume': hist['Volume'].iloc[-1] if 'Volume' in hist.columns else 0,
                        'pe_ratio': info.get('trailingPE', 0),
                        'dividend_yield': info.get('dividendYield', 0) or 0
                    })
                    
                    # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ì§€ì—°
                    time.sleep(0.1)
                    
                except Exception as e:
                    continue
            
            progress_bar.empty()
            status_text.empty()
            
            if not sector_data:
                st.warning(f"{sector_name} ì„¹í„°ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ê³  ì‹œê°€ì´ì•¡ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            df = pd.DataFrame(sector_data)
            df = df.sort_values('market_cap', ascending=False).head(top_n)
            
            return df
            
        except Exception as e:
            st.error(f"ì„¹í„° ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return pd.DataFrame()
    
    @staticmethod
    def create_sector_treemap(sector_data: pd.DataFrame, sector_name: str) -> go.Figure:
        """ì„¹í„°ë³„ íŠ¸ë¦¬ë§µ ìƒì„± (ìŠ¤ë§ˆíŠ¸ í…ìŠ¤íŠ¸ ìƒ‰ìƒ)"""
        try:
            if sector_data.empty:
                return go.Figure()
            
            # ìƒ‰ìƒê³¼ í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ í•¨ê»˜ ê²°ì •
            colors = []
            
            for change in sector_data['change_pct']:
                if change > 2:
                    colors.append('#00AA00')  # ì§„í•œ ì´ˆë¡ -> ë°ê¸°ë¥¼ ì¡°ê¸ˆ ë‚®ì¶°ì„œ ê²€ì€ í…ìŠ¤íŠ¸ê°€ ë³´ì´ë„ë¡
                elif change > 0:
                    colors.append('#90EE90')  # ì—°í•œ ì´ˆë¡
                elif change > -2:
                    colors.append('#FFB6C1')  # ì—°í•œ ë¹¨ê°•
                else:
                    colors.append('#CC0000')  # ì§„í•œ ë¹¨ê°• -> ë°ê¸°ë¥¼ ì¡°ê¸ˆ ë‚®ì¶°ì„œ ê²€ì€ í…ìŠ¤íŠ¸ê°€ ë³´ì´ë„ë¡
            
            # í˜¸ë²„ í…ìŠ¤íŠ¸ ìƒì„±
            hover_text = []
            for _, row in sector_data.iterrows():
                hover_text.append(
                    f"<b>{row['company_name']}</b><br>" +
                    f"ì¢…ëª©ì½”ë“œ: {row['symbol']}<br>" +
                    f"ì‹œê°€ì´ì•¡: ${row['market_cap_b']:.1f}B<br>" +
                    f"í˜„ì¬ê°€: ${row['current_price']:.2f}<br>" +
                    f"ë³€ë™ë¥ : {row['change_pct']:+.2f}%<br>" +
                    f"P/E ë¹„ìœ¨: {row['pe_ratio']:.1f}<br>" +
                    f"ë°°ë‹¹ìˆ˜ìµë¥ : {row['dividend_yield']:.2f}%"
                )
            
            # íŠ¸ë¦¬ë§µ ìƒì„±
            fig = go.Figure(go.Treemap(
                labels=[f"<b>{row['symbol']}</b><br>{row['company_name']}<br>${row['market_cap_b']:.1f}B<br><b>{row['change_pct']:+.1f}%</b>" 
                    for _, row in sector_data.iterrows()],
                values=sector_data['market_cap'],
                parents=[""] * len(sector_data),
                marker=dict(
                    colors=colors,
                    line=dict(width=3, color='white')  # ê²½ê³„ì„ ì„ ë” ë‘ê»ê²Œ
                ),
                textfont=dict(
                    size=11,  # í¬ê¸°ë¥¼ ì‚´ì§ ì¤„ì—¬ì„œ ê°€ë…ì„± í–¥ìƒ
                    color='black',  # ê²€ì€ìƒ‰ í…ìŠ¤íŠ¸
                    family='Arial Black, Arial, sans-serif'  # ë” êµµì€ í°íŠ¸ë¡œ ê°€ë…ì„± í–¥ìƒ
                ),
                hovertext=hover_text,
                hovertemplate='%{hovertext}<extra></extra>'
            ))
            
            fig.update_layout(
                title=f'{sector_name} ì„¹í„° ì‹œê°€ì´ì•¡ TOP {len(sector_data)}',
                title_x=0.5,
                font_size=12,
                height=600,
                margin=dict(t=50, l=25, r=25, b=25)
            )
            
            return fig
            
        except Exception as e:
            st.error(f"íŠ¸ë¦¬ë§µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return go.Figure()
    
    @staticmethod
    def create_sector_summary_chart(all_sectors_data: Dict) -> go.Figure:
        """ì „ì²´ ì„¹í„° ìš”ì•½ ì°¨íŠ¸ ìƒì„±"""
        try:
            if not all_sectors_data:
                return go.Figure()
            
            sector_summary = []
            
            for sector, data in all_sectors_data.items():
                if data.empty:
                    continue
                
                total_market_cap = data['market_cap'].sum()
                avg_change = data['change_pct'].mean()
                top_stock = data.iloc[0]
                
                sector_summary.append({
                    'sector': sector,
                    'total_market_cap_b': total_market_cap / 1e9,
                    'avg_change_pct': avg_change,
                    'stock_count': len(data),
                    'top_stock': f"{top_stock['symbol']} (${top_stock['market_cap_b']:.1f}B)"
                })
            
            if not sector_summary:
                return go.Figure()
            
            summary_df = pd.DataFrame(sector_summary)
            summary_df = summary_df.sort_values('total_market_cap_b', ascending=True)
            
            # ìƒ‰ìƒ ê²°ì • (í‰ê·  ë³€ë™ë¥  ê¸°ì¤€)
            colors = ['green' if x > 0 else 'red' for x in summary_df['avg_change_pct']]
            
            fig = go.Figure(go.Bar(
                y=summary_df['sector'],
                x=summary_df['total_market_cap_b'],
                orientation='h',
                marker_color=colors,
                text=[f"{x:.1f}% ({summary_df.iloc[i]['stock_count']}ê°œ)" 
                      for i, x in enumerate(summary_df['avg_change_pct'])],
                textposition='auto',
                hovertemplate='<b>%{y}</b><br>' +
                             'ì´ ì‹œê°€ì´ì•¡: $%{x:.1f}B<br>' +
                             'í‰ê·  ë³€ë™ë¥ : %{text}<br>' +
                             '<extra></extra>'
            ))
            
            fig.update_layout(
                title='ì„¹í„°ë³„ ì‹œê°€ì´ì•¡ ë° í‰ê·  ë³€ë™ë¥ ',
                xaxis_title='ì´ ì‹œê°€ì´ì•¡ (Billions $)',
                yaxis_title='ì„¹í„°',
                height=500,
                showlegend=False
            )
            
            return fig
            
        except Exception as e:
            st.error(f"ì„¹í„° ìš”ì•½ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return go.Figure()


class DataManager:
    """ë°ì´í„° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    @st.cache_data(ttl=3600)  # 1ì‹œê°„ ìºì‹±
    def get_stock_data(symbol: str, period: str = "2y") -> pd.DataFrame:
        """ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            stock = yf.Ticker(symbol)
            data = stock.history(period=period)
            return data
        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {symbol} - {str(e)}")
            return pd.DataFrame()
    
    @staticmethod
    @st.cache_data(ttl=3600)
    def get_financial_data(symbol: str) -> Dict:
        """ì¬ë¬´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            stock = yf.Ticker(symbol)
            info = stock.info
            financials = stock.financials
            balance_sheet = stock.balance_sheet
            cash_flow = stock.cashflow
            
            return {
                'info': info,
                'financials': financials,
                'balance_sheet': balance_sheet,
                'cash_flow': cash_flow
            }
        except Exception as e:
            st.error(f"ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {symbol} - {str(e)}")
            return {}


class PredictionModel:
    """ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤"""
    
    @staticmethod
    def prophet_forecast(data: pd.DataFrame, days: int = 30) -> Tuple[pd.DataFrame, Dict]:
        """Prophetì„ ì‚¬ìš©í•œ ì£¼ê°€ ì˜ˆì¸¡"""
        try:
            # Prophetìš© ë°ì´í„° ì¤€ë¹„
            df = data.reset_index()
            df = df[['Date', 'Close']].rename(columns={'Date': 'ds', 'Close': 'y'})
            
            # ì‹œê°„ëŒ€ ì •ë³´ ì œê±° (Prophetì€ timezone-naive datetimeì„ ìš”êµ¬)
            df['ds'] = pd.to_datetime(df['ds']).dt.tz_localize(None)
            
            # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
            model = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)
            model.fit(df)
            
            # ì˜ˆì¸¡
            future = model.make_future_dataframe(periods=days)
            forecast = model.predict(future)
            
            # ì„±ëŠ¥ í‰ê°€ (ë§ˆì§€ë§‰ 30ì¼)
            if len(df) > 30:
                train_size = len(df) - 30
                train_df = df[:train_size]
                test_df = df[train_size:]
                
                model_eval = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)
                model_eval.fit(train_df)
                
                future_eval = model_eval.make_future_dataframe(periods=30)
                forecast_eval = model_eval.predict(future_eval)
                
                # MAPE ê³„ì‚°
                actual = test_df['y'].values
                predicted = forecast_eval.tail(30)['yhat'].values[:len(actual)]
                mape = np.mean(np.abs((actual - predicted) / actual)) * 100
                rmse = np.sqrt(np.mean((actual - predicted) ** 2))
            else:
                # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ë”ë¯¸ ë©”íŠ¸ë¦­
                mape = 0.0
                rmse = 0.0
            
            metrics = {'MAPE': mape, 'RMSE': rmse}
            
            return forecast, metrics
            
        except Exception as e:
            st.error(f"Prophet ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            return pd.DataFrame(), {}
    
    @staticmethod
    def arima_forecast(data: pd.DataFrame, days: int = 30) -> Tuple[pd.DataFrame, Dict]:
        """ARIMAë¥¼ ì‚¬ìš©í•œ ì£¼ê°€ ì˜ˆì¸¡"""
        try:
            prices = data['Close'].values
            
            # ARIMA ëª¨ë¸ (ìë™ íŒŒë¼ë¯¸í„°ëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ê³ ì •ê°’ ì‚¬ìš©)
            model = ARIMA(prices, order=(5,1,2))
            fitted_model = model.fit()
            
            # ì˜ˆì¸¡
            forecast_result = fitted_model.forecast(steps=days)
            
            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            last_date = data.index[-1]
            forecast_dates = pd.date_range(start=last_date + timedelta(days=1), periods=days)
            
            forecast_df = pd.DataFrame({
                'ds': forecast_dates,
                'yhat': forecast_result,
                'yhat_lower': forecast_result * 0.95,  # ê°„ë‹¨í•œ ì‹ ë¢°êµ¬ê°„
                'yhat_upper': forecast_result * 1.05
            })
            
            # ì„±ëŠ¥ í‰ê°€
            if len(prices) > 30:
                train_size = len(prices) - 30
                train_data = prices[:train_size]
                test_data = prices[train_size:]
                
                model_eval = ARIMA(train_data, order=(5,1,2))
                fitted_eval = model_eval.fit()
                forecast_eval = fitted_eval.forecast(steps=len(test_data))
                
                mape = np.mean(np.abs((test_data - forecast_eval) / test_data)) * 100
                rmse = np.sqrt(np.mean((test_data - forecast_eval) ** 2))
            else:
                mape = 0.0
                rmse = 0.0
            
            metrics = {'MAPE': mape, 'RMSE': rmse}
            
            return forecast_df, metrics
            
        except Exception as e:
            st.error(f"ARIMA ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            return pd.DataFrame(), {}
        
    @staticmethod
    def prophet_volume_forecast(data: pd.DataFrame, days: int = 30) -> Tuple[pd.DataFrame, Dict]:
        """Prophetì„ ì‚¬ìš©í•œ ê±°ë˜ëŸ‰ ì˜ˆì¸¡"""
        try:
            # Prophetìš© ë°ì´í„° ì¤€ë¹„ (ê±°ë˜ëŸ‰ ê¸°ì¤€)
            df = data.reset_index()
            
            # ê±°ë˜ëŸ‰ì´ 0ì¸ ë°ì´í„° ì œê±°
            df = df[df['Volume'] > 0]
            
            if len(df) < 10:  # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì˜ˆì¸¡ ë¶ˆê°€
                return pd.DataFrame(), {'error': 'ê±°ë˜ëŸ‰ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤'}
            
            df = df[['Date', 'Volume']].rename(columns={'Date': 'ds', 'Volume': 'y'})
            
            # ì‹œê°„ëŒ€ ì •ë³´ ì œê±°
            df['ds'] = pd.to_datetime(df['ds']).dt.tz_localize(None)
            
            # ê±°ë˜ëŸ‰ì€ ë¡œê·¸ ë³€í™˜í•˜ì—¬ ì˜ˆì¸¡ (ë³€ë™ì„± ì™„í™”)
            df['y'] = np.log(df['y'] + 1)
            
            # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
            model = Prophet(
                daily_seasonality=True, 
                weekly_seasonality=True, 
                yearly_seasonality=False,  # ê±°ë˜ëŸ‰ì€ ì—°ê°„ ê³„ì ˆì„±ì´ ì•½í•¨
                seasonality_mode='additive'
            )
            model.fit(df)
            
            # ì˜ˆì¸¡
            future = model.make_future_dataframe(periods=days)
            forecast = model.predict(future)
            
            # ë¡œê·¸ ë³€í™˜ ì—­ë³€í™˜
            forecast['yhat'] = np.exp(forecast['yhat']) - 1
            forecast['yhat_lower'] = np.exp(forecast['yhat_lower']) - 1
            forecast['yhat_upper'] = np.exp(forecast['yhat_upper']) - 1
            
            # ìŒìˆ˜ ê°’ ì œê±°
            forecast['yhat'] = np.maximum(forecast['yhat'], 0)
            forecast['yhat_lower'] = np.maximum(forecast['yhat_lower'], 0)
            forecast['yhat_upper'] = np.maximum(forecast['yhat_upper'], 0)
            
            # ì„±ëŠ¥ í‰ê°€
            if len(df) > 15:
                train_size = len(df) - 15
                train_df = df[:train_size]
                test_df = df[train_size:]
                
                model_eval = Prophet(
                    daily_seasonality=True, 
                    weekly_seasonality=True, 
                    yearly_seasonality=False,
                    seasonality_mode='additive'
                )
                model_eval.fit(train_df)
                
                future_eval = model_eval.make_future_dataframe(periods=15)
                forecast_eval = model_eval.predict(future_eval)
                
                # ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ ë¹„êµ (ë¡œê·¸ ì—­ë³€í™˜)
                actual = np.exp(test_df['y'].values) - 1
                predicted = np.exp(forecast_eval.tail(15)['yhat'].values[:len(actual)]) - 1
                
                # MAPE ê³„ì‚° (ê±°ë˜ëŸ‰ì´ 0ì— ê°€ê¹Œìš´ ê²½ìš° ì²˜ë¦¬)
                mask = actual > 1000  # ê±°ë˜ëŸ‰ì´ 1000 ì´ìƒì¸ ê²½ìš°ë§Œ ê³„ì‚°
                if mask.sum() > 0:
                    mape = np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100
                    rmse = np.sqrt(np.mean((actual - predicted) ** 2))
                else:
                    mape = 0.0
                    rmse = 0.0
            else:
                mape = 0.0
                rmse = 0.0
            
            metrics = {'MAPE': mape, 'RMSE': rmse}
            
            return forecast, metrics
            
        except Exception as e:
            return pd.DataFrame(), {'error': f"Prophet ê±°ë˜ëŸ‰ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}"}
    
    @staticmethod
    def arima_volume_forecast(data: pd.DataFrame, days: int = 30) -> Tuple[pd.DataFrame, Dict]:
        """ARIMAë¥¼ ì‚¬ìš©í•œ ê±°ë˜ëŸ‰ ì˜ˆì¸¡"""
        try:
            # ê±°ë˜ëŸ‰ì´ 0ì¸ ë°ì´í„° ì œê±°
            volume_data = data[data['Volume'] > 0]['Volume']
            
            if len(volume_data) < 20:
                return pd.DataFrame(), {'error': 'ê±°ë˜ëŸ‰ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤'}
            
            # ë¡œê·¸ ë³€í™˜ìœ¼ë¡œ ì•ˆì •í™”
            log_volume = np.log(volume_data + 1)
            
            # ARIMA ëª¨ë¸ (ê±°ë˜ëŸ‰ì€ ì°¨ë¶„ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
            model = ARIMA(log_volume, order=(3,1,2))
            fitted_model = model.fit()
            
            # ì˜ˆì¸¡
            forecast_result = fitted_model.forecast(steps=days)
            
            # ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
            forecast_ci = fitted_model.get_forecast(steps=days).conf_int()
            
            # ë¡œê·¸ ì—­ë³€í™˜
            forecast_values = np.exp(forecast_result) - 1
            forecast_lower = np.exp(forecast_ci.iloc[:, 0]) - 1
            forecast_upper = np.exp(forecast_ci.iloc[:, 1]) - 1
            
            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            last_date = data.index[-1]
            forecast_dates = pd.date_range(start=last_date + timedelta(days=1), periods=days)
            
            forecast_df = pd.DataFrame({
                'ds': forecast_dates,
                'yhat': forecast_values,
                'yhat_lower': forecast_lower,
                'yhat_upper': forecast_upper
            })
            
            # ì„±ëŠ¥ í‰ê°€
            if len(log_volume) > 15:
                train_size = len(log_volume) - 15
                train_data = log_volume[:train_size]
                test_data = log_volume[train_size:]
                
                model_eval = ARIMA(train_data, order=(3,1,2))
                fitted_eval = model_eval.fit()
                forecast_eval = fitted_eval.forecast(steps=len(test_data))
                
                # ë¡œê·¸ ì—­ë³€í™˜í•˜ì—¬ ë¹„êµ
                actual = np.exp(test_data) - 1
                predicted = np.exp(forecast_eval) - 1
                
                # MAPE ê³„ì‚°
                mask = actual > 1000
                if mask.sum() > 0:
                    mape = np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100
                    rmse = np.sqrt(np.mean((actual - predicted) ** 2))
                else:
                    mape = 0.0
                    rmse = 0.0
            else:
                mape = 0.0
                rmse = 0.0
            
            metrics = {'MAPE': mape, 'RMSE': rmse}
            
            return forecast_df, metrics
            
        except Exception as e:
            return pd.DataFrame(), {'error': f"ARIMA ê±°ë˜ëŸ‰ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}"}


# ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜ ì¶”ê°€

def create_volume_chart(data: pd.DataFrame, forecast: pd.DataFrame, symbol: str):
    """ê±°ë˜ëŸ‰ ì°¨íŠ¸ ìƒì„± (ì„  ê·¸ë˜í”„)"""
    fig = go.Figure()
    
    # ì‹¤ì œ ê±°ë˜ëŸ‰ (ì„  ê·¸ë˜í”„)
    fig.add_trace(go.Scatter(
        x=data.index,
        y=data['Volume'],
        mode='lines',
        name='ì‹¤ì œ ê±°ë˜ëŸ‰',
        line=dict(color='lightblue', width=2),
        fill=None
    ))
    
    if not forecast.empty:
        # ì˜ˆì¸¡ ê±°ë˜ëŸ‰ (ì„  ê·¸ë˜í”„)
        fig.add_trace(go.Scatter(
            x=forecast['ds'],
            y=forecast['yhat'],
            mode='lines',
            name='ì˜ˆì¸¡ ê±°ë˜ëŸ‰',
            line=dict(color='orange', width=2, dash='dash')
        ))
        
        # ì‹ ë¢°êµ¬ê°„ (ì˜ì—­ ì°¨íŠ¸)
        if 'yhat_lower' in forecast.columns and 'yhat_upper' in forecast.columns:
            fig.add_trace(go.Scatter(
                x=forecast['ds'],
                y=forecast['yhat_upper'],
                fill=None,
                mode='lines',
                line_color='rgba(0,0,0,0)',
                showlegend=False
            ))
            
            fig.add_trace(go.Scatter(
                x=forecast['ds'],
                y=forecast['yhat_lower'],
                fill='tonexty',
                mode='lines',
                line_color='rgba(0,0,0,0)',
                name='ì‹ ë¢°êµ¬ê°„',
                fillcolor='rgba(255,165,0,0.2)'
            ))
    
    fig.update_layout(
        title=f'{symbol} ê±°ë˜ëŸ‰ ì˜ˆì¸¡',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='ê±°ë˜ëŸ‰',
        hovermode='x unified',
        height=400,
        yaxis=dict(type='linear')  # ë¡œê·¸ ìŠ¤ì¼€ì¼ì´ í•„ìš”í•˜ë©´ 'log'ë¡œ ë³€ê²½
    )
    
    return fig


def create_combined_chart(price_data: pd.DataFrame, volume_data: pd.DataFrame, 
                         price_forecast: pd.DataFrame, volume_forecast: pd.DataFrame, symbol: str):
    """ì£¼ê°€ì™€ ê±°ë˜ëŸ‰ì„ í•¨ê»˜ ë³´ì—¬ì£¼ëŠ” ë³µí•© ì°¨íŠ¸"""
    from plotly.subplots import make_subplots
    
    # 2ê°œ í–‰ì˜ ì„œë¸Œí”Œë¡¯ ìƒì„±
    fig = make_subplots(
        rows=2, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.03,
        subplot_titles=(f'{symbol} ì£¼ê°€ ì˜ˆì¸¡', f'{symbol} ê±°ë˜ëŸ‰ ì˜ˆì¸¡'),
        row_width=[0.7, 0.3]
    )
    
    # ì£¼ê°€ ì°¨íŠ¸ (ì²« ë²ˆì§¸ í–‰)
    fig.add_trace(
        go.Scatter(
            x=price_data.index,
            y=price_data['Close'],
            mode='lines',
            name='ì‹¤ì œ ì£¼ê°€',
            line=dict(color='blue', width=2)
        ),
        row=1, col=1
    )
    
    if not price_forecast.empty:
        fig.add_trace(
            go.Scatter(
                x=price_forecast['ds'],
                y=price_forecast['yhat'],
                mode='lines',
                name='ì˜ˆì¸¡ ì£¼ê°€',
                line=dict(color='red', width=2, dash='dash')
            ),
            row=1, col=1
        )
    
    # ê±°ë˜ëŸ‰ ì°¨íŠ¸ (ë‘ ë²ˆì§¸ í–‰) - ì„  ê·¸ë˜í”„ë¡œ ë³€ê²½
    fig.add_trace(
        go.Scatter(
            x=volume_data.index,
            y=volume_data['Volume'],
            mode='lines',
            name='ì‹¤ì œ ê±°ë˜ëŸ‰',
            line=dict(color='lightblue', width=2),
            fill='tozeroy',  # 0ê¹Œì§€ ì±„ìš°ê¸°
            fillcolor='rgba(173,216,230,0.3)'
        ),
        row=2, col=1
    )
    
    if not volume_forecast.empty:
        fig.add_trace(
            go.Scatter(
                x=volume_forecast['ds'],
                y=volume_forecast['yhat'],
                mode='lines',
                name='ì˜ˆì¸¡ ê±°ë˜ëŸ‰',
                line=dict(color='orange', width=2, dash='dash'),
                fill='tozeroy',  # 0ê¹Œì§€ ì±„ìš°ê¸°
                fillcolor='rgba(255,165,0,0.3)'
            ),
            row=2, col=1
        )
    
    # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
    fig.update_layout(
        title=f'{symbol} ì£¼ê°€ ë° ê±°ë˜ëŸ‰ ì¢…í•© ì˜ˆì¸¡',
        height=700,
        hovermode='x unified'
    )
    
    fig.update_xaxes(title_text="ë‚ ì§œ", row=2, col=1)
    fig.update_yaxes(title_text="ì£¼ê°€ ($)", row=1, col=1)
    fig.update_yaxes(title_text="ê±°ë˜ëŸ‰", row=2, col=1)
    
    return fig


# ê±°ë˜ëŸ‰ ë¶„ì„ í•¨ìˆ˜
def analyze_volume_trends(data: pd.DataFrame, forecast: pd.DataFrame) -> Dict:
    """ê±°ë˜ëŸ‰ íŠ¸ë Œë“œ ë¶„ì„"""
    try:
        analysis = {}
        
        if data.empty or 'Volume' not in data.columns:
            return {'error': 'ê±°ë˜ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
        
        # ìµœê·¼ ê±°ë˜ëŸ‰ í†µê³„
        recent_volume = data['Volume'][-30:]  # ìµœê·¼ 30ì¼
        avg_volume_30d = recent_volume.mean()
        
        # ì „ì²´ í‰ê· ê³¼ ë¹„êµ
        total_avg_volume = data['Volume'].mean()
        volume_ratio = avg_volume_30d / total_avg_volume if total_avg_volume > 0 else 0
        
        # ê±°ë˜ëŸ‰ íŠ¸ë Œë“œ (ìµœê·¼ 10ì¼ vs ì´ì „ 10ì¼)
        if len(data) >= 20:
            recent_10d = data['Volume'][-10:].mean()
            previous_10d = data['Volume'][-20:-10].mean()
            trend_change = ((recent_10d - previous_10d) / previous_10d * 100) if previous_10d > 0 else 0
        else:
            trend_change = 0
        
        # ê±°ë˜ëŸ‰ ë³€ë™ì„±
        volume_std = recent_volume.std()
        volume_cv = (volume_std / avg_volume_30d * 100) if avg_volume_30d > 0 else 0
        
        # ì˜ˆì¸¡ ê±°ë˜ëŸ‰ ë¶„ì„
        if not forecast.empty and 'yhat' in forecast.columns:
            predicted_avg = forecast['yhat'].mean()
            volume_forecast_change = ((predicted_avg - avg_volume_30d) / avg_volume_30d * 100) if avg_volume_30d > 0 else 0
        else:
            volume_forecast_change = 0
            predicted_avg = 0
        
        analysis = {
            'avg_volume_30d': avg_volume_30d,
            'total_avg_volume': total_avg_volume,
            'volume_ratio': volume_ratio,
            'trend_change': trend_change,
            'volume_cv': volume_cv,
            'volume_forecast_change': volume_forecast_change,
            'predicted_avg': predicted_avg
        }
        
        return analysis
        
    except Exception as e:
        return {'error': f'ê±°ë˜ëŸ‰ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}


class SentimentAnalyzer:
    """ê°ì„± ë¶„ì„ í´ë˜ìŠ¤"""
    
    @staticmethod
    @st.cache_data(ttl=1800)  # 30ë¶„ ìºì‹±
    def search_web_news(query: str, num_results: int = 10) -> List[Dict]:
        """ì›¹ì—ì„œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            # Google ê²€ìƒ‰ (ë‰´ìŠ¤ í•„í„°)
            search_url = f"https://www.google.com/search?q={quote(query)}&tbm=nws&num={num_results}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(search_url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            news_results = []
            
            # ë‰´ìŠ¤ í•­ëª© íŒŒì‹±
            news_items = soup.find_all('div', class_='SoaBEf')
            
            for item in news_items[:num_results]:
                try:
                    # ì œëª© ì¶”ì¶œ
                    title_elem = item.find('div', class_='MBeuO')
                    title = title_elem.get_text() if title_elem else "ì œëª© ì—†ìŒ"
                    
                    # ë§í¬ ì¶”ì¶œ
                    link_elem = item.find('a')
                    link = link_elem.get('href') if link_elem else "#"
                    
                    # ì¶œì²˜ ì¶”ì¶œ
                    source_elem = item.find('div', class_='CEMjEf')
                    source = source_elem.get_text() if source_elem else "ì¶œì²˜ ë¶ˆëª…"
                    
                    # ì‹œê°„ ì¶”ì¶œ
                    time_elem = item.find('span', class_='r0bn4c')
                    pub_time = time_elem.get_text() if time_elem else "ì‹œê°„ ë¶ˆëª…"
                    
                    # ìš”ì•½ ì¶”ì¶œ
                    snippet_elem = item.find('div', class_='GI74Re')
                    snippet = snippet_elem.get_text() if snippet_elem else ""
                    
                    news_results.append({
                        'title': title,
                        'link': link,
                        'source': source,
                        'published_time': pub_time,
                        'snippet': snippet
                    })
                    
                except Exception as e:
                    continue
            
            return news_results
            
        except Exception as e:
            st.warning(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    @staticmethod
    def analyze_with_gpt(news_data: List[Dict], symbol: str, openai_api_key: str) -> Dict:
        """GPTë¥¼ ì´ìš©í•œ ë‰´ìŠ¤ ë¶„ì„"""
        try:
            if not openai_api_key:
                return {"error": "OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
            
            # ìµœì‹  OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
            from openai import OpenAI
            client = OpenAI(api_key=openai_api_key)
            
            # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            news_text = ""
            for i, news in enumerate(news_data[:10], 1):  # ìµœëŒ€ 10ê°œ ë‰´ìŠ¤
                news_text += f"\n{i}. ì œëª©: {news['title']}\n"
                news_text += f"   ì¶œì²˜: {news['source']} ({news['published_time']})\n"
                news_text += f"   ë‚´ìš©: {news['snippet']}\n"
            
            prompt = f"""
ë‹¤ìŒì€ {symbol} ê¸°ì—…ê³¼ ê´€ë ¨ëœ ìµœê·¼ ë‰´ìŠ¤ë“¤ì…ë‹ˆë‹¤. ì´ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

ë‰´ìŠ¤ ë°ì´í„°:
{news_text}

ë¶„ì„ ìš”ì²­:
1. ì „ì²´ì ì¸ ì‹œì¥ ê°ì„± (ë§¤ìš° ê¸ì •ì /ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì /ë§¤ìš° ë¶€ì •ì )
2. ì£¼ìš” ì´ìŠˆ 3ê°€ì§€ (ê°ê° í•œ ì¤„ë¡œ ìš”ì•½)
3. íˆ¬ìì ê´€ì ì—ì„œì˜ ì‹œì‚¬ì  (3-4ì¤„)
4. ì˜ˆìƒë˜ëŠ” ì£¼ê°€ ì˜í–¥ (ìƒìŠ¹ ìš”ì¸/í•˜ë½ ìš”ì¸)

ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, íˆ¬ì ì „ë¬¸ê°€ ê´€ì ì—ì„œ ê°ê´€ì ì´ê³  ë¶„ì„ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

            response = client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ê°ê´€ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” íˆ¬ì ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            analysis = response.choices[0].message.content.strip()
            
            # ê°ì„± ì ìˆ˜ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
            if "ë§¤ìš° ê¸ì •ì " in analysis:
                sentiment_score = 0.8
                sentiment_label = "ë§¤ìš° ê¸ì •ì "
            elif "ê¸ì •ì " in analysis:
                sentiment_score = 0.4
                sentiment_label = "ê¸ì •ì "
            elif "ë§¤ìš° ë¶€ì •ì " in analysis:
                sentiment_score = -0.8
                sentiment_label = "ë§¤ìš° ë¶€ì •ì "
            elif "ë¶€ì •ì " in analysis:
                sentiment_score = -0.4
                sentiment_label = "ë¶€ì •ì "
            else:
                sentiment_score = 0.0
                sentiment_label = "ì¤‘ë¦½ì "
            
            return {
                "analysis": analysis,
                "sentiment_score": sentiment_score,
                "sentiment_label": sentiment_label,
                "news_count": len(news_data)
            }
            
        except Exception as e:
            return {"error": f"GPT ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
    
    @staticmethod
    @st.cache_data(ttl=3600)
    def get_news_sentiment(symbol: str, days: int = 7) -> Dict:
        """ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (ê¸°ì¡´ ë”ë¯¸ ë°ì´í„° ë°©ì‹ ìœ ì§€)"""
        try:
            # ê¸°ì¡´ ë”ë¯¸ ë°ì´í„° (GPT ë¶„ì„ì´ ì‹¤íŒ¨í•  ê²½ìš° ëŒ€ë¹„)
            news_data = {
                'articles': [
                    {'title': f'{symbol} shows strong quarterly results', 'description': 'The company reported better than expected earnings.'},
                    {'title': f'{symbol} faces market challenges', 'description': 'Industry headwinds affecting performance.'},
                    {'title': f'{symbol} announces new product launch', 'description': 'Innovation driving future growth prospects.'}
                ]
            }
            
            sentiments = []
            for article in news_data['articles']:
                text = f"{article['title']} {article['description']}"
                blob = TextBlob(text)
                sentiment = blob.sentiment.polarity
                
                if sentiment > 0.1:
                    category = 'Positive'
                elif sentiment < -0.1:
                    category = 'Negative'
                else:
                    category = 'Neutral'
                
                sentiments.append({
                    'title': article['title'],
                    'sentiment_score': sentiment,
                    'sentiment_category': category
                })
            
            # ê°ì„± ì§‘ê³„
            positive = sum(1 for s in sentiments if s['sentiment_category'] == 'Positive')
            negative = sum(1 for s in sentiments if s['sentiment_category'] == 'Negative')
            neutral = sum(1 for s in sentiments if s['sentiment_category'] == 'Neutral')
            
            return {
                'sentiments': sentiments,
                'summary': {
                    'positive': positive,
                    'negative': negative,
                    'neutral': neutral,
                    'total': len(sentiments)
                }
            }
        except Exception as e:
            st.error(f"ê°ì„± ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    @staticmethod
    def get_enhanced_news_sentiment(symbol: str, openai_api_key: str = None) -> Dict:
        """GPT ê¸°ë°˜ í–¥ìƒëœ ë‰´ìŠ¤ ê°ì„± ë¶„ì„"""
        try:
            # ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì œ ë‰´ìŠ¤ ìˆ˜ì§‘
            search_query = f"{symbol} stock news latest"
            news_results = SentimentAnalyzer.search_web_news(search_query, num_results=15)
            
            if not news_results:
                # ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                return SentimentAnalyzer.get_news_sentiment(symbol)
            
            result = {
                'news_articles': news_results,
                'basic_sentiment': None,
                'gpt_analysis': None
            }
            
            # ê¸°ë³¸ TextBlob ê°ì„± ë¶„ì„
            basic_sentiments = []
            for news in news_results:
                text = f"{news['title']} {news['snippet']}"
                blob = TextBlob(text)
                sentiment = blob.sentiment.polarity
                
                if sentiment > 0.1:
                    category = 'Positive'
                elif sentiment < -0.1:
                    category = 'Negative'
                else:
                    category = 'Neutral'
                
                basic_sentiments.append({
                    'title': news['title'],
                    'sentiment_score': sentiment,
                    'sentiment_category': category,
                    'link': news['link'],
                    'source': news['source'],
                    'time': news['published_time']
                })
            
            # ê¸°ë³¸ ê°ì„± ì§‘ê³„
            positive = sum(1 for s in basic_sentiments if s['sentiment_category'] == 'Positive')
            negative = sum(1 for s in basic_sentiments if s['sentiment_category'] == 'Negative')
            neutral = sum(1 for s in basic_sentiments if s['sentiment_category'] == 'Neutral')
            
            result['basic_sentiment'] = {
                'sentiments': basic_sentiments,
                'summary': {
                    'positive': positive,
                    'negative': negative,
                    'neutral': neutral,
                    'total': len(basic_sentiments)
                }
            }
            
            # GPT ë¶„ì„ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
            if openai_api_key:
                gpt_result = SentimentAnalyzer.analyze_with_gpt(news_results, symbol, openai_api_key)
                result['gpt_analysis'] = gpt_result
            
            return result
            
        except Exception as e:
            st.error(f"í–¥ìƒëœ ê°ì„± ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return SentimentAnalyzer.get_news_sentiment(symbol)


class FinancialAnalyzer:
    """ì¬ë¬´ ë¶„ì„ í´ë˜ìŠ¤"""
    
    @staticmethod
    def calculate_financial_metrics(financial_data: Dict) -> Dict:
        """ì¬ë¬´ ì§€í‘œ ê³„ì‚°"""
        try:
            info = financial_data.get('info', {})
            
            metrics = {
                'market_cap': info.get('marketCap', 0),
                'pe_ratio': info.get('trailingPE', 0),
                'pb_ratio': info.get('priceToBook', 0),
                'debt_to_equity': info.get('debtToEquity', 0),
                'roe': info.get('returnOnEquity', 0),
                'profit_margin': info.get('profitMargins', 0),
                'revenue_growth': info.get('revenueGrowth', 0),
                'free_cash_flow': info.get('freeCashflow', 0),
                'current_ratio': info.get('currentRatio', 0),
                'dividend_yield': info.get('dividendYield', 0) or 0
            }
            
            # None ê°’ë“¤ì„ 0ìœ¼ë¡œ ë³€í™˜
            for key, value in metrics.items():
                if value is None:
                    metrics[key] = 0
            
            return metrics
            
        except Exception as e:
            st.error(f"ì¬ë¬´ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            return {}
    
    @staticmethod
    def analyze_financial_metrics_with_gpt(metrics: Dict, financial_history: Dict, symbol: str, openai_api_key: str) -> Dict:
        """GPTë¥¼ ì´ìš©í•œ ì¬ë¬´ ì§€í‘œ ë¶„ì„"""
        try:
            if not openai_api_key:
                return {"error": "OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
            
            from openai import OpenAI
            client = OpenAI(api_key=openai_api_key)
            
            # ì¬ë¬´ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            financial_text = f"""
{symbol} ê¸°ì—…ì˜ ì¬ë¬´ ì§€í‘œ ë¶„ì„:

ğŸ“Š í˜„ì¬ ì¬ë¬´ ì§€í‘œ:
- ì‹œê°€ì´ì•¡: ${metrics.get('market_cap', 0)/1e9:.1f}B
- P/E ë¹„ìœ¨: {metrics.get('pe_ratio', 0):.2f}
- P/B ë¹„ìœ¨: {metrics.get('pb_ratio', 0):.2f}
- ë¶€ì±„ë¹„ìœ¨ (D/E): {metrics.get('debt_to_equity', 0):.2f}
- ROE: {metrics.get('roe', 0)*100:.1f}%
- ìˆœì´ìµë¥ : {metrics.get('profit_margin', 0)*100:.1f}%
- ë§¤ì¶œ ì„±ì¥ë¥ : {metrics.get('revenue_growth', 0)*100:.1f}%
- ììœ í˜„ê¸ˆíë¦„: ${metrics.get('free_cash_flow', 0)/1e9:.1f}B
- ìœ ë™ë¹„ìœ¨: {metrics.get('current_ratio', 0):.2f}
- ë°°ë‹¹ìˆ˜ìµë¥ : {metrics.get('dividend_yield', 0):.2f}%
"""

            # 3ê°œë…„ ì‹¤ì  ë°ì´í„° ì¶”ê°€
            if financial_history and financial_history.get('years'):
                financial_text += f"""

ğŸ“ˆ ìµœê·¼ 3ê°œë…„ ì‹¤ì  ì¶”ì´:
"""
                for i, year in enumerate(financial_history['years']):
                    revenue = financial_history['revenue'][i]
                    op_income = financial_history['operating_income'][i]
                    net_income = financial_history['net_income'][i]
                    
                    financial_text += f"""
- {year}ë…„: ë§¤ì¶œ ${revenue:.1f}B, ì˜ì—…ì´ìµ ${op_income:.1f}B, ìˆœì´ìµ ${net_income:.1f}B"""

            prompt = f"""
ë‹¤ìŒì€ {symbol} ê¸°ì—…ì˜ ì¬ë¬´ ì§€í‘œì…ë‹ˆë‹¤. ì „ë¬¸ ì¬ë¬´ ë¶„ì„ê°€ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

{financial_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì¬ë¬´ ê±´ì „ì„± ì¢…í•© í‰ê°€** (5ì  ë§Œì ìœ¼ë¡œ ì ìˆ˜ ë¶€ì—¬)
   - ì ìˆ˜: X/5ì 
   - í•œ ì¤„ ìš”ì•½

2. **ì£¼ìš” ê°•ì ** (3ê°€ì§€)
   - ê°•ì  1: ì„¤ëª…
   - ê°•ì  2: ì„¤ëª…  
   - ê°•ì  3: ì„¤ëª…

3. **ì£¼ìš” ì•½ì  ë˜ëŠ” ì£¼ì˜ì‚¬í•­** (2-3ê°€ì§€)
   - ì•½ì  1: ì„¤ëª…
   - ì•½ì  2: ì„¤ëª…

4. **ì—…ì¢… ëŒ€ë¹„ ê²½ìŸë ¥**
   - ì—…ì¢… í‰ê·  ëŒ€ë¹„ ìš°ìˆ˜í•œ ì§€í‘œ
   - ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë¶€ì¡±í•œ ì§€í‘œ

5. **íˆ¬ìì ê´€ì  ë¶„ì„**
   - ì¥ê¸° íˆ¬ìì ê´€ì 
   - ë‹¨ê¸° íˆ¬ìì ê´€ì 
   - ë¦¬ìŠ¤í¬ ìš”ì¸

6. **ì¬ë¬´ ê°œì„  ê³¼ì œ**
   - ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­
   - ëª¨ë‹ˆí„°ë§ í•„ìš” ì§€í‘œ

7. **ê²°ë¡  ë° íˆ¬ì ì˜ê²¬**
   - ë§¤ìˆ˜/ë³´ìœ /ë§¤ë„ ì¶”ì²œ
   - ì¶”ì²œ ì´ìœ  (2-3ì¤„)

ê° í•­ëª©ì„ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. ìˆ˜ì¹˜ê°€ 0ì´ê±°ë‚˜ ì—†ëŠ” ì§€í‘œëŠ” "ë°ì´í„° ì—†ìŒ"ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ë‹¤ë¥¸ ì§€í‘œë¡œ ë³´ì™„ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""

            response = client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ì¬ë¬´ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê¸°ì—…ì˜ ì¬ë¬´ ì§€í‘œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ íˆ¬ììì—ê²Œ ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1200,
                temperature=0.3
            )
            
            analysis = response.choices[0].message.content.strip()
            
            # ì ìˆ˜ ì¶”ì¶œ (ê°„ë‹¨í•œ ì •ê·œì‹ ì‚¬ìš©)
            import re
            score_match = re.search(r'ì ìˆ˜[:\s]*(\d+(?:\.\d+)?)[/ì ]', analysis)
            score = float(score_match.group(1)) if score_match else 3.0
            
            return {
                "analysis": analysis,
                "score": score,
                "max_score": 5.0,
                "success": True
            }
            
        except Exception as e:
            return {"error": f"GPT ì¬ë¬´ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

    @staticmethod
    def get_financial_grade(score: float, max_score: float = 5.0) -> Dict:
        """ì¬ë¬´ ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        percentage = (score / max_score) * 100
        
        if percentage >= 90:
            return {"grade": "A+", "color": "success", "description": "ë§¤ìš° ìš°ìˆ˜"}
        elif percentage >= 80:
            return {"grade": "A", "color": "success", "description": "ìš°ìˆ˜"}
        elif percentage >= 70:
            return {"grade": "B+", "color": "success", "description": "ì–‘í˜¸"}
        elif percentage >= 60:
            return {"grade": "B", "color": "warning", "description": "ë³´í†µ"}
        elif percentage >= 50:
            return {"grade": "C+", "color": "warning", "description": "ë¯¸í¡"}
        elif percentage >= 40:
            return {"grade": "C", "color": "error", "description": "ë¶€ì¡±"}
        else:
            return {"grade": "D", "color": "error", "description": "ë§¤ìš° ë¶€ì¡±"}


class EconomicIndicatorAnalyzer:
    """ëŒ€ì™¸ ê²½ì œì§€í‘œ ë¶„ì„ í´ë˜ìŠ¤"""
    
    @staticmethod
    def interpret_vix(vix_value: float) -> Dict:
        """VIX ìˆ˜ì¹˜ í•´ì„"""
        if vix_value >= 50:
            return {
                'level': 'ê·¹ë„ ê³µí¬',
                'color': 'error',
                'emoji': 'ğŸš¨',
                'message': 'íŒ¨ë‹‰ ìƒíƒœ - ì—­ì„¤ì  ë§¤ìˆ˜ ê¸°íšŒ ê°€ëŠ¥',
                'advice': 'ê·¹ë„ì˜ ê³µí¬ë¡œ ì¸í•œ ê³¼ë§¤ë„ ìƒí™©. ì¥ê¸° íˆ¬ììì—ê²ŒëŠ” ê¸°íšŒê°€ ë  ìˆ˜ ìˆìŒ'
            }
        elif vix_value >= 30:
            return {
                'level': 'ë†’ì€ ê³µí¬',
                'color': 'error',
                'emoji': 'ğŸ˜°',
                'message': 'ì‹œì¥ ë¶ˆì•ˆì • - ì£¼ì˜ ê¹Šì€ ë§¤ìˆ˜ ê²€í† ',
                'advice': 'ë³€ë™ì„±ì´ ë†’ì€ ìƒíƒœ. ë¶„í•  ë§¤ìˆ˜ë‚˜ ë°©ì–´ì  íˆ¬ì ì „ëµ ê³ ë ¤'
            }
        elif vix_value >= 20:
            return {
                'level': 'ë³´í†µ ê¸´ì¥',
                'color': 'warning',
                'emoji': 'âš ï¸',
                'message': 'ì •ìƒì ì¸ ë³€ë™ì„± ìˆ˜ì¤€',
                'advice': 'ì¼ë°˜ì ì¸ ì‹œì¥ ì¡°ì • ë²”ìœ„. ì •ìƒì ì¸ íˆ¬ì ì „ëµ ìœ ì§€'
            }
        elif vix_value >= 12:
            return {
                'level': 'ì•ˆì •',
                'color': 'success',
                'emoji': 'ğŸ˜Œ',
                'message': 'ì‹œì¥ ì•ˆì • - ì •ìƒì ì¸ íˆ¬ì í™˜ê²½',
                'advice': 'ì•ˆì •ì ì¸ ì‹œì¥ ìƒí™©. ì„±ì¥ì£¼ íˆ¬ìì— ì í•©í•œ í™˜ê²½'
            }
        else:
            return {
                'level': 'ê·¹ë„ ì•ˆì •',
                'color': 'warning',
                'emoji': 'ğŸ˜´',
                'message': 'ê³¼ë„í•œ ë‚™ê´€ë¡  - ì£¼ì˜ í•„ìš”',
                'advice': 'ë„ˆë¬´ ì•ˆì¼í•œ ìƒí™©. ì‹œì¥ ê³¼ì—´ ê°€ëŠ¥ì„±ì„ ì—¼ë‘ì— ë‘ê³  ì‹ ì¤‘í•œ íˆ¬ì í•„ìš”'
            }
    
    @staticmethod
    @st.cache_data(ttl=1800)  # 30ë¶„ ìºì‹±
    def get_economic_indicators() -> Dict:
        """ì£¼ìš” ê²½ì œì§€í‘œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            indicators = {}
            
            # ì£¼ìš” ê²½ì œì§€í‘œ ì‹¬ë³¼ë“¤
            symbols = {
                'gold': 'GC=F',  # ê¸ˆ ì„ ë¬¼
                'dollar_index': 'DX-Y.NYB',  # ë‹¬ëŸ¬ ì¸ë±ìŠ¤
                'sp500': '^GSPC',  # S&P 500
                'nasdaq': '^IXIC',  # ë‚˜ìŠ¤ë‹¥
                'dow': '^DJI',  # ë‹¤ìš°ì¡´ìŠ¤
                'us_10yr': '^TNX',  # ë¯¸êµ­ 10ë…„ êµ­ì±„
                'us_2yr': '^IRX',  # ë¯¸êµ­ 2ë…„ êµ­ì±„
                'vix': '^VIX',  # ë³€ë™ì„± ì§€ìˆ˜
                'oil': 'CL=F',  # ì›ìœ  ì„ ë¬¼
                'btc': 'BTC-USD'  # ë¹„íŠ¸ì½”ì¸
            }
            
            for name, symbol in symbols.items():
                try:
                    ticker = yf.Ticker(symbol)
                    data = ticker.history(period="1y")
                    info = ticker.info
                    
                    if not data.empty:
                        current_price = data['Close'].iloc[-1]
                        prev_price = data['Close'].iloc[-2] if len(data) > 1 else current_price
                        change_pct = ((current_price - prev_price) / prev_price) * 100
                        
                        indicators[name] = {
                            'symbol': symbol,
                            'data': data,
                            'current_price': current_price,
                            'change_pct': change_pct,
                            'name': info.get('longName', name.replace('_', ' ').title())
                        }
                except Exception as e:
                    st.warning(f"{name} ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
                    continue
                    
            return indicators
            
        except Exception as e:
            st.error(f"ê²½ì œì§€í‘œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    @staticmethod
    def analyze_economic_indicators_with_gpt(indicators: Dict, openai_api_key: str) -> Dict:
        """GPTë¥¼ ì´ìš©í•œ ì¢…í•© ê²½ì œì§€í‘œ ë¶„ì„"""
        try:
            if not openai_api_key:
                return {"error": "OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
            
            from openai import OpenAI
            client = OpenAI(api_key=openai_api_key)
            
            # ê²½ì œì§€í‘œ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            economic_text = "ğŸ“Š í˜„ì¬ ì£¼ìš” ê²½ì œì§€í‘œ í˜„í™©:\n\n"
            
            # ì£¼ì‹ ì§€ìˆ˜
            if 'sp500' in indicators:
                sp500 = indicators['sp500']
                economic_text += f"â€¢ S&P 500: {sp500['current_price']:.2f} ({sp500['change_pct']:+.2f}%)\n"
            
            if 'nasdaq' in indicators:
                nasdaq = indicators['nasdaq']
                economic_text += f"â€¢ ë‚˜ìŠ¤ë‹¥: {nasdaq['current_price']:.2f} ({nasdaq['change_pct']:+.2f}%)\n"
            
            if 'dow' in indicators:
                dow = indicators['dow']
                economic_text += f"â€¢ ë‹¤ìš°ì¡´ìŠ¤: {dow['current_price']:.2f} ({dow['change_pct']:+.2f}%)\n"
            
            economic_text += "\n"
            
            # ì±„ê¶Œ ìˆ˜ìµë¥ 
            if 'us_10yr' in indicators:
                us_10yr = indicators['us_10yr']
                economic_text += f"â€¢ ë¯¸êµ­ 10ë…„ êµ­ì±„ ìˆ˜ìµë¥ : {us_10yr['current_price']:.3f}% ({us_10yr['change_pct']:+.2f}%)\n"
            
            if 'us_2yr' in indicators:
                us_2yr = indicators['us_2yr']
                economic_text += f"â€¢ ë¯¸êµ­ 2ë…„ êµ­ì±„ ìˆ˜ìµë¥ : {us_2yr['current_price']:.3f}% ({us_2yr['change_pct']:+.2f}%)\n"
            
            economic_text += "\n"
            
            # ì›ìì¬
            if 'gold' in indicators:
                gold = indicators['gold']
                economic_text += f"â€¢ ê¸ˆ ê°€ê²©: ${gold['current_price']:.2f} ({gold['change_pct']:+.2f}%)\n"
            
            if 'oil' in indicators:
                oil = indicators['oil']
                economic_text += f"â€¢ ì›ìœ  ê°€ê²©: ${oil['current_price']:.2f} ({oil['change_pct']:+.2f}%)\n"
            
            economic_text += "\n"
            
            # ê¸°íƒ€ ì§€í‘œ
            if 'dollar_index' in indicators:
                dollar = indicators['dollar_index']
                economic_text += f"â€¢ ë‹¬ëŸ¬ ì¸ë±ìŠ¤: {dollar['current_price']:.2f} ({dollar['change_pct']:+.2f}%)\n"
            
            if 'vix' in indicators:
                vix = indicators['vix']
                economic_text += f"â€¢ VIX ê³µí¬ì§€ìˆ˜: {vix['current_price']:.2f} ({vix['change_pct']:+.2f}%)\n"
            
            if 'btc' in indicators:
                btc = indicators['btc']
                economic_text += f"â€¢ ë¹„íŠ¸ì½”ì¸: ${btc['current_price']:,.0f} ({btc['change_pct']:+.2f}%)\n"

            prompt = f"""
    ë‹¤ìŒì€ í˜„ì¬ ì£¼ìš” ê²½ì œì§€í‘œë“¤ì˜ ì‹¤ì‹œê°„ ë°ì´í„°ì…ë‹ˆë‹¤. ì „ë¬¸ ê²½ì œ ë¶„ì„ê°€ ê´€ì ì—ì„œ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”:

    {economic_text}

    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

    ## ğŸŒ ëŒ€ì™¸ ê²½ì œí™˜ê²½ ì¢…í•© ë¶„ì„

    ### 1. **í˜„ì¬ ê²½ì œ ìƒí™© ì§„ë‹¨** (5ì  ë§Œì ìœ¼ë¡œ ì ìˆ˜ ë¶€ì—¬)
    - ì¢…í•© ì ìˆ˜: X/5ì 
    - í•œ ì¤„ ìš”ì•½

    ### 2. **ì£¼ì‹ì‹œì¥ ë¶„ì„**
    - ì£¼ìš” ì§€ìˆ˜ ë™í–¥ ë° ì˜ë¯¸
    - ì‹œì¥ ëª¨ë©˜í…€ í‰ê°€
    - ì„¹í„°ë³„ ì˜í–¥ ì „ë§

    ### 3. **ê¸ˆë¦¬ í™˜ê²½ ë¶„ì„**
    - ìˆ˜ìµë¥  ê³¡ì„  ìƒíƒœ ë° ì˜ë¯¸
    - ì—°ì¤€ ì •ì±… ë°©í–¥ì„± ì¶”ë¡ 
    - ì¥ë‹¨ê¸° ê¸ˆë¦¬ ìŠ¤í”„ë ˆë“œ ë¶„ì„

    ### 4. **ì¸í”Œë ˆì´ì…˜ ë° ì›ìì¬**
    - ê¸ˆ, ì›ìœ  ê°€ê²© ë™í–¥ ë¶„ì„
    - ì¸í”Œë ˆì´ì…˜ ì••ë ¥ ì§„ë‹¨
    - ì›ìì¬ ìˆœí™˜ ì‚¬ì´í´ ìœ„ì¹˜

    ### 5. **ë‹¬ëŸ¬ ë° ì™¸í™˜ í™˜ê²½**
    - ë‹¬ëŸ¬ ê°•ì„¸/ì•½ì„¸ ë°°ê²½
    - ê¸€ë¡œë²Œ ìœ ë™ì„± ìƒí™©
    - ì‹ í¥êµ­ ì˜í–¥ í‰ê°€

    ### 6. **ë¦¬ìŠ¤í¬ ì§€í‘œ ë¶„ì„**
    - VIXë¥¼ í†µí•œ ì‹œì¥ ë¶ˆì•ˆê° ì¸¡ì •
    - ì•ˆì „ìì‚° ì„ í˜¸ë„ ë³€í™”
    - ì‹œìŠ¤í…œ ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ í‰ê°€

    ### 7. **íˆ¬ììë¥¼ ìœ„í•œ ì‹œì‚¬ì **
    - í˜„ì¬ ìƒí™©ì—ì„œì˜ ìì‚°ë°°ë¶„ ë°©í–¥
    - ì£¼ì˜í•´ì•¼ í•  ë¦¬ìŠ¤í¬ ìš”ì¸
    - ê¸°íšŒ ìš”ì¸ ë° íˆ¬ì í…Œë§ˆ

    ### 8. **í–¥í›„ ì „ë§** (1-3ê°œì›”)
    - ì˜ˆìƒë˜ëŠ” ì‹œì¥ ì‹œë‚˜ë¦¬ì˜¤
    - ì£¼ìš” ë³€ê³¡ì  ë° ëª¨ë‹ˆí„°ë§ ì§€í‘œ
    - ì •ì±… ë³€í™” ê°€ëŠ¥ì„±

    ### 9. **ê²°ë¡  ë° íˆ¬ì ê°€ì´ë“œ**
    - í˜„ì¬ ê²½ì œí™˜ê²½ í•œ ì¤„ ìš”ì•½
    - Risk-On / Risk-Off ì¤‘ ì–´ëŠ ìƒí™©ì¸ì§€
    - ì¶”ì²œ íˆ¬ì ì „ëµ (ê³µê²©ì /ì¤‘ë¦½ì /ë°©ì–´ì )

    ê° ì„¹ì…˜ì„ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì‹œê³ , íˆ¬ììê°€ ì‹¤ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
    """

            response = client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ê±°ì‹œê²½ì œ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ê²½ì œì§€í‘œë¥¼ ì¢…í•©í•˜ì—¬ í˜„ì¬ ê²½ì œí™˜ê²½ì„ ì •í™•íˆ ì§„ë‹¨í•˜ê³ , íˆ¬ììì—ê²Œ ì‹¤ìš©ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            analysis = response.choices[0].message.content.strip()
            
            # ì ìˆ˜ ì¶”ì¶œ
            import re
            score_match = re.search(r'ì ìˆ˜[:\s]*(\d+(?:\.\d+)?)[/ì ]', analysis)
            score = float(score_match.group(1)) if score_match else 3.0
            
            # íˆ¬ì í™˜ê²½ ë¶„ë¥˜
            if score >= 4.0:
                environment = "Risk-On (ìœ„í—˜ìì‚° ì„ í˜¸)"
                environment_color = "success"
            elif score >= 3.0:
                environment = "ì¤‘ë¦½ì  (í˜¼ì¬ëœ ì‹ í˜¸)"
                environment_color = "warning"
            else:
                environment = "Risk-Off (ì•ˆì „ìì‚° ì„ í˜¸)"
                environment_color = "error"
            
            return {
                "analysis": analysis,
                "score": score,
                "max_score": 5.0,
                "environment": environment,
                "environment_color": environment_color,
                "success": True
            }
            
        except Exception as e:
            return {"error": f"GPT ê²½ì œë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
    
    @staticmethod
    def get_financial_history(symbol: str) -> Dict:
        """3ê°œë…„ ì¬ë¬´ ì‹¤ì  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            stock = yf.Ticker(symbol)
            financials = stock.financials
            
            if financials.empty:
                return {}
            
            # ìµœê·¼ 3ë…„ ë°ì´í„° ì¶”ì¶œ
            years = financials.columns[:3]  # ìµœì‹  3ê°œë…„
            
            financial_history = {
                'years': [year.strftime('%Y') for year in years],
                'revenue': [],
                'operating_income': [],
                'net_income': []
            }
            
            for year in years:
                # ë§¤ì¶œ (Total Revenue)
                revenue = financials.loc['Total Revenue', year] if 'Total Revenue' in financials.index else 0
                
                # ì˜ì—…ì´ìµ (Operating Income)
                operating_income = financials.loc['Operating Income', year] if 'Operating Income' in financials.index else 0
                
                # ìˆœì´ìµ (Net Income)
                net_income = financials.loc['Net Income', year] if 'Net Income' in financials.index else 0
                
                financial_history['revenue'].append(revenue / 1e9 if revenue else 0)  # 10ì–µ ë‹¨ìœ„
                financial_history['operating_income'].append(operating_income / 1e9 if operating_income else 0)
                financial_history['net_income'].append(net_income / 1e9 if net_income else 0)
            
            return financial_history
            
        except Exception as e:
            st.error(f"ì¬ë¬´ ì‹¤ì  ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {}
    

class BuffettAnalyzer:
    """ë²„í• ìŠ¤íƒ€ì¼ íˆ¬ì ë¶„ì„ í´ë˜ìŠ¤"""
    
    @staticmethod
    def buffett_analysis(financial_metrics: Dict, sentiment_data: Dict) -> Dict:
        """ë²„í• ìŠ¤íƒ€ì¼ íˆ¬ì ë¶„ì„"""
        try:
            score = 0
            max_score = 100
            reasons = []
            
            # ROE í‰ê°€ (25ì )
            roe = financial_metrics.get('roe', 0) * 100 if financial_metrics.get('roe') else 0
            if roe > 15:
                score += 25
                reasons.append(f"âœ… ìš°ìˆ˜í•œ ROE: {roe:.1f}% (ê¸°ì¤€: 15% ì´ìƒ)")
            elif roe > 10:
                score += 15
                reasons.append(f"âš ï¸ ì ì • ROE: {roe:.1f}% (ê¸°ì¤€: 15% ì´ìƒ)")
            else:
                reasons.append(f"âŒ ë‚®ì€ ROE: {roe:.1f}% (ê¸°ì¤€: 15% ì´ìƒ)")
            
            # P/E ë¹„ìœ¨ í‰ê°€ (20ì )
            pe_ratio = financial_metrics.get('pe_ratio', 0)
            if 10 <= pe_ratio <= 20:
                score += 20
                reasons.append(f"âœ… ì ì • P/E ë¹„ìœ¨: {pe_ratio:.1f} (ì„ í˜¸: 10-20)")
            elif pe_ratio > 0:
                score += 10
                reasons.append(f"âš ï¸ P/E ë¹„ìœ¨: {pe_ratio:.1f} (ì„ í˜¸: 10-20)")
            else:
                reasons.append("âŒ P/E ë¹„ìœ¨ ë°ì´í„° ì—†ìŒ")
            
            # ë¶€ì±„ë¹„ìœ¨ í‰ê°€ (20ì )
            debt_to_equity = financial_metrics.get('debt_to_equity', 0)
            if debt_to_equity < 0.3:
                score += 20
                reasons.append(f"âœ… ë‚®ì€ ë¶€ì±„ë¹„ìœ¨: {debt_to_equity:.2f} (ì„ í˜¸: 0.3 ë¯¸ë§Œ)")
            elif debt_to_equity < 0.5:
                score += 10
                reasons.append(f"âš ï¸ ë¶€ì±„ë¹„ìœ¨: {debt_to_equity:.2f} (ì„ í˜¸: 0.3 ë¯¸ë§Œ)")
            else:
                reasons.append(f"âŒ ë†’ì€ ë¶€ì±„ë¹„ìœ¨: {debt_to_equity:.2f} (ì„ í˜¸: 0.3 ë¯¸ë§Œ)")
            
            # ììœ í˜„ê¸ˆíë¦„ í‰ê°€ (15ì )
            fcf = financial_metrics.get('free_cash_flow', 0)
            if fcf > 0:
                score += 15
                reasons.append(f"âœ… ì–‘ì˜ ììœ í˜„ê¸ˆíë¦„: ${fcf:,.0f}")
            else:
                reasons.append("âŒ ìŒì˜ ììœ í˜„ê¸ˆíë¦„")
            
            # ìˆ˜ìµì„± í‰ê°€ (10ì )
            profit_margin = financial_metrics.get('profit_margin', 0) * 100 if financial_metrics.get('profit_margin') else 0
            if profit_margin > 10:
                score += 10
                reasons.append(f"âœ… ìš°ìˆ˜í•œ ìˆ˜ìµì„±: {profit_margin:.1f}% (ì„ í˜¸: 10% ì´ìƒ)")
            elif profit_margin > 5:
                score += 5
                reasons.append(f"âš ï¸ ì ì • ìˆ˜ìµì„±: {profit_margin:.1f}% (ì„ í˜¸: 10% ì´ìƒ)")
            else:
                reasons.append(f"âŒ ë‚®ì€ ìˆ˜ìµì„±: {profit_margin:.1f}% (ì„ í˜¸: 10% ì´ìƒ)")
            
            # ê°ì„± ë¶„ì„ ë°˜ì˜ (10ì )
            if sentiment_data:
                sentiment_summary = sentiment_data.get('summary', {})
                positive_ratio = sentiment_summary.get('positive', 0) / max(sentiment_summary.get('total', 1), 1)
                if positive_ratio > 0.6:
                    score += 10
                    reasons.append(f"âœ… ê¸ì •ì  ì‹œì¥ ê°ì„±: {positive_ratio:.1%}")
                elif positive_ratio > 0.4:
                    score += 5
                    reasons.append(f"âš ï¸ ì¤‘ë¦½ì  ì‹œì¥ ê°ì„±: {positive_ratio:.1%}")
                else:
                    reasons.append(f"âŒ ë¶€ì •ì  ì‹œì¥ ê°ì„±: {positive_ratio:.1%}")
            
            # íˆ¬ì ë“±ê¸‰ ê²°ì •
            if score >= 80:
                grade = "BUY"
                grade_color = "buy-signal"
                recommendation = "ğŸš€ ê°•ë ¥ ë§¤ìˆ˜ ì¶”ì²œ: ë²„í•ì˜ íˆ¬ì ê¸°ì¤€ì„ ëŒ€ë¶€ë¶„ ì¶©ì¡±í•©ë‹ˆë‹¤."
            elif score >= 60:
                grade = "HOLD"
                grade_color = "hold-signal"
                recommendation = "ğŸ“Š ë³´ìœ  ê¶Œì¥: ì¼ë¶€ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ë‚˜ ì‹ ì¤‘í•œ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            else:
                grade = "SELL"
                grade_color = "sell-signal"
                recommendation = "âš ï¸ íˆ¬ì ë¹„ì¶”ì²œ: ë²„í•ì˜ íˆ¬ì ê¸°ì¤€ì— ë¯¸ë‹¬í•©ë‹ˆë‹¤."
            
            return {
                'score': score,
                'max_score': max_score,
                'grade': grade,
                'grade_color': grade_color,
                'recommendation': recommendation,
                'reasons': reasons
            }
            
        except Exception as e:
            st.error(f"ë²„í• ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {}

class YouTubeAnalyzer:
    """ìœ íŠœë¸Œ ì±„ë„ ê²€ìƒ‰ ë° ì˜ìƒ ìš”ì•½ í´ë˜ìŠ¤ (í–¥ìƒëœ ë²„ì „)"""
    
    @staticmethod
    @st.cache_data(ttl=3600)  # 1ì‹œê°„ ìºì‹±
    def search_youtube_videos(query: str, max_results: int = 50, sort_order: str = 'relevance') -> List[Dict]:
        """ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ (í–¥ìƒëœ ë²„ì „)"""
        try:
            # ì •ë ¬ ì˜µì…˜ì— ë”°ë¥¸ URL íŒŒë¼ë¯¸í„° ì„¤ì •
            sort_params = {
                'relevance': '',  # ê¸°ë³¸ê°’
                'upload_date': '&sp=CAI%253D',  # ìµœì‹ ìˆœ
                'view_count': '&sp=CAM%253D',   # ì¡°íšŒìˆ˜ìˆœ  
                'rating': '&sp=CAE%253D'        # í‰ì ìˆœ (ì¢‹ì•„ìš” ê¸°ì¤€)
            }
            
            sort_param = sort_params.get(sort_order, '')
            search_url = f"https://www.youtube.com/results?search_query={quote(query)}{sort_param}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(search_url, headers=headers, timeout=15)
            response.raise_for_status()
            
            video_results = []
            
            # JavaScriptë¡œ ë Œë”ë§ëœ ë°ì´í„° ì¶”ì¶œ
            pattern = r'var ytInitialData = ({.*?});'
            match = re.search(pattern, response.text)
            
            if match:
                try:
                    data = json.loads(match.group(1))
                    
                    # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
                    contents = data.get('contents', {}).get('twoColumnSearchResultsRenderer', {}).get('primaryContents', {}).get('sectionListRenderer', {}).get('contents', [])
                    
                    for content in contents:
                        items = content.get('itemSectionRenderer', {}).get('contents', [])
                        
                        for item in items:
                            if 'videoRenderer' in item:
                                video = item['videoRenderer']
                                
                                # ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
                                video_id = video.get('videoId', '')
                                title = video.get('title', {}).get('runs', [{}])[0].get('text', '')
                                
                                # ì±„ë„ ì •ë³´
                                channel_info = video.get('ownerText', {}).get('runs', [{}])[0]
                                channel_name = channel_info.get('text', '')
                                
                                # ì¡°íšŒìˆ˜ ì •ë³´ ë° ìˆ«ì ì¶”ì¶œ
                                view_count_text = ''
                                view_count_num = 0
                                if 'viewCountText' in video:
                                    view_count_text = video['viewCountText'].get('simpleText', '')
                                    # ì¡°íšŒìˆ˜ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: "1.2M views" -> 1200000)
                                    view_count_num = YouTubeAnalyzer._parse_view_count(view_count_text)
                                
                                # ì—…ë¡œë“œ ì‹œê°„ ë° íŒŒì‹±
                                published_text = ''
                                published_days_ago = 0
                                if 'publishedTimeText' in video:
                                    published_text = video['publishedTimeText'].get('simpleText', '')
                                    published_days_ago = YouTubeAnalyzer._parse_published_time(published_text)
                                
                                # ì¬ìƒ ì‹œê°„ ë° ì´ˆ ë‹¨ìœ„ ë³€í™˜
                                duration = ''
                                duration_seconds = 0
                                if 'lengthText' in video:
                                    duration = video['lengthText'].get('simpleText', '')
                                    duration_seconds = YouTubeAnalyzer._parse_duration(duration)
                                
                                # ì¸ë„¤ì¼ URL
                                thumbnail_url = f"https://img.youtube.com/vi/{video_id}/maxresdefault.jpg"
                                
                                # ì¢‹ì•„ìš”/ì‹«ì–´ìš” ì •ë³´ (YouTube API ì œí•œìœ¼ë¡œ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
                                likes_count = 0  # ì‹¤ì œë¡œëŠ” ì¶”ì¶œí•˜ê¸° ì–´ë ¤ì›€
                                
                                video_results.append({
                                    'video_id': video_id,
                                    'title': title,
                                    'channel_name': channel_name,
                                    'view_count': view_count_text,
                                    'view_count_num': view_count_num,  # í•„í„°ë§ìš© ìˆ«ìê°’
                                    'published_time': published_text,
                                    'published_days_ago': published_days_ago,  # í•„í„°ë§ìš© ìˆ«ìê°’
                                    'duration': duration,
                                    'duration_seconds': duration_seconds,  # í•„í„°ë§ìš© ìˆ«ìê°’
                                    'likes_count': likes_count,  # ì¶”í›„ êµ¬í˜„ ê°€ëŠ¥
                                    'thumbnail_url': thumbnail_url,
                                    'video_url': f"https://www.youtube.com/watch?v={video_id}"
                                })
                                
                                if len(video_results) >= max_results:
                                    break
                        
                        if len(video_results) >= max_results:
                            break
                    
                except json.JSONDecodeError:
                    pass
            
            # ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ ë”ë¯¸ ë°ì´í„°ë¡œ ë³´ì™„ (ë°ëª¨ìš©)
            if len(video_results) < 10:
                demo_data = YouTubeAnalyzer._generate_demo_videos(query, max_results - len(video_results))
                video_results.extend(demo_data)
            
            return video_results[:max_results]
            
        except Exception as e:
            st.error(f"ìœ íŠœë¸Œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            # ì „ì²´ ì‹¤íŒ¨ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
            return YouTubeAnalyzer._generate_demo_videos(query, min(max_results, 20))
    
    @staticmethod
    def _parse_view_count(view_text: str) -> int:
        """ì¡°íšŒìˆ˜ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜"""
        try:
            if not view_text:
                return 0
            
            # "1.2M views" -> 1200000
            import re
            numbers = re.findall(r'[\d.]+', view_text.lower())
            if not numbers:
                return 0
            
            num_str = numbers[0]
            multiplier = 1
            
            if 'k' in view_text.lower():
                multiplier = 1000
            elif 'm' in view_text.lower():
                multiplier = 1000000
            elif 'b' in view_text.lower():
                multiplier = 1000000000
            
            return int(float(num_str) * multiplier)
        except:
            return 0
    
    @staticmethod
    def _parse_published_time(time_text: str) -> int:
        """ì—…ë¡œë“œ ì‹œê°„ì„ ì¼ ë‹¨ìœ„ë¡œ ë³€í™˜"""
        try:
            if not time_text:
                return 999999  # ë§¤ìš° ì˜¤ë˜ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
            
            import re
            
            # "2 days ago", "1 week ago", "3 months ago" ë“± íŒŒì‹±
            if 'hour' in time_text or 'ì‹œê°„' in time_text:
                hours = re.findall(r'\d+', time_text)
                return float(hours[0]) / 24 if hours else 0
            elif 'day' in time_text or 'ì¼' in time_text:
                days = re.findall(r'\d+', time_text)
                return int(days[0]) if days else 1
            elif 'week' in time_text or 'ì£¼' in time_text:
                weeks = re.findall(r'\d+', time_text)
                return int(weeks[0]) * 7 if weeks else 7
            elif 'month' in time_text or 'ê°œì›”' in time_text or 'ë‹¬' in time_text:
                months = re.findall(r'\d+', time_text)
                return int(months[0]) * 30 if months else 30
            elif 'year' in time_text or 'ë…„' in time_text:
                years = re.findall(r'\d+', time_text)
                return int(years[0]) * 365 if years else 365
            else:
                return 1  # ê¸°ë³¸ê°’
        except:
            return 999999
    
    @staticmethod
    def _parse_duration(duration_text: str) -> int:
        """ì¬ìƒì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜"""
        try:
            if not duration_text:
                return 0
            
            # "12:34" -> 754ì´ˆ, "1:23:45" -> 5025ì´ˆ
            parts = duration_text.split(':')
            total_seconds = 0
            
            if len(parts) == 2:  # MM:SS
                total_seconds = int(parts[0]) * 60 + int(parts[1])
            elif len(parts) == 3:  # HH:MM:SS
                total_seconds = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
            else:
                return 0
            
            return total_seconds
        except:
            return 0
    
    @staticmethod
    def _generate_demo_videos(query: str, count: int) -> List[Dict]:
        """ë°ëª¨ìš© ì˜ìƒ ë°ì´í„° ìƒì„±"""
        import random
        
        demo_videos = []
        base_channels = [
            "íˆ¬ìì™•", "ì£¼ì‹ì—°êµ¬ì†Œ", "ê²½ì œë¶„ì„ê°€", "ì¬í…Œí¬TV", "íˆ¬ìì˜ì‹ ",
            "Financial Wisdom", "Stock Analysis Pro", "Investment Guru", "Market Insider", "Trading Master"
        ]
        
        for i in range(count):
            random_views = random.randint(1000, 5000000)
            random_days = random.randint(0, 365)
            random_duration = random.randint(300, 3600)  # 5ë¶„~1ì‹œê°„
            
            demo_videos.append({
                'video_id': f'demo_{i}_{hash(query) % 10000}',
                'title': f'{query} ê´€ë ¨ íˆ¬ì ë¶„ì„ ì˜ìƒ {i+1}',
                'channel_name': random.choice(base_channels),
                'view_count': f'{random_views:,}íšŒ ì¡°íšŒ',
                'view_count_num': random_views,
                'published_time': f'{random_days}ì¼ ì „',
                'published_days_ago': random_days,
                'duration': f'{random_duration//60}:{random_duration%60:02d}',
                'duration_seconds': random_duration,
                'likes_count': random.randint(10, random_views//100),
                'thumbnail_url': 'https://img.youtube.com/vi/dQw4w9WgXcQ/maxresdefault.jpg',
                'video_url': 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'
            })
        
        return demo_videos
    
    @staticmethod
    def filter_videos(videos: List[Dict], 
                     min_views: int = 0, 
                     max_days_ago: int = 999999,
                     min_duration: int = 0,
                     max_duration: int = 999999,
                     sort_by: str = 'relevance') -> List[Dict]:
        """ì˜ìƒ í•„í„°ë§ ë° ì •ë ¬"""
        try:
            # í•„í„°ë§
            filtered = []
            for video in videos:
                if (video['view_count_num'] >= min_views and
                    video['published_days_ago'] <= max_days_ago and
                    min_duration <= video['duration_seconds'] <= max_duration):
                    filtered.append(video)
            
            # ì •ë ¬
            if sort_by == 'view_count':
                filtered.sort(key=lambda x: x['view_count_num'], reverse=True)
            elif sort_by == 'upload_date':
                filtered.sort(key=lambda x: x['published_days_ago'])
            elif sort_by == 'duration':
                filtered.sort(key=lambda x: x['duration_seconds'], reverse=True)
            elif sort_by == 'likes':
                filtered.sort(key=lambda x: x['likes_count'], reverse=True)
            # 'relevance'ëŠ” ê¸°ë³¸ ìˆœì„œ ìœ ì§€
            
            return filtered
        except Exception as e:
            st.error(f"í•„í„°ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return videos

    # ê¸°ì¡´ ë©”ì„œë“œë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    @staticmethod
    def get_video_transcript(video_id: str) -> str:
        """ìœ íŠœë¸Œ ì˜ìƒ ìë§‰ ì¶”ì¶œ (ì‹¤ì œ êµ¬í˜„)"""
        try:
            # youtube-transcript-api ì„¤ì¹˜ í™•ì¸ ë° ì‹¤ì œ ìë§‰ ì¶”ì¶œ
            try:
                from youtube_transcript_api import YouTubeTranscriptApi
                from youtube_transcript_api.formatters import TextFormatter
                
                # ìë§‰ ì–¸ì–´ ìš°ì„ ìˆœìœ„: í•œêµ­ì–´ â†’ ì˜ì–´ â†’ ìë™ìƒì„± ìë§‰
                languages_to_try = [
                    ['ko'],           # í•œêµ­ì–´
                    ['en'],           # ì˜ì–´
                    ['ko', 'en'],     # í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´
                    None              # ìë™ ìƒì„± ìë§‰ í¬í•¨
                ]
                
                transcript_text = None
                
                for languages in languages_to_try:
                    try:
                        if languages is None:
                            # ìë™ ìƒì„± ìë§‰ í¬í•¨í•´ì„œ ì‹œë„
                            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
                            
                            # ìˆ˜ë™ ìë§‰ ìš°ì„  ì‹œë„
                            for transcript in transcript_list:
                                if not transcript.is_generated:
                                    transcript_data = transcript.fetch()
                                    break
                            else:
                                # ìˆ˜ë™ ìë§‰ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„± ìë§‰ ì‚¬ìš©
                                for transcript in transcript_list:
                                    if transcript.is_generated:
                                        transcript_data = transcript.fetch()
                                        break
                                else:
                                    continue
                        else:
                            # íŠ¹ì • ì–¸ì–´ë¡œ ì‹œë„
                            transcript_data = YouTubeTranscriptApi.get_transcript(
                                video_id, 
                                languages=languages
                            )
                        
                        # í…ìŠ¤íŠ¸ í¬ë§·í„°ë¡œ ì •ë¦¬
                        formatter = TextFormatter()
                        transcript_text = formatter.format_transcript(transcript_data)
                        
                        # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ
                        break
                        
                    except Exception:
                        # í˜„ì¬ ì–¸ì–´/ë°©ë²•ìœ¼ë¡œ ì‹¤íŒ¨í•˜ë©´ ë‹¤ìŒ ì‹œë„
                        continue
                
                if transcript_text:
                    # ìë§‰ í…ìŠ¤íŠ¸ ì •ë¦¬
                    cleaned_text = transcript_text.strip()
                    
                    # ë„ˆë¬´ ì§§ì€ ìë§‰ì€ ìœ íš¨í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨
                    if len(cleaned_text) < 50:
                        raise Exception("ìë§‰ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
                    
                    # ìë§‰ í’ˆì§ˆ ì •ë³´ ì¶”ê°€
                    quality_info = ""
                    if len(cleaned_text) > 5000:
                        quality_info = "[ê³ í’ˆì§ˆ ìë§‰] "
                    elif len(cleaned_text) > 1000:
                        quality_info = "[í‘œì¤€ ìë§‰] "
                    else:
                        quality_info = "[ê°„ë‹¨í•œ ìë§‰] "
                    
                    return quality_info + cleaned_text
                else:
                    raise Exception("ëª¨ë“  ì–¸ì–´ì—ì„œ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨")
                    
            except ImportError:
                # youtube-transcript-apiê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°
                return f"""
[ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜] youtube-transcript-apiê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

ì‹¤ì œ ìë§‰ì„ ê°€ì ¸ì˜¤ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:
pip install youtube-transcript-api

í˜„ì¬ëŠ” ë°ëª¨ ë°ì´í„°ë¡œ ë¶„ì„ë©ë‹ˆë‹¤:

ì´ ì˜ìƒì—ì„œëŠ” {video_id}ì— ëŒ€í•œ íˆ¬ì ë¶„ì„ì„ ë‹¤ë£¹ë‹ˆë‹¤. 

ì£¼ìš” ë‚´ìš©:
1. í˜„ì¬ ì‹œì¥ ìƒí™© ë° íŠ¸ë Œë“œ ë¶„ì„
2. ê¸°ì—…ì˜ ì¬ë¬´ ì„±ê³¼ ë° ê±´ì „ì„± ê²€í†   
3. í–¥í›„ ì„±ì¥ ì „ë§ ë° ì ì¬ì  ë¦¬ìŠ¤í¬ ìš”ì¸
4. í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ë° íˆ¬ì ì „ëµ ì œì•ˆ

ì „ë¬¸ê°€ ì˜ê²¬:
- ì¥ê¸°ì  ê´€ì ì—ì„œ ê¸ì •ì ì¸ ì„±ì¥ ì „ë§
- ë‹¨ê¸°ì ìœ¼ë¡œëŠ” ì‹œì¥ ë³€ë™ì„±ì— ì£¼ì˜ í•„ìš”
- ë¶„ì‚° íˆ¬ìë¥¼ í†µí•œ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê¶Œì¥
- ì •ê¸°ì ì¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë·° ë° ì¡°ì • í•„ìš”

íˆ¬ì ê¶Œê³ ì‚¬í•­:
- ê°œì¸ì˜ íˆ¬ì ì„±í–¥ê³¼ ëª©í‘œë¥¼ ê³ ë ¤í•œ ì‹ ì¤‘í•œ íŒë‹¨
- ì¶©ë¶„í•œ ìë£Œ ì¡°ì‚¬ ë° ì „ë¬¸ê°€ ìƒë‹´ ê¶Œì¥
- íˆ¬ì ì›ê¸ˆ ì†ì‹¤ ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì¸ì§€ í•„ìš”

ê²°ë¡ :
ì²´ê³„ì ì¸ ë¶„ì„ê³¼ ì‹ ì¤‘í•œ ì ‘ê·¼ì„ í†µí•´ í˜„ëª…í•œ íˆ¬ì ê²°ì •ì„ ë‚´ë¦¬ì‹œê¸° ë°”ëë‹ˆë‹¤.
"""
                
        except Exception as e:
            # ìë§‰ ì¶”ì¶œ ì™„ì „ ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„°
            error_msg = str(e)
            
            # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë“¤ì— ëŒ€í•œ ì‚¬ìš©ì ì¹œí™”ì  ì„¤ëª…
            if "TranscriptsDisabled" in error_msg:
                reason = "ì´ ì˜ìƒì€ ìë§‰ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            elif "NoTranscriptFound" in error_msg:
                reason = "ì´ ì˜ìƒì—ëŠ” ìë§‰ì´ ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            elif "VideoUnavailable" in error_msg:
                reason = "ì˜ìƒì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¹„ê³µê°œ ë˜ëŠ” ì‚­ì œë¨)"
            elif "TooManyRequests" in error_msg:
                reason = "YouTube API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            else:
                reason = f"ìë§‰ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_msg}"
            
            return f"""
[ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨] {reason}

ëŒ€ì‹  ì˜ìƒ ì •ë³´ ê¸°ë°˜ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤:

ì˜ìƒ ID: {video_id}

ë¶„ì„ ë°©í–¥ì„±:
1. ì˜ìƒ ì œëª©ê³¼ ì±„ë„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë‚´ìš© ì¶”ì •
2. ìœ ì‚¬í•œ íˆ¬ì ë¶„ì„ ì˜ìƒë“¤ì˜ ì¼ë°˜ì ì¸ íŒ¨í„´ ë¶„ì„
3. í˜„ì¬ ì‹œì¥ ìƒí™©ì„ ê³ ë ¤í•œ íˆ¬ì ì‹œì‚¬ì  ë„ì¶œ

ì£¼ì˜ì‚¬í•­:
- ì‹¤ì œ ì˜ìƒ ë‚´ìš©ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
- ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì§ì ‘ ì˜ìƒ ì‹œì²­ ê¶Œì¥
- íˆ¬ì ê²°ì •ì€ ì—¬ëŸ¬ ì†ŒìŠ¤ë¥¼ ì¢…í•©í•˜ì—¬ íŒë‹¨ í•„ìš”

ê¶Œì¥ì‚¬í•­:
ì˜ìƒ ë§í¬ë¥¼ í†µí•´ ì§ì ‘ ì‹œì²­í•˜ì‹œê±°ë‚˜, ìë§‰ì´ ì œê³µë˜ëŠ” ë‹¤ë¥¸ ì˜ìƒì„ ì„ íƒí•´ë³´ì„¸ìš”.
"""
    
    @staticmethod
    def summarize_video_with_gpt(transcript: str, video_title: str, openai_api_key: str) -> Dict:
        """GPTë¥¼ ì´ìš©í•œ ì˜ìƒ ìš”ì•½"""
        try:
            if not openai_api_key:
                return {"error": "OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
            
            from openai import OpenAI
            client = OpenAI(api_key=openai_api_key)
            
            prompt = f"""
ë‹¤ìŒì€ "{video_title}" ìœ íŠœë¸Œ ì˜ìƒì˜ ì „ì²´ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤. ì´ë¥¼ íˆ¬ìì ê´€ì ì—ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ì˜ìƒ ë‚´ìš©:
{transcript[:3000]}  # í† í° ì œí•œì„ ìœ„í•´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

1. **í•µì‹¬ ë‚´ìš© ìš”ì•½** (3-4ì¤„)
2. **ì£¼ìš” íˆ¬ì í¬ì¸íŠ¸** (3ê°œ)
3. **ì–¸ê¸‰ëœ ë¦¬ìŠ¤í¬** (ìˆë‹¤ë©´)
4. **íˆ¬ììë¥¼ ìœ„í•œ í•µì‹¬ ì‹œì‚¬ì ** (2-3ì¤„)
5. **ì¶”ì²œ ì—¬ë¶€** (ì¶”ì²œ/ë³´ë¥˜/ë¹„ì¶”ì²œ ì¤‘ í•˜ë‚˜ì™€ ì´ìœ )

íˆ¬ì ì „ë¬¸ê°€ ê´€ì ì—ì„œ ê°ê´€ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""

            response = client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. ìœ íŠœë¸Œ ì˜ìƒ ë‚´ìš©ì„ íˆ¬ìì ê´€ì ì—ì„œ ìš”ì•½í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.3
            )
            
            summary = response.choices[0].message.content.strip()
            
            return {
                "summary": summary,
                "success": True
            }
            
        except Exception as e:
            return {"error": f"GPT ìš”ì•½ ì‹¤íŒ¨: {str(e)}"}

    
def create_stock_chart(data: pd.DataFrame, forecast: pd.DataFrame, symbol: str):
    """ì£¼ê°€ ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # ì‹¤ì œ ì£¼ê°€
    fig.add_trace(go.Scatter(
        x=data.index,
        y=data['Close'],
        mode='lines',
        name='ì‹¤ì œ ì£¼ê°€',
        line=dict(color='blue', width=2)
    ))
    
    if not forecast.empty:
        # ì˜ˆì¸¡ ì£¼ê°€
        fig.add_trace(go.Scatter(
            x=forecast['ds'],
            y=forecast['yhat'],
            mode='lines',
            name='ì˜ˆì¸¡ ì£¼ê°€',
            line=dict(color='red', width=2, dash='dash')
        ))
        
        # ì‹ ë¢°êµ¬ê°„
        if 'yhat_lower' in forecast.columns:
            fig.add_trace(go.Scatter(
                x=forecast['ds'],
                y=forecast['yhat_upper'],
                fill=None,
                mode='lines',
                line_color='rgba(0,0,0,0)',
                showlegend=False
            ))
            
            fig.add_trace(go.Scatter(
                x=forecast['ds'],
                y=forecast['yhat_lower'],
                fill='tonexty',
                mode='lines',
                line_color='rgba(0,0,0,0)',
                name='ì‹ ë¢°êµ¬ê°„',
                fillcolor='rgba(255,0,0,0.2)'
            ))
    
    fig.update_layout(
        title=f'{symbol} ì£¼ê°€ ì˜ˆì¸¡',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='ì£¼ê°€ ($)',
        hovermode='x unified',
        height=500
    )
    
    return fig


def create_sentiment_chart(sentiment_data: Dict):
    """ê°ì„± ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
    if not sentiment_data:
        return go.Figure()
    
    summary = sentiment_data.get('summary', {})
    
    fig = go.Figure(data=[
        go.Bar(
            x=['Positive', 'Neutral', 'Negative'],
            y=[summary.get('positive', 0), summary.get('neutral', 0), summary.get('negative', 0)],
            marker_color=['green', 'gray', 'red']
        )
    ])
    
    fig.update_layout(
        title='ë‰´ìŠ¤ ê°ì„± ë¶„ì„',
        xaxis_title='ê°ì„±',
        yaxis_title='ê¸°ì‚¬ ìˆ˜',
        height=400
    )
    
    return fig


def create_financial_metrics_chart(metrics: Dict):
    """ì¬ë¬´ ì§€í‘œ ì°¨íŠ¸ ìƒì„±"""
    if not metrics:
        return go.Figure()
    
    # ì£¼ìš” ì§€í‘œë§Œ ì„ íƒ
    key_metrics = {
        'ROE (%)': metrics.get('roe', 0) * 100,
        'P/E Ratio': metrics.get('pe_ratio', 0),
        'Debt/Equity': metrics.get('debt_to_equity', 0),
        'Profit Margin (%)': metrics.get('profit_margin', 0) * 100,
        'Current Ratio': metrics.get('current_ratio', 0)
    }
    
    fig = go.Figure(data=[
        go.Bar(
            x=list(key_metrics.keys()),
            y=list(key_metrics.values()),
            marker_color='lightblue'
        )
    ])
    
    fig.update_layout(
        title='ì£¼ìš” ì¬ë¬´ ì§€í‘œ',
        xaxis_title='ì§€í‘œ',
        yaxis_title='ê°’',
        height=400
    )
    
    return fig


def create_financial_history_chart(financial_history: Dict):
    """3ê°œë…„ ì¬ë¬´ ì‹¤ì  ì°¨íŠ¸ ìƒì„±"""
    if not financial_history or not financial_history.get('years'):
        return go.Figure()
    
    years = financial_history['years']
    
    fig = go.Figure()
    
    # ë§¤ì¶œ
    fig.add_trace(go.Bar(
        name='ë§¤ì¶œ',
        x=years,
        y=financial_history['revenue'],
        marker_color='lightblue'
    ))
    
    # ì˜ì—…ì´ìµ
    fig.add_trace(go.Bar(
        name='ì˜ì—…ì´ìµ',
        x=years,
        y=financial_history['operating_income'],
        marker_color='lightgreen'
    ))
    
    # ìˆœì´ìµ
    fig.add_trace(go.Bar(
        name='ìˆœì´ìµ',
        x=years,
        y=financial_history['net_income'],
        marker_color='lightcoral'
    ))
    
    fig.update_layout(
        title='ìµœê·¼ 3ê°œë…„ ì¬ë¬´ ì‹¤ì  (ë‹¨ìœ„: 10ì–µ ë‹¬ëŸ¬)',
        xaxis_title='ì—°ë„',
        yaxis_title='ê¸ˆì•¡ (Billions $)',
        barmode='group',
        height=400
    )
    
    return fig


def create_economic_indicators_dashboard(indicators: Dict):
    """ê²½ì œì§€í‘œ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    if not indicators:
        return {}
    
    charts = {}
    
    # ì£¼ìš” ì§€ìˆ˜ë“¤ ì°¨íŠ¸
    major_indices = ['sp500', 'nasdaq', 'dow']
    if any(idx in indicators for idx in major_indices):
        fig_indices = go.Figure()
        
        for idx in major_indices:
            if idx in indicators:
                data = indicators[idx]['data']
                name = indicators[idx]['name']
                
                # ì •ê·œí™” (ì²« ë²ˆì§¸ ê°’ì„ 100ìœ¼ë¡œ)
                normalized_data = (data['Close'] / data['Close'].iloc[0]) * 100
                
                fig_indices.add_trace(go.Scatter(
                    x=data.index,
                    y=normalized_data,
                    mode='lines',
                    name=name,
                    line=dict(width=2)
                ))
        
        fig_indices.update_layout(
            title='ì£¼ìš” ì£¼ì‹ ì§€ìˆ˜ ì¶”ì´ (ì •ê·œí™”, ê¸°ì¤€ì =100)',
            xaxis_title='ë‚ ì§œ',
            yaxis_title='ì •ê·œí™”ëœ ì§€ìˆ˜',
            height=400
        )
        
        charts['indices'] = fig_indices
    
    # ê¸ˆë¦¬ ì°¨íŠ¸
    bond_yields = ['us_10yr', 'us_2yr']
    if any(bond in indicators for bond in bond_yields):
        fig_bonds = go.Figure()
        
        for bond in bond_yields:
            if bond in indicators:
                data = indicators[bond]['data']
                name = '10ë…„ êµ­ì±„' if bond == 'us_10yr' else '2ë…„ êµ­ì±„'
                
                fig_bonds.add_trace(go.Scatter(
                    x=data.index,
                    y=data['Close'],
                    mode='lines',
                    name=name,
                    line=dict(width=2)
                ))
        
        fig_bonds.update_layout(
            title='ë¯¸êµ­ êµ­ì±„ ìˆ˜ìµë¥  ì¶”ì´',
            xaxis_title='ë‚ ì§œ',
            yaxis_title='ìˆ˜ìµë¥  (%)',
            height=400
        )
        
        charts['bonds'] = fig_bonds
    
    # ì›ìì¬ ì°¨íŠ¸
    commodities = ['gold', 'oil']
    if any(comm in indicators for comm in commodities):
        fig_commodities = make_subplots(
            rows=1, cols=2,
            subplot_titles=('ê¸ˆ ê°€ê²©', 'ì›ìœ  ê°€ê²©'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        if 'gold' in indicators:
            gold_data = indicators['gold']['data']
            fig_commodities.add_trace(
                go.Scatter(x=gold_data.index, y=gold_data['Close'],
                          mode='lines', name='ê¸ˆ', line=dict(color='gold')),
                row=1, col=1
            )
        
        if 'oil' in indicators:
            oil_data = indicators['oil']['data']
            fig_commodities.add_trace(
                go.Scatter(x=oil_data.index, y=oil_data['Close'],
                          mode='lines', name='ì›ìœ ', line=dict(color='black')),
                row=1, col=2
            )
        
        fig_commodities.update_layout(height=400, title_text="ì›ìì¬ ê°€ê²© ì¶”ì´")
        charts['commodities'] = fig_commodities
    
    return charts

class GoogleTrendsAnalyzer:
    """êµ¬ê¸€ íŠ¸ë Œë“œ ë¶„ì„ í´ë˜ìŠ¤"""

    @staticmethod
    def _safe_create_pytrends():
        """ì•ˆì „í•œ pytrends ê°ì²´ ìƒì„±"""
        try:
            # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹œë„
            pytrends = TrendReq()
            return pytrends, None
        except Exception as e1:
            try:
                # ìµœì†Œ ì„¤ì •ìœ¼ë¡œ ì‹œë„
                pytrends = TrendReq(hl='en-US', tz=360)
                return pytrends, None
            except Exception as e2:
                try:
                    # ë” ê°„ë‹¨í•œ ì„¤ì •ìœ¼ë¡œ ì‹œë„
                    pytrends = TrendReq(hl='en', tz=0)
                    return pytrends, None
                except Exception as e3:
                    return None, f"ëª¨ë“  ì´ˆê¸°í™” ë°©ë²• ì‹¤íŒ¨: {str(e3)}"
    
    @staticmethod
    @st.cache_data(ttl=1800)  # 30ë¶„ ìºì‹± (ë” ì§§ê²Œ)
    def get_trends_data(keywords: List[str], timeframe: str = '12-m', geo: str = '') -> Dict:
        """êµ¬ê¸€ íŠ¸ë Œë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° - ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬"""
        
        # ì…ë ¥ ê²€ì¦
        if not keywords:
            return {"error": "ê²€ìƒ‰í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        # í‚¤ì›Œë“œ ì •ë¦¬
        clean_keywords = []
        for k in keywords:
            if k and isinstance(k, str) and k.strip():
                clean_keywords.append(k.strip())
        
        if not clean_keywords:
            return {"error": "ìœ íš¨í•œ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        clean_keywords = clean_keywords[:3]  # ìµœëŒ€ 3ê°œë¡œ ì œí•œ (ì•ˆì •ì„±)
        
        st.info(f"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(clean_keywords)}")
        st.info(f"ğŸ“… ê¸°ê°„: {timeframe}, ğŸŒ ì§€ì—­: {geo if geo else 'ì „ ì„¸ê³„'}")
        
        # pytrends ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸
        try:
            from pytrends.request import TrendReq
        except ImportError:
            return {
                "error": "pytrends ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "suggestions": [
                    "í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰:",
                    "pip install pytrends",
                    "ë˜ëŠ”",
                    "pip install --upgrade pytrends"
                ]
            }
        
        # pytrends ê°ì²´ ìƒì„± ì‹œë„
        st.info("ğŸ”§ pytrends ì´ˆê¸°í™” ì¤‘...")
        pytrends, error = GoogleTrendsAnalyzer._safe_create_pytrends()
        
        if pytrends is None:
            return {
                "error": f"pytrends ì´ˆê¸°í™” ì‹¤íŒ¨: {error}",
                "suggestions": [
                    "pytrends ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¬ì„¤ì¹˜:",
                    "pip uninstall pytrends",
                    "pip install pytrends",
                    "ë˜ëŠ” ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„"
                ]
            }
        
        st.success("âœ… pytrends ì´ˆê¸°í™” ì„±ê³µ!")
        
        # ê²°ê³¼ ì €ì¥ìš©
        result = {
            'interest_over_time': None,
            'interest_by_region': None,
            'related_queries': None,
            'related_topics': None,
            'keywords': clean_keywords,
            'timeframe': timeframe
        }
        
        # ë°ì´í„° ìˆ˜ì§‘ ì‹œë„
        success_count = 0
        
        # 1. ì‹œê°„ë³„ ê´€ì‹¬ë„ ë°ì´í„° (ê°€ì¥ ì¤‘ìš”)
        st.info("ğŸ“Š ì‹œê°„ë³„ íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        try:
            # í˜ì´ë¡œë“œ ë¹Œë“œ
            pytrends.build_payload(
                clean_keywords, 
                cat=0, 
                timeframe=timeframe, 
                geo=geo, 
                gprop=''
            )
            
            # ì‹œê°„ë³„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            interest_over_time = pytrends.interest_over_time()
            
            if (interest_over_time is not None and 
                hasattr(interest_over_time, 'empty') and 
                not interest_over_time.empty):
                
                # 'isPartial' ì»¬ëŸ¼ ì œê±°
                if 'isPartial' in interest_over_time.columns:
                    interest_over_time = interest_over_time.drop('isPartial', axis=1)
                
                # ì‹¤ì œ ë°ì´í„° ìˆëŠ”ì§€ í™•ì¸
                data_sum = 0
                for col in interest_over_time.columns:
                    if col in clean_keywords:
                        data_sum += interest_over_time[col].sum()
                
                if data_sum > 0:
                    result['interest_over_time'] = interest_over_time
                    success_count += 1
                    st.success(f"âœ… ì‹œê°„ë³„ íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({len(interest_over_time)}ê°œ í¬ì¸íŠ¸)")
                else:
                    st.warning("âš ï¸ ì‹œê°„ë³„ íŠ¸ë Œë“œ ë°ì´í„°ì— ê²€ìƒ‰ëŸ‰ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ ì‹œê°„ë³„ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            error_msg = str(e).lower()
            if "429" in error_msg or "rate limit" in error_msg:
                st.error("âŒ ìš”ì²­ í•œë„ ì´ˆê³¼ - 5ë¶„ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            elif "timeout" in error_msg:
                st.error("âŒ ìš”ì²­ ì‹œê°„ ì´ˆê³¼ - ë„¤íŠ¸ì›Œí¬ í™•ì¸ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.")
            else:
                st.error(f"âŒ ì‹œê°„ë³„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        
        # 2. ì§€ì—­ë³„ ê´€ì‹¬ë„ ë°ì´í„° (ì„ íƒì‚¬í•­)
        if success_count > 0:  # ì‹œê°„ë³„ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ì‹œë„
            st.info("ğŸŒ ì§€ì—­ë³„ ê´€ì‹¬ë„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            try:
                interest_by_region = pytrends.interest_by_region(
                    resolution='COUNTRY', 
                    inc_low_vol=True, 
                    inc_geo_code=False
                )
                
                if (interest_by_region is not None and 
                    hasattr(interest_by_region, 'empty') and 
                    not interest_by_region.empty):
                    
                    result['interest_by_region'] = interest_by_region
                    success_count += 1
                    st.success(f"âœ… ì§€ì—­ë³„ ê´€ì‹¬ë„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({len(interest_by_region)}ê°œ êµ­ê°€)")
                else:
                    st.info("â„¹ï¸ ì§€ì—­ë³„ ê´€ì‹¬ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.info(f"â„¹ï¸ ì§€ì—­ë³„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        
        # 3. ê´€ë ¨ ê²€ìƒ‰ì–´ (ì„ íƒì‚¬í•­)
        if success_count > 0:  # ê¸°ë³¸ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ì‹œë„
            st.info("ğŸ” ê´€ë ¨ ê²€ìƒ‰ì–´ ìˆ˜ì§‘ ì¤‘...")
            try:
                related_queries = pytrends.related_queries()
                
                if (related_queries is not None and 
                    isinstance(related_queries, dict) and 
                    len(related_queries) > 0):
                    
                    result['related_queries'] = related_queries
                    success_count += 1
                    st.success("âœ… ê´€ë ¨ ê²€ìƒ‰ì–´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                else:
                    st.info("â„¹ï¸ ê´€ë ¨ ê²€ìƒ‰ì–´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.info(f"â„¹ï¸ ê´€ë ¨ ê²€ìƒ‰ì–´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        
        # ê²°ê³¼ ê²€ì¦
        if success_count == 0:
            return {
                "error": "ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "suggestions": [
                    "ğŸ”„ ë‹¤ë¥¸ í‚¤ì›Œë“œ ì‹œë„:",
                    f"  â€¢ '{clean_keywords[0]}' ëŒ€ì‹  '{clean_keywords[0]} stock' ì‚¬ìš©",
                    "ğŸ“… ë¶„ì„ ê¸°ê°„ ë³€ê²½:",
                    "  â€¢ 'ì§€ë‚œ 12ê°œì›”' ë˜ëŠ” 'ì§€ë‚œ 5ë…„' ì„ íƒ",
                    "ğŸŒ ì§€ì—­ ì„¤ì • ë³€ê²½:",
                    "  â€¢ 'ì „ ì„¸ê³„' ë˜ëŠ” 'ë¯¸êµ­' ì„ íƒ",
                    "â° ì ì‹œ í›„ ì¬ì‹œë„:",
                    "  â€¢ 5-10ë¶„ í›„ ë‹¤ì‹œ ì‹œë„",
                    "ğŸ”¤ ì˜ì–´ í‚¤ì›Œë“œ ì‚¬ìš©:",
                    "  â€¢ í•œê¸€ë³´ë‹¤ ì˜ì–´ í‚¤ì›Œë“œê°€ ë” ì •í™•"
                ]
            }
        
        st.success(f"ğŸ‰ ì´ {success_count}ê°œ ë°ì´í„° ìœ í˜• ìˆ˜ì§‘ ì™„ë£Œ!")
        return result
    
    @staticmethod
    def create_trends_chart(trends_data: Dict) -> go.Figure:
        """íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„± - ì•ˆì „ì„± ê°•í™”"""
        try:
            if not trends_data or trends_data.get('error'):
                return go.Figure()
            
            interest_df = trends_data.get('interest_over_time')
            keywords = trends_data.get('keywords', [])
            
            if (interest_df is None or 
                not hasattr(interest_df, 'empty') or 
                interest_df.empty):
                return go.Figure()
            
            fig = go.Figure()
            colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
            added_traces = 0
            
            for i, keyword in enumerate(keywords):
                try:
                    if keyword in interest_df.columns:
                        y_data = interest_df[keyword]
                        if y_data.sum() > 0:  # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                            fig.add_trace(go.Scatter(
                                x=interest_df.index,
                                y=y_data,
                                mode='lines+markers',
                                name=keyword,
                                line=dict(color=colors[i % len(colors)], width=2),
                                marker=dict(size=4),
                                hovertemplate=f'<b>{keyword}</b><br>' +
                                            'Date: %{x}<br>' +
                                            'Interest: %{y}<br>' +
                                            '<extra></extra>'
                            ))
                            added_traces += 1
                except Exception:
                    continue
            
            if added_traces == 0:
                return go.Figure()
            
            fig.update_layout(
                title=f'êµ¬ê¸€ ê²€ìƒ‰ íŠ¸ë Œë“œ ({trends_data.get("timeframe", "12ê°œì›”")})',
                xaxis_title='ë‚ ì§œ',
                yaxis_title='ê²€ìƒ‰ ê´€ì‹¬ë„ (0-100)',
                height=500,
                hovermode='x unified',
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            
            return fig
            
        except Exception as e:
            st.error(f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return go.Figure()
    
    @staticmethod
    def create_regional_chart(trends_data: Dict) -> go.Figure:
        """ì§€ì—­ë³„ ì°¨íŠ¸ ìƒì„± - ì•ˆì „ì„± ê°•í™”"""
        try:
            if not trends_data or trends_data.get('error'):
                return go.Figure()
            
            regional_df = trends_data.get('interest_by_region')
            keywords = trends_data.get('keywords', [])
            
            if (regional_df is None or 
                not hasattr(regional_df, 'empty') or 
                regional_df.empty or 
                not keywords):
                return go.Figure()
            
            first_keyword = keywords[0]
            if first_keyword not in regional_df.columns:
                return go.Figure()
            
            # 0ë³´ë‹¤ í° ê°’ë§Œ í•„í„°ë§
            valid_data = regional_df[regional_df[first_keyword] > 0]
            if valid_data.empty:
                return go.Figure()
            
            top_regions = valid_data[first_keyword].sort_values(ascending=False).head(20)
            if top_regions.empty:
                return go.Figure()
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=top_regions.values,
                y=top_regions.index,
                orientation='h',
                marker=dict(
                    color=top_regions.values,
                    colorscale='Blues',
                    showscale=True,
                    colorbar=dict(title="ê´€ì‹¬ë„")
                ),
                text=[f"{val:.0f}" for val in top_regions.values],
                textposition='auto',
                hovertemplate='<b>%{y}</b><br>' +
                            first_keyword + ' ê´€ì‹¬ë„: %{x}<br>' +
                            '<extra></extra>'
            ))
            
            fig.update_layout(
                title=f'êµ­ê°€ë³„ ê²€ìƒ‰ ê´€ì‹¬ë„ - {first_keyword}',
                xaxis_title='ê²€ìƒ‰ ê´€ì‹¬ë„',
                yaxis_title='êµ­ê°€',
                height=600,
                yaxis=dict(autorange="reversed")
            )
            
            return fig
            
        except Exception as e:
            st.error(f"ì§€ì—­ë³„ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return go.Figure()
    
    @staticmethod
    def analyze_trends_with_gpt(trends_data: Dict, openai_api_key: str) -> Dict:
        """GPTë¥¼ ì´ìš©í•œ íŠ¸ë Œë“œ ë¶„ì„"""
        try:
            if not openai_api_key or not trends_data:
                return {"error": "API í‚¤ ë˜ëŠ” íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
            
            from openai import OpenAI
            client = OpenAI(api_key=openai_api_key)
            
            # íŠ¸ë Œë“œ ë°ì´í„° í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            keywords = trends_data.get('keywords', [])
            interest_df = trends_data.get('interest_over_time')
            
            if interest_df is None or interest_df.empty:
                return {"error": "íŠ¸ë Œë“œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}
            
            # ìµœê·¼ íŠ¸ë Œë“œ ë¶„ì„
            analysis_text = f"ğŸ“Š êµ¬ê¸€ íŠ¸ë Œë“œ ë¶„ì„ ë°ì´í„°:\n\n"
            analysis_text += f"ê²€ìƒ‰ì–´: {', '.join(keywords)}\n"
            analysis_text += f"ë¶„ì„ ê¸°ê°„: {trends_data.get('timeframe', '12ê°œì›”')}\n\n"
            
            # ê° í‚¤ì›Œë“œë³„ ìµœê·¼ íŠ¸ë Œë“œ
            for keyword in keywords:
                if keyword in interest_df.columns:
                    recent_values = interest_df[keyword].tail(10)
                    avg_recent = recent_values.mean()
                    trend_direction = "ìƒìŠ¹" if recent_values.iloc[-1] > recent_values.iloc[0] else "í•˜ë½"
                    max_val = interest_df[keyword].max()
                    max_date = interest_df[keyword].idxmax()
                    
                    analysis_text += f"â€¢ {keyword}:\n"
                    analysis_text += f"  - ìµœê·¼ í‰ê·  ê´€ì‹¬ë„: {avg_recent:.1f}\n"
                    analysis_text += f"  - ìµœê·¼ íŠ¸ë Œë“œ: {trend_direction}\n"
                    analysis_text += f"  - ìµœê³  ê´€ì‹¬ë„: {max_val} (ë‚ ì§œ: {max_date.strftime('%Y-%m-%d')})\n\n"
            
            # ê´€ë ¨ ê²€ìƒ‰ì–´ ì •ë³´ ì¶”ê°€
            related_queries = trends_data.get('related_queries', {})
            if related_queries:
                analysis_text += "ğŸ” ê´€ë ¨ ìƒìŠ¹ ê²€ìƒ‰ì–´:\n"
                for keyword in keywords:
                    if keyword in related_queries and related_queries[keyword].get('rising') is not None:
                        rising_queries = related_queries[keyword]['rising'].head(3)
                        for _, row in rising_queries.iterrows():
                            analysis_text += f"  - {row['query']} (+{row['value']}%)\n"
                analysis_text += "\n"

            prompt = f"""
ë‹¤ìŒì€ êµ¬ê¸€ íŠ¸ë Œë“œ ë°ì´í„° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. íˆ¬ìì ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

{analysis_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

### ğŸ” êµ¬ê¸€ íŠ¸ë Œë“œ ì¢…í•© ë¶„ì„

#### 1. **ê²€ìƒ‰ íŠ¸ë Œë“œ ìš”ì•½** (5ì  ë§Œì ìœ¼ë¡œ ì ìˆ˜ ë¶€ì—¬)
- ì¢…í•© ì ìˆ˜: X/5ì 
- í•œ ì¤„ ìš”ì•½

#### 2. **ì£¼ìš” íŠ¸ë Œë“œ íŒ¨í„´**
- ê²€ìƒ‰ëŸ‰ ë³€í™”ì˜ íŠ¹ì§•ì  íŒ¨í„´
- ê³„ì ˆì„± ë˜ëŠ” ì£¼ê¸°ì„± ë¶„ì„
- ê¸‰ìƒìŠ¹/ê¸‰í•˜ë½ êµ¬ê°„ ë¶„ì„

#### 3. **íˆ¬ìì ê´€ì‹¬ë„ ë¶„ì„**
- ê²€ìƒ‰ëŸ‰ê³¼ íˆ¬ì ì‹¬ë¦¬ì˜ ìƒê´€ê´€ê³„
- ëŒ€ì¤‘ì˜ ê´€ì‹¬ë„ ë³€í™” ì˜ë¯¸
- ë¯¸ë””ì–´ ë…¸ì¶œê³¼ì˜ ì—°ê´€ì„±

#### 4. **ì§€ì—­ë³„ ê´€ì‹¬ë„ ì¸ì‚¬ì´íŠ¸**
- ì£¼ìš” ê´€ì‹¬ ì§€ì—­ ë¶„ì„
- ê¸€ë¡œë²Œ vs ë¡œì»¬ ê´€ì‹¬ë„
- ì§€ì—­ë³„ íˆ¬ì íŠ¸ë Œë“œ ì‹œì‚¬ì 

#### 5. **ê´€ë ¨ ê²€ìƒ‰ì–´ ë¶„ì„**
- ìƒìŠ¹ ê²€ìƒ‰ì–´ì˜ ì˜ë¯¸
- íˆ¬ììë“¤ì˜ ì£¼ìš” ê´€ì‹¬ì‚¬
- ì‹œì¥ ì‹¬ë¦¬ ë°˜ì˜ í‚¤ì›Œë“œ

#### 6. **íˆ¬ì ì‹œì‚¬ì **
- ê²€ìƒ‰ íŠ¸ë Œë“œì™€ ì£¼ê°€ì˜ ì¼ë°˜ì  ìƒê´€ê´€ê³„
- í˜„ì¬ íŠ¸ë Œë“œê°€ ì‹œì‚¬í•˜ëŠ” ë°”
- ì£¼ì˜í•´ì•¼ í•  ì‹ í˜¸ë“¤

#### 7. **í–¥í›„ ì „ë§ ë° ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸**
- ê²€ìƒ‰ íŠ¸ë Œë“œ ë°©í–¥ì„± ì˜ˆì¸¡
- ì£¼ì‹œí•´ì•¼ í•  ë³€ê³¡ì 
- ì¶”ê°€ ëª¨ë‹ˆí„°ë§ í‚¤ì›Œë“œ

#### 8. **ê²°ë¡ **
- í˜„ì¬ ëŒ€ì¤‘ ê´€ì‹¬ë„ í•œ ì¤„ ìš”ì•½
- íˆ¬ìì ê´€ì ì—ì„œì˜ ì¢…í•© ì˜ê²¬

ê° ì„¹ì…˜ì„ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì‹œê³ , êµ¬ê¸€ íŠ¸ë Œë“œë¥¼ íˆ¬ì ë¶„ì„ì— í™œìš©í•˜ëŠ” ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
"""

            response = client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. êµ¬ê¸€ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ íˆ¬ììì—ê²Œ ìœ ìš©í•œ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1200,
                temperature=0.3
            )
            
            analysis = response.choices[0].message.content.strip()
            
            # ì ìˆ˜ ì¶”ì¶œ
            import re
            score_match = re.search(r'ì ìˆ˜[:\s]*(\d+(?:\.\d+)?)[/ì ]', analysis)
            score = float(score_match.group(1)) if score_match else 3.0
            
            return {
                "analysis": analysis,
                "score": score,
                "max_score": 5.0,
                "success": True
            }
            
        except Exception as e:
            return {"error": f"GPT íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

    @staticmethod
    def get_stock_related_keywords(symbol: str, company_name: str = None) -> List[str]:
        """ì£¼ì‹ ê´€ë ¨ í‚¤ì›Œë“œ ìƒì„± - ë” ì•ˆì „í•˜ê²Œ"""
        keywords = []
        
        if symbol and isinstance(symbol, str):
            symbol = symbol.strip().upper()
            keywords.append(symbol)
            keywords.append(f"{symbol} stock")
        
        if company_name and isinstance(company_name, str):
            clean_name = company_name.strip()
            # íšŒì‚¬ suffix ì œê±°
            for suffix in [' Inc.', ' Corp.', ' Ltd.', ' Co.', ' LLC', ' Plc']:
                clean_name = clean_name.replace(suffix, '')
            
            if clean_name and clean_name != symbol:
                keywords.append(clean_name)
        
        # ì¤‘ë³µ ì œê±° ë° ìœ íš¨ì„± ê²€ì‚¬
        unique_keywords = []
        for kw in keywords:
            if kw and kw.strip() and kw.strip() not in unique_keywords:
                unique_keywords.append(kw.strip())
        
        return unique_keywords[:3]  # ìµœëŒ€ 3ê°œë¡œ ì œí•œ
    
    # ë”ë¯¸ ë°ì´í„° ìƒì„± í•¨ìˆ˜ (ë°±ì—…ìš©)
@staticmethod
def create_demo_trends_data(keywords: List[str]) -> Dict:
    """ë°ëª¨/í…ŒìŠ¤íŠ¸ìš© íŠ¸ë Œë“œ ë°ì´í„° ìƒì„±"""
    import pandas as pd
    import numpy as np
    from datetime import datetime, timedelta
    
    # ë‚ ì§œ ìƒì„± (ìµœê·¼ 12ê°œì›”)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)
    dates = pd.date_range(start=start_date, end=end_date, freq='W')
    
    # ë”ë¯¸ íŠ¸ë Œë“œ ë°ì´í„° ìƒì„±
    demo_data = {}
    for keyword in keywords[:3]:
        # ëœë¤í•˜ì§€ë§Œ í˜„ì‹¤ì ì¸ íŠ¸ë Œë“œ íŒ¨í„´ ìƒì„±
        base_trend = 30 + 20 * np.sin(np.linspace(0, 4*np.pi, len(dates)))
        noise = np.random.normal(0, 5, len(dates))
        values = np.maximum(0, base_trend + noise)
        demo_data[keyword] = values
    
    demo_df = pd.DataFrame(demo_data, index=dates)
    
    return {
        'interest_over_time': demo_df,
        'interest_by_region': None,
        'related_queries': None,
        'related_topics': None,
        'keywords': keywords[:3],
        'timeframe': '12-m',
        'is_demo': True
    }

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    st.markdown('<h1 class="main-header"> ì„œí•™ê°œë¯¸ì˜ íˆ¬ì íƒêµ¬ìƒí™œ ğŸœğŸ”</h1>', unsafe_allow_html=True)
    st.markdown('### AI ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ ë° íˆ¬ì ë¶„ì„ í”Œë«í¼')
    
    # ë©´ì±… ê³ ì§€
    st.warning('âš ï¸ **íˆ¬ì ë©´ì±… ê³ ì§€**: ë³¸ ë¶„ì„ì€ ì •ë³´ ì œê³µ ëª©ì ì´ë©° íˆ¬ì ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤. ëª¨ë“  íˆ¬ì ê²°ì •ì€ ë³¸ì¸ ì±…ì„í•˜ì— í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.')
    
    # ì‚¬ì´ë“œë°” - ì…ë ¥ ì„¤ì •
    st.sidebar.header('ğŸ“Š ë¶„ì„ ì„¤ì •')
    
    # ì¢…ëª© ì…ë ¥
    symbols_input = st.sidebar.text_input(
        'ì¢…ëª© ì½”ë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)',
        value='AAPL',
        help='ì˜ˆ: AAPL,MSFT,GOOGL'
    )
    
    symbols = [s.strip().upper() for s in symbols_input.split(',') if s.strip()]
    
    # ë¶„ì„ ì˜µì…˜
    prediction_model = st.sidebar.selectbox(
        'ì˜ˆì¸¡ ëª¨ë¸ ì„ íƒ',
        ['Prophet', 'ARIMA']
    )
    
    prediction_days = st.sidebar.slider(
        'ì˜ˆì¸¡ ê¸°ê°„ (ì¼)',
        min_value=7,
        max_value=180,
        value=30
    )
    
    # íƒ­ ìƒì„± (ì„¹í„° íŠ¸ë¦¬ë§µ íƒ­ ì¶”ê°€)
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs(['ğŸ  í™ˆ', 'ğŸ“Š ì„¹í„° íŠ¸ë¦¬ë§µ', 'ğŸ“ˆ ì£¼ê°€ ì˜ˆì¸¡', 'ğŸ“° ë‰´ìŠ¤ ë¶„ì„', 'ğŸ’° ì¬ë¬´ ê±´ì „ì„±', 'ğŸŒ ê²½ì œì§€í‘œ', 'ğŸ§  ë²„í• ì¡°ì–¸', 'ğŸ“º ìœ íŠœë¸Œ ë¶„ì„', 'ğŸ“ˆ êµ¬ê¸€ íŠ¸ë Œë“œ'])
    
    with tab1:
        st.header('ğŸ  ì„œë¹„ìŠ¤ ê°œìš”')
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.subheader('ğŸ“Š ì„¹í„° íŠ¸ë¦¬ë§µ')
            st.write('ì‹¤ì‹œê°„ ì„¹í„°ë³„ ì‹œê°€ì´ì•¡ ì‹œê°í™”')
            st.write('â€¢ S&P 500 ê¸°ë°˜ ì„¹í„° ë¶„ë¥˜')
            st.write('â€¢ ì‹œê°€ì´ì•¡ ìƒìœ„ 20ê°œ ì¢…ëª©')
            st.write('â€¢ ì¼ì¼ ë³€ë™ë¥  ìƒ‰ìƒ í‘œì‹œ')
            st.write('â€¢ íŠ¸ë¦¬ë§µ ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸')
        
        with col2:
            st.subheader('ğŸ“ˆ ì£¼ê°€ ë° ê±°ë˜ëŸ‰ ì˜ˆì¸¡')
            st.write('AI ëª¨ë¸ì„ í™œìš©í•œ ì£¼ê°€ ë° ê±°ë˜ëŸ‰ ì˜ˆì¸¡')
            st.write('â€¢ Prophet: Facebookì˜ ì‹œê³„ì—´ ì˜ˆì¸¡')
            st.write('â€¢ ARIMA: ì „í†µì ì¸ í†µê³„ ëª¨ë¸')
            st.write('â€¢ ë°±í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì§€í‘œ ì œê³µ')
            st.write('â€¢ ì‹œê°í™” ì°¨íŠ¸')
        
        with col3:
            st.subheader('ğŸ“° ë‰´ìŠ¤ ë¶„ì„')
            st.write('êµ¬ê¸€ ë‰´ìŠ¤ ë¶„ì„')
            st.write('â€¢ ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„')
            st.write('â€¢ ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ë¶„ë¥˜')
            st.write('â€¢ íŠ¸ë Œë“œ ì‹œê°í™”')
            st.write('â€¢ GPT ê¸°ë°˜ ë‰´ìŠ¤ ìš”ì•½')

        with col4:
            st.subheader('ğŸ§  ì›Œë Œ ë²„í• ìŠ¤íƒ€ì¼ ì¡°ì–¸')
            st.write('ê°€ì¹˜ íˆ¬ì ê´€ì ì˜ ì¢…í•© ë¶„ì„')
            st.write('â€¢ ROE, P/E ë¹„ìœ¨ ë“± í•µì‹¬ ì§€í‘œ')
            st.write('â€¢ ë¶€ì±„ë¹„ìœ¨ ë° ì¬ë¬´ ê±´ì „ì„±')
            st.write('â€¢ ììœ í˜„ê¸ˆíë¦„ ë¶„ì„')
            st.write('â€¢ ë§¤ìˆ˜/ë³´ìœ /ë§¤ë„ ë“±ê¸‰ ì œê³µ')
            st.write('â€¢ ë²„í• ì² í•™ ê¸°ë°˜ ì ìˆ˜ ì‹œìŠ¤í…œ')

        # ì¶”ê°€ ì„¹ì…˜
        st.markdown('---')
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.subheader('ğŸ’° ì¬ë¬´ ì§€í‘œ ë¶„ì„')
            st.write('ê³¼ê±° ì‹¤ì  ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„')
            st.write('â€¢ ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ ì¶”ì´')
            st.write('â€¢ ì—°ë„ë³„ ì„±ì¥ë¥  ë¶„ì„')
            st.write('â€¢ ìˆ˜ìµì„± ì§€í‘œ ë³€í™”')
            st.write('â€¢ GPT ê¸°ë°˜ ì¬ë¬´ ì§€í‘œ ë¶„ì„')
            
        with col2:
            st.subheader('ğŸŒ ëŒ€ì™¸ ê²½ì œì§€í‘œ')
            st.write('ê±°ì‹œê²½ì œ í™˜ê²½ ë¶„ì„')
            st.write('â€¢ ì£¼ìš” ì£¼ì‹ ì§€ìˆ˜ ì¶”ì´')
            st.write('â€¢ ê¸ˆë¦¬, ê¸ˆì‹œì„¸, ë‹¬ëŸ¬ ë™í–¥')
            st.write('â€¢ ì‹œì¥ ë³€ë™ì„± ì§€í‘œ')
            st.write('â€¢ ì›ìì¬ ê°€ê²© ì¶”ì´')
            st.write('â€¢ GPT ê¸°ë°˜ ê±°ì‹œê²½ì œ ë¶„ì„')

        with col3:
            st.subheader('ğŸ“º ìœ íŠœë¸Œ ì˜ìƒ ë¶„ì„')
            st.write('ì£¼ì‹ ê´€ë ¨ ìœ íŠœë¸Œ ì½˜í…ì¸  AI ë¶„ì„')
            st.write('â€¢ ì‹¤ì‹œê°„ ì˜ìƒ ê²€ìƒ‰')
            st.write('â€¢ GPT ê¸°ë°˜ ì˜ìƒ ìš”ì•½')
            st.write('â€¢ íˆ¬ì í¬ì¸íŠ¸ ìë™ ì¶”ì¶œ')
            st.write('â€¢ ì „ë¬¸ê°€ ì˜ê²¬ ì¢…í•© ë¶„ì„')
            st.write('â€¢ ë¦¬ìŠ¤í¬ ìš”ì¸ ì‹ë³„')

        with col4:
            st.subheader('ğŸ“ˆ êµ¬ê¸€ íŠ¸ë Œë“œ ë¶„ì„')
            st.write('ê²€ìƒ‰ëŸ‰ ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„')
            st.write('â€¢ ì‹¤ì‹œê°„ ê²€ìƒ‰ ê´€ì‹¬ë„ ì¶”ì´')
            st.write('â€¢ ì§€ì—­ë³„ ê´€ì‹¬ë„ ë¶„í¬')
            st.write('â€¢ ê´€ë ¨ ê²€ìƒ‰ì–´ ë¶„ì„')
            st.write('â€¢ GPT ê¸°ë°˜ íŠ¸ë Œë“œ í•´ì„')
            st.write('â€¢ íˆ¬ì ì‹¬ë¦¬ ì§€í‘œë¡œ í™œìš©')

        # í”Œë«í¼ íŠ¹ì§• ì„¹ì…˜ ì¶”ê°€
        st.markdown('---')
        st.header('ğŸš€ í”Œë«í¼ í•µì‹¬ íŠ¹ì§•')

        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader('ğŸ¤– AI ê¸°ë°˜ í†µí•© ë¶„ì„')
            st.success("""
            **GPT-4 í™œìš© ì „ë¬¸ê°€ê¸‰ ë¶„ì„**
            â€¢ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ë° ìš”ì•½
            â€¢ ì¬ë¬´ì§€í‘œ ì „ë¬¸ê°€ í•´ì„  
            â€¢ ê²½ì œí™˜ê²½ ì¢…í•© ì§„ë‹¨
            â€¢ êµ¬ê¸€ íŠ¸ë Œë“œ íˆ¬ì ì‹¬ë¦¬ ë¶„ì„
            â€¢ ìœ íŠœë¸Œ ì˜ìƒ í•µì‹¬ ìš”ì•½
            
            **ì‹¤ì‹œê°„ ë°ì´í„° ì—°ë™**
            â€¢ Yahoo Finance ì‹¤ì‹œê°„ ì£¼ê°€
            â€¢ Google News ìµœì‹  ë‰´ìŠ¤
            â€¢ Google Trends ê²€ìƒ‰ëŸ‰
            â€¢ S&P 500 ì„¹í„°ë³„ ë°ì´í„°
            â€¢ ê²½ì œì§€í‘œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
            """)
        
        with col2:
            st.subheader('ğŸ“Š ì°¨ë³„í™”ëœ ë¶„ì„ ê¸°ëŠ¥')
            st.info("""
            **ë…ì°½ì ì¸ ë¶„ì„ ë„êµ¬**
            â€¢ ì„¹í„°ë³„ íŠ¸ë¦¬ë§µ ì‹œê°í™”
            â€¢ ì›Œë Œ ë²„í• ìŠ¤íƒ€ì¼ í‰ê°€ ì‹œìŠ¤í…œ
            â€¢ ì£¼ê°€ + ê±°ë˜ëŸ‰ ë™ì‹œ ì˜ˆì¸¡
            â€¢ 3ê°œë…„ ì¬ë¬´ì‹¤ì  íŠ¸ë Œë“œ ë¶„ì„
            â€¢ ê±°ì‹œê²½ì œ vs ê°œë³„ì¢…ëª© ì—°ê´€ë¶„ì„
            
            **ì‚¬ìš©ì ì¹œí™”ì  ì„¤ê³„**
            â€¢ ì§ê´€ì ì¸ íƒ­ êµ¬ì¡°
            â€¢ ëŒ€í™”í˜• ì°¨íŠ¸ (Plotly)
            â€¢ ë‹¨ê³„ë³„ ê°€ì´ë“œ ì œê³µ
            â€¢ ëª¨ë°”ì¼/ë°ìŠ¤í¬í†± ë°˜ì‘í˜•
            â€¢ í•œ ë²ˆì— ì—¬ëŸ¬ ì¢…ëª© ë¶„ì„ ê°€ëŠ¥
            """)

        # íˆ¬ì í”„ë¡œì„¸ìŠ¤ ê°€ì´ë“œ
        st.markdown('---')
        st.header('ğŸ“‹ ì¶”ì²œ íˆ¬ì ë¶„ì„ í”„ë¡œì„¸ìŠ¤')

        process_steps = [
            ("1ï¸âƒ£ **ì„¹í„° íŠ¸ë¦¬ë§µ**", "ê´€ì‹¬ ì„¹í„°ì˜ ì „ë°˜ì ì¸ ì‹œì¥ ìƒí™© íŒŒì•…"),
            ("2ï¸âƒ£ **ì£¼ê°€ ì˜ˆì¸¡**", "AI ëª¨ë¸ë¡œ í–¥í›„ ì£¼ê°€ ë° ê±°ë˜ëŸ‰ ì „ë§"),
            ("3ï¸âƒ£ **ë‰´ìŠ¤ ë¶„ì„**", "ìµœì‹  ë‰´ìŠ¤ì˜ ê°ì„±ê³¼ ì‹œì¥ ì˜í–¥ í‰ê°€"),
            ("4ï¸âƒ£ **ì¬ë¬´ ê±´ì „ì„±**", "ê¸°ì—…ì˜ ì¬ë¬´ ìƒíƒœì™€ ì„±ì¥ì„± ì ê²€"),
            ("5ï¸âƒ£ **ê²½ì œì§€í‘œ**", "ê±°ì‹œê²½ì œ í™˜ê²½ì´ íˆ¬ìì— ë¯¸ì¹˜ëŠ” ì˜í–¥"),
            ("6ï¸âƒ£ **ë²„í• ì¡°ì–¸**", "ê°€ì¹˜ íˆ¬ì ê´€ì ì—ì„œì˜ ì¢…í•© í‰ê°€"),
            ("7ï¸âƒ£ **ìœ íŠœë¸Œ ë¶„ì„**", "ì „ë¬¸ê°€ë“¤ì˜ ì˜ê²¬ê³¼ ì‹œì¥ ë¶„ìœ„ê¸° í™•ì¸"),
            ("8ï¸âƒ£ **êµ¬ê¸€ íŠ¸ë Œë“œ**", "ëŒ€ì¤‘ì˜ ê´€ì‹¬ë„ì™€ íˆ¬ì ì‹¬ë¦¬ ì¸¡ì •"),
            ("9ï¸âƒ£ **ì¢…í•© íŒë‹¨**", "ëª¨ë“  ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… íˆ¬ì ê²°ì •")
        ]
        
        for i in range(0, len(process_steps), 3):
            cols = st.columns(3)
            for j in range(3):
                if i + j < len(process_steps):
                    step, description = process_steps[i + j]
                    with cols[j]:
                        st.markdown(f"**{step}**")
                        st.write(description)

        # ì„±ê³µ ì‚¬ë¡€ ë° í™œìš© íŒ
        st.markdown('---')
        st.header('ğŸ’¡ íš¨ê³¼ì ì¸ í™œìš© ë°©ë²•')
        
        with st.expander('ğŸ¯ ì´ˆë³´ íˆ¬ììë¥¼ ìœ„í•œ ê°€ì´ë“œ'):
            st.markdown("""
            **ğŸ“š íˆ¬ì í•™ìŠµ ë‹¨ê³„ë³„ í™œìš©ë²•**
            
            **ğŸ¥‰ ì´ˆê¸‰ì (íˆ¬ì ê²½í—˜ 6ê°œì›” ë¯¸ë§Œ)**
            1. ì›Œë Œ ë²„í• ì¡°ì–¸ íƒ­ë¶€í„° ì‹œì‘ â†’ ê¸°ë³¸ì ì¸ ì¬ë¬´ì§€í‘œ í•™ìŠµ
            2. ë‰´ìŠ¤ ë¶„ì„ìœ¼ë¡œ ì‹œì¥ ê°ì„± ì´í•´
            3. ì„¹í„° íŠ¸ë¦¬ë§µìœ¼ë¡œ ì‹œì¥ ì „ì²´ íë¦„ íŒŒì•…
            
            **ğŸ¥ˆ ì¤‘ê¸‰ì (íˆ¬ì ê²½í—˜ 6ê°œì›”~2ë…„)**
            1. ì¬ë¬´ ê±´ì „ì„± + ê²½ì œì§€í‘œ ì¡°í•© ë¶„ì„
            2. ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ë¡œ íƒ€ì´ë° ì—°êµ¬
            3. êµ¬ê¸€ íŠ¸ë Œë“œë¡œ ëŒ€ì¤‘ ì‹¬ë¦¬ í™œìš©
            
            **ğŸ¥‡ ê³ ê¸‰ì (íˆ¬ì ê²½í—˜ 2ë…„ ì´ìƒ)**
            1. ëª¨ë“  íƒ­ì„ ì¢…í•©í•˜ì—¬ ë‹¤ê°ë„ ë¶„ì„
            2. GPT ë¶„ì„ ê²°ê³¼ì™€ ë³¸ì¸ ë¶„ì„ ë¹„êµ
            3. í¬íŠ¸í´ë¦¬ì˜¤ ì°¨ì›ì—ì„œ ì¢…ëª© ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
            """)
        
        with st.expander('âš¡ ì‹œê°„ëŒ€ë³„ íš¨ìœ¨ì  ì‚¬ìš©ë²•'):
            st.markdown("""
            **ğŸ• ì‹œê°„ëŒ€ë³„ ìµœì  í™œìš© ì „ëµ**
            
            **ğŸŒ… ì¥ ì‹œì‘ ì „ (9:00 AM ì´ì „)**
            â€¢ ê²½ì œì§€í‘œ â†’ ì˜¤ëŠ˜ì˜ ì‹œì¥ í™˜ê²½ íŒŒì•…
            â€¢ ë‰´ìŠ¤ ë¶„ì„ â†’ ë°¤ì‚¬ì´ ë°œìƒí•œ ì´ìŠˆ í™•ì¸
            â€¢ ì„¹í„° íŠ¸ë¦¬ë§µ â†’ í”„ë¦¬ë§ˆì¼“ ë™í–¥ ì²´í¬
            
            **ğŸ“ˆ ì¥ì¤‘ (9:30 AM - 4:00 PM)**
            â€¢ ì‹¤ì‹œê°„ íŠ¸ë¦¬ë§µìœ¼ë¡œ ì„¹í„° ë¡œí…Œì´ì…˜ ëª¨ë‹ˆí„°ë§
            â€¢ êµ¬ê¸€ íŠ¸ë Œë“œë¡œ ê¸‰ë“±/ê¸‰ë½ ì¢…ëª©ì˜ ê´€ì‹¬ë„ í™•ì¸
            â€¢ ë‰´ìŠ¤ ë¶„ì„ìœ¼ë¡œ ëŒë°œ ì´ìŠˆ ëŒ€ì‘
            
            **ğŸŒ† ì¥ ë§ˆê° í›„ (4:00 PM ì´í›„)**
            â€¢ ì¬ë¬´ ê±´ì „ì„±ìœ¼ë¡œ ì‹ ê·œ ì¢…ëª© ë°œêµ´
            â€¢ ë²„í• ì¡°ì–¸ìœ¼ë¡œ ì¥ê¸° íˆ¬ì ì¢…ëª© ì„ ë³„
            â€¢ ìœ íŠœë¸Œ ë¶„ì„ìœ¼ë¡œ ì „ë¬¸ê°€ ì˜ê²¬ ìˆ˜ì§‘
            â€¢ ì£¼ê°€ ì˜ˆì¸¡ìœ¼ë¡œ ë‹¤ìŒ ì£¼ ì „ëµ ìˆ˜ë¦½
            
            **ğŸ“… ì£¼ë§ (í† -ì¼)**
            â€¢ ëª¨ë“  íƒ­ ì¢…í•© ë¶„ì„ìœ¼ë¡œ ë‹¤ìŒ ì£¼ ê³„íš ìˆ˜ë¦½
            â€¢ GPT ë¶„ì„ ê²°ê³¼ë“¤ì„ ì •ë¦¬í•˜ì—¬ íˆ¬ì ì¼ì§€ ì‘ì„±
            â€¢ ìƒˆë¡œìš´ ì¢…ëª© í›„ë³´êµ° ë°œêµ´ ë° ì‚¬ì „ ì¡°ì‚¬
            """)
        
        with st.expander('ğŸ”¥ ê³ ê¸‰ í™œìš© íŒ'):
            st.markdown("""
            **ğŸš€ ì „ë¬¸ê°€ ìˆ˜ì¤€ í™œìš© ì „ëµ**
            
            **ğŸ“Š ë‹¤ì¤‘ ì¢…ëª© ë¹„êµ ë¶„ì„**
            â€¢ ë™ì¼ ì„¹í„° ë‚´ 3-5ê°œ ì¢…ëª© ë™ì‹œ ë¶„ì„
            â€¢ ì›Œë Œ ë²„í• ì ìˆ˜ë¡œ ì¢…ëª© ìˆœìœ„ ë§¤ê¸°ê¸°
            â€¢ êµ¬ê¸€ íŠ¸ë Œë“œë¡œ ê´€ì‹¬ë„ ìƒëŒ€ ë¹„êµ
            
            **â° íƒ€ì´ë° ìµœì í™”**
            â€¢ VIX ê³µí¬ì§€ìˆ˜ + ë‰´ìŠ¤ ê°ì„± ì¡°í•©ìœ¼ë¡œ ì‹œì¥ íƒ€ì´ë° í¬ì°©
            â€¢ êµ¬ê¸€ íŠ¸ë Œë“œ ê¸‰ìƒìŠ¹ + ì£¼ê°€ ì˜ˆì¸¡ ì¡°í•©ìœ¼ë¡œ ëª¨ë©˜í…€ íˆ¬ì
            â€¢ ê²½ì œì§€í‘œ ë³€í™” + ì„¹í„° íŠ¸ë¦¬ë§µìœ¼ë¡œ ì„¹í„° ë¡œí…Œì´ì…˜ ì „ëµ
            
            **ğŸ¯ ë¦¬ìŠ¤í¬ ê´€ë¦¬**
            â€¢ ë²„í• ì¡°ì–¸ ë‚®ì€ ì ìˆ˜ + ë¶€ì •ì  ë‰´ìŠ¤ = íˆ¬ì ì œì™¸
            â€¢ ê²½ì œì§€í‘œ ì•…í™” + VIX ìƒìŠ¹ = ë°©ì–´ì  í¬ì§€ì…˜
            â€¢ íŠ¸ë Œë“œ ê´€ì‹¬ë„ ê¸‰ë½ + ê±°ë˜ëŸ‰ ê°ì†Œ = ì²­ì‚° ì‹ í˜¸
            
            **ğŸ’ ìˆ¨ì€ ë³´ì„ ë°œêµ´**
            â€¢ ì¬ë¬´ ê±´ì „ì„± ìš°ìˆ˜ + êµ¬ê¸€ íŠ¸ë Œë“œ ë‚®ìŒ = ì €í‰ê°€ í›„ë³´
            â€¢ ìœ íŠœë¸Œ ì „ë¬¸ê°€ ê¸ì • + ë‰´ìŠ¤ ì¼ì‹œì  ë¶€ì • = ë‹¨ê¸° ê¸°íšŒ
            â€¢ ì„¹í„° ì „ì²´ í•˜ë½ + ê°œë³„ ê¸°ì—… ì‹¤ì  ì–‘í˜¸ = ì—­ë°œìƒ íˆ¬ì
            """)
    
    with tab2:
        st.header('ğŸ“Š ì„¹í„°ë³„ ì‹œê°€ì´ì•¡ íŠ¸ë¦¬ë§µ')
        
        # S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        with st.spinner('S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
            sp500_df = SectorTreemapAnalyzer.get_sp500_stocks()
        
        if sp500_df.empty:
            st.error('S&P 500 ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        else:
            # ì„¹í„° ì„ íƒ
            available_sectors = sorted(sp500_df['sector'].unique())
            selected_sectors = st.multiselect(
                'ë¶„ì„í•  ì„¹í„°ë¥¼ ì„ íƒí•˜ì„¸ìš” (ìµœëŒ€ 4ê°œ ê¶Œì¥)',
                available_sectors,
                default=[]
            )
            
            if not selected_sectors:
                st.warning('ë¶„ì„í•  ì„¹í„°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.')
            else:
                # ì„¹í„°ë³„ ë¶„ì„ ì‹¤í–‰
                all_sectors_data = {}
                
                for sector in selected_sectors:
                    st.subheader(f'ğŸ¢ {sector} ì„¹í„°')
                    
                    with st.spinner(f'{sector} ì„¹í„° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘...'):
                        sector_data = SectorTreemapAnalyzer.get_sector_market_data(sp500_df, sector, top_n=20)
                        all_sectors_data[sector] = sector_data
                    
                    if not sector_data.empty:
                        # íŠ¸ë¦¬ë§µ ìƒì„± ë° í‘œì‹œ
                        fig = SectorTreemapAnalyzer.create_sector_treemap(sector_data, sector)
                        st.plotly_chart(fig, use_container_width=True, key=f"treemap_{sector}")
                        
                        # ì„¹í„° ìš”ì•½ ì •ë³´
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            total_market_cap = sector_data['market_cap'].sum() / 1e12
                            st.metric('ì´ ì‹œê°€ì´ì•¡', f'${total_market_cap:.2f}T')
                        
                        with col2:
                            avg_change = sector_data['change_pct'].mean()
                            color = 'normal' if avg_change > 0 else 'inverse'
                            st.metric('í‰ê·  ë³€ë™ë¥ ', f'{avg_change:+.2f}%', delta_color=color)
                        
                        with col3:
                            positive_count = len(sector_data[sector_data['change_pct'] > 0])
                            st.metric('ìƒìŠ¹ ì¢…ëª©', f'{positive_count}/{len(sector_data)}')
                        
                        with col4:
                            top_stock = sector_data.iloc[0]
                            st.metric('ìµœëŒ€ ì¢…ëª©', f"{top_stock['symbol']}")
                        
                        # ìƒìœ„ 5ê°œ ì¢…ëª© í…Œì´ë¸”
                        st.subheader(f'ğŸ“ˆ {sector} ì„¹í„° TOP 5')
                        top_5 = sector_data.head(5)[['symbol', 'company_name', 'market_cap_b', 'current_price', 'change_pct']]
                        top_5.columns = ['ì¢…ëª©ì½”ë“œ', 'íšŒì‚¬ëª…', 'ì‹œê°€ì´ì•¡($B)', 'í˜„ì¬ê°€($)', 'ë³€ë™ë¥ (%)']
                        
                        # ë³€ë™ë¥ ì— ë”°ë¥¸ ìƒ‰ìƒ ì ìš©
                        def color_negative_red(val):
                            if isinstance(val, (int, float)):
                                color = 'color: red' if val < 0 else 'color: green'
                                return color
                            return ''
                        
                        styled_df = top_5.style.applymap(color_negative_red, subset=['ë³€ë™ë¥ (%)'])
                        st.dataframe(styled_df, use_container_width=True)
                        
                        st.markdown('---')
                    else:
                        st.warning(f'{sector} ì„¹í„°ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                
                # ì „ì²´ ì„¹í„° ìš”ì•½ ì°¨íŠ¸
                if all_sectors_data:
                    st.header('ğŸ“Š ì„ íƒëœ ì„¹í„° ì¢…í•© ë¹„êµ')
                    summary_fig = SectorTreemapAnalyzer.create_sector_summary_chart(all_sectors_data)
                    if summary_fig.data:
                        st.plotly_chart(summary_fig, use_container_width=True, key="sector_summary")
                
                # ìƒ‰ìƒ ë²”ë¡€ ì„¤ëª…
                with st.expander('ğŸ¨ íŠ¸ë¦¬ë§µ ìƒ‰ìƒ ê°€ì´ë“œ'):
                    st.markdown("""
                    **ğŸ“Š íŠ¸ë¦¬ë§µ í•´ì„ ë°©ë²•:**
                    
                    **ë°•ìŠ¤ í¬ê¸°**: ì‹œê°€ì´ì•¡ (í´ìˆ˜ë¡ ì‹œê°€ì´ì•¡ì´ í¼)
                    
                    **ìƒ‰ìƒ ì˜ë¯¸**:
                    - ğŸŸ¢ **ì§„í•œ ì´ˆë¡**: +2% ì´ìƒ ìƒìŠ¹ (ê°•í•œ ìƒìŠ¹)
                    - ğŸƒ **ì—°í•œ ì´ˆë¡**: 0% ~ +2% ìƒìŠ¹ (ì•½í•œ ìƒìŠ¹)
                    - ğŸŒ¸ **ì—°í•œ ë¹¨ê°•**: 0% ~ -2% í•˜ë½ (ì•½í•œ í•˜ë½)
                    - ğŸ”´ **ì§„í•œ ë¹¨ê°•**: -2% ì´í•˜ í•˜ë½ (ê°•í•œ í•˜ë½)
                    
                    **ì •ë³´ í‘œì‹œ**:
                    - ì²« ë²ˆì§¸ ì¤„: ì¢…ëª© ì½”ë“œ
                    - ë‘ ë²ˆì§¸ ì¤„: íšŒì‚¬ëª…
                    - ì„¸ ë²ˆì§¸ ì¤„: ì‹œê°€ì´ì•¡ (Billions)
                    - ë„¤ ë²ˆì§¸ ì¤„: ì¼ì¼ ë³€ë™ë¥ 
                    
                    **ğŸ’¡ íˆ¬ì í™œìš© íŒ**:
                    - í° ë°•ìŠ¤ë©´ì„œ ì´ˆë¡ìƒ‰ â†’ ëŒ€í˜•ì£¼ ìƒìŠ¹ (ì‹œì¥ ê°•ì„¸ ì‹ í˜¸)
                    - ì‘ì€ ë°•ìŠ¤ë“¤ì´ ëŒ€ë¶€ë¶„ ë¹¨ê°„ìƒ‰ â†’ ì†Œí˜•ì£¼ ì•½ì„¸
                    - ì„¹í„° ë‚´ ìƒ‰ìƒì´ ê³ ë¥´ê²Œ ë¶„í¬ â†’ ê°œë³„ ì¢…ëª© ì´ìŠˆ
                    - ì„¹í„° ë‚´ ìƒ‰ìƒì´ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨ â†’ ì„¹í„° ì „ë°˜ ì´ìŠˆ
                    """)
    
    with tab3:
        st.header('ğŸ“ˆ ì£¼ê°€ ì˜ˆì¸¡ ë¶„ì„')
        
        if not symbols:
            st.warning('ì¢…ëª© ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
        else:
            # ê±°ë˜ëŸ‰ ì˜ˆì¸¡ ì˜µì…˜ ì¶”ê°€
            st.subheader('âš™ï¸ ì˜ˆì¸¡ ì„¤ì •')
            col1, col2 = st.columns(2)
            
            with col1:
                include_volume = st.checkbox('ê±°ë˜ëŸ‰ ì˜ˆì¸¡ í¬í•¨', value=True, help='ì£¼ê°€ ì˜ˆì¸¡ê³¼ í•¨ê»˜ ê±°ë˜ëŸ‰ë„ ì˜ˆì¸¡í•©ë‹ˆë‹¤')
            
            with col2:
                chart_type = st.selectbox('ì°¨íŠ¸ í˜•íƒœ', ['ê°œë³„ ì°¨íŠ¸', 'í†µí•© ì°¨íŠ¸'], help='ê°œë³„ ì°¨íŠ¸: ì£¼ê°€ì™€ ê±°ë˜ëŸ‰ì„ ë”°ë¡œ í‘œì‹œ\ní†µí•© ì°¨íŠ¸: ì£¼ê°€ì™€ ê±°ë˜ëŸ‰ì„ í•¨ê»˜ í‘œì‹œ')
            
            for symbol in symbols:
                st.subheader(f'{symbol} ë¶„ì„')
                
                with st.spinner(f'{symbol} ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
                    # ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    stock_data = DataManager.get_stock_data(symbol)
                    
                    if stock_data.empty:
                        st.error(f'{symbol} ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                        continue
                    
                    # ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ ì‹¤í–‰
                    if prediction_model == 'Prophet':
                        price_forecast, price_metrics = PredictionModel.prophet_forecast(stock_data, prediction_days)
                        
                        # ê±°ë˜ëŸ‰ ì˜ˆì¸¡ (ì˜µì…˜ì´ ì„ íƒëœ ê²½ìš°)
                        if include_volume:
                            volume_forecast, volume_metrics = PredictionModel.prophet_volume_forecast(stock_data, prediction_days)
                        else:
                            volume_forecast, volume_metrics = pd.DataFrame(), {}
                    else:  # ARIMA
                        price_forecast, price_metrics = PredictionModel.arima_forecast(stock_data, prediction_days)
                        
                        # ê±°ë˜ëŸ‰ ì˜ˆì¸¡ (ì˜µì…˜ì´ ì„ íƒëœ ê²½ìš°)
                        if include_volume:
                            volume_forecast, volume_metrics = PredictionModel.arima_volume_forecast(stock_data, prediction_days)
                        else:
                            volume_forecast, volume_metrics = pd.DataFrame(), {}
                    
                    # ì°¨íŠ¸ í‘œì‹œ
                    if include_volume and chart_type == 'í†µí•© ì°¨íŠ¸' and not volume_forecast.empty:
                        # í†µí•© ì°¨íŠ¸
                        combined_fig = create_combined_chart(stock_data, stock_data, price_forecast, volume_forecast, symbol)
                        st.plotly_chart(combined_fig, use_container_width=True, key=f"combined_chart_{symbol}")
                    else:
                        # ê°œë³„ ì°¨íŠ¸ë“¤
                        # ì£¼ê°€ ì°¨íŠ¸
                        price_fig = create_stock_chart(stock_data, price_forecast, symbol)
                        st.plotly_chart(price_fig, use_container_width=True, key=f"price_chart_{symbol}")
                        
                        # ê±°ë˜ëŸ‰ ì°¨íŠ¸ (ì˜µì…˜ì´ ì„ íƒëœ ê²½ìš°)
                        if include_volume:
                            if not volume_forecast.empty:
                                volume_fig = create_volume_chart(stock_data, volume_forecast, symbol)
                                st.plotly_chart(volume_fig, use_container_width=True, key=f"volume_chart_{symbol}")
                            else:
                                st.warning('ê±°ë˜ëŸ‰ ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                    
                    # ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
                    if include_volume and not volume_forecast.empty:
                        # ì£¼ê°€ì™€ ê±°ë˜ëŸ‰ ì„±ëŠ¥ ì§€í‘œë¥¼ í•¨ê»˜ í‘œì‹œ
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.subheader('ğŸ“ˆ ì£¼ê°€ ì˜ˆì¸¡ ì„±ëŠ¥')
                            if price_metrics:
                                subcol1, subcol2, subcol3 = st.columns(3)
                                with subcol1:
                                    st.metric('ì˜ˆì¸¡ ëª¨ë¸', prediction_model)
                                with subcol2:
                                    st.metric('MAPE', f"{price_metrics.get('MAPE', 0):.2f}%")
                                with subcol3:
                                    st.metric('RMSE', f"{price_metrics.get('RMSE', 0):.2f}")
                        
                        with col2:
                            st.subheader('ğŸ“Š ê±°ë˜ëŸ‰ ì˜ˆì¸¡ ì„±ëŠ¥')
                            if volume_metrics and not volume_metrics.get('error'):
                                subcol1, subcol2, subcol3 = st.columns(3)
                                with subcol1:
                                    st.metric('ì˜ˆì¸¡ ëª¨ë¸', prediction_model)
                                with subcol2:
                                    st.metric('MAPE', f"{volume_metrics.get('MAPE', 0):.2f}%")
                                with subcol3:
                                    st.metric('RMSE', f"{volume_metrics.get('RMSE', 0):.0f}")
                            elif volume_metrics.get('error'):
                                st.error(volume_metrics['error'])
                    else:
                        # ì£¼ê°€ ì„±ëŠ¥ ì§€í‘œë§Œ í‘œì‹œ
                        if price_metrics:
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric('ì˜ˆì¸¡ ëª¨ë¸', prediction_model)
                            with col2:
                                st.metric('MAPE', f"{price_metrics.get('MAPE', 0):.2f}%")
                            with col3:
                                st.metric('RMSE', f"{price_metrics.get('RMSE', 0):.2f}")
                    
                    # ê±°ë˜ëŸ‰ íŠ¸ë Œë“œ ë¶„ì„
                    if include_volume:
                        volume_analysis = analyze_volume_trends(stock_data, volume_forecast)
                        
                        if not volume_analysis.get('error'):
                            st.subheader('ğŸ“Š ê±°ë˜ëŸ‰ íŠ¸ë Œë“œ ë¶„ì„')
                            
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                avg_vol = volume_analysis.get('avg_volume_30d', 0)
                                st.metric('ìµœê·¼ 30ì¼ í‰ê·  ê±°ë˜ëŸ‰', f"{avg_vol:,.0f}")
                            
                            with col2:
                                ratio = volume_analysis.get('volume_ratio', 0)
                                st.metric(
                                    'ì „ì²´ í‰ê·  ëŒ€ë¹„',
                                    f"{ratio:.2f}ë°°",
                                    delta="í™œë°œ" if ratio > 1.2 else "ë³´í†µ" if ratio > 0.8 else "ì €ì¡°"
                                )
                            
                            with col3:
                                trend = volume_analysis.get('trend_change', 0)
                                st.metric(
                                    'ìµœê·¼ íŠ¸ë Œë“œ',
                                    f"{trend:+.1f}%",
                                    delta="ì¦ê°€" if trend > 10 else "ê°ì†Œ" if trend < -10 else "ì•ˆì •"
                                )
                            
                            with col4:
                                forecast_change = volume_analysis.get('volume_forecast_change', 0)
                                st.metric(
                                    'ì˜ˆì¸¡ ë³€í™”ìœ¨',
                                    f"{forecast_change:+.1f}%",
                                    delta="ì¦ê°€ ì˜ˆìƒ" if forecast_change > 5 else "ê°ì†Œ ì˜ˆìƒ" if forecast_change < -5 else "ìœ ì§€ ì˜ˆìƒ"
                                )
                            
                            # ê±°ë˜ëŸ‰ í•´ì„
                            with st.expander('ğŸ“Š ê±°ë˜ëŸ‰ ë¶„ì„ í•´ì„'):
                                st.markdown(f'''
                                **ê±°ë˜ëŸ‰ ë¶„ì„ ë¦¬í¬íŠ¸:**
                                
                                **í˜„ì¬ ìƒí™©:**
                                - ìµœê·¼ 30ì¼ í‰ê·  ê±°ë˜ëŸ‰: {avg_vol:,.0f}
                                - ì „ì²´ í‰ê·  ëŒ€ë¹„: {ratio:.2f}ë°° ({'í™œë°œ' if ratio > 1.2 else 'ë³´í†µ' if ratio > 0.8 else 'ì €ì¡°'})
                                - ìµœê·¼ íŠ¸ë Œë“œ: {trend:+.1f}% ({'ì¦ê°€' if trend > 10 else 'ê°ì†Œ' if trend < -10 else 'ì•ˆì •'})
                                
                                **ì˜ˆì¸¡ ì „ë§:**
                                - í–¥í›„ {prediction_days}ì¼ ì˜ˆìƒ ë³€í™”: {forecast_change:+.1f}%
                                - ì˜ˆìƒ í‰ê·  ê±°ë˜ëŸ‰: {volume_analysis.get('predicted_avg', 0):,.0f}
                                
                                **íˆ¬ì ì‹œì‚¬ì :**
                                - ê±°ë˜ëŸ‰ ì¦ê°€: ê´€ì‹¬ë„ ìƒìŠ¹, ë³€ë™ì„± í™•ëŒ€ ê°€ëŠ¥ì„±
                                - ê±°ë˜ëŸ‰ ê°ì†Œ: ê´€ì‹¬ë„ í•˜ë½, íš¡ë³´ ê°€ëŠ¥ì„±
                                - ê¸‰ê²©í•œ ê±°ë˜ëŸ‰ ë³€í™”: ì¤‘ìš”í•œ ë‰´ìŠ¤ë‚˜ ì´ë²¤íŠ¸ ë°œìƒ ì‹ í˜¸
                                ''')
                        else:
                            st.warning(f"ê±°ë˜ëŸ‰ ë¶„ì„ ì‹¤íŒ¨: {volume_analysis.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    
                    st.markdown('---')
    
    with tab4:
        st.header('ğŸ“° ìµœì‹  ë‰´ìŠ¤ ë¶„ì„')
        
        if not symbols:
            st.warning('ì¢…ëª© ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
            return
        
        # OpenAI API í‚¤ ì…ë ¥
        st.subheader('ğŸ”§ GPT ë¶„ì„ ì„¤ì • (ì„ íƒì‚¬í•­)')
        openai_api_key = st.text_input(
            "OpenAI API í‚¤ (GPT ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ì„ ìœ„í•´ í•„ìš”)",
            type="password",
            help="GPTë¥¼ ì´ìš©í•œ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë¶„ì„ì„ ì›í•˜ì‹œë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ê°ì„± ë¶„ì„ë§Œ ì§„í–‰ë©ë‹ˆë‹¤."
        )
        
        # API í‚¤ ê²€ì¦
        if openai_api_key:
            if openai_api_key.startswith('sk-') and len(openai_api_key) > 20:
                st.success("âœ… API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤.")
            else:
                st.error("âŒ API í‚¤ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. 'sk-'ë¡œ ì‹œì‘í•˜ëŠ” ì˜¬ë°”ë¥¸ í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.info("â„¹ï¸ API í‚¤ë¥¼ ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ê°ì„± ë¶„ì„ë§Œ ì œê³µë©ë‹ˆë‹¤.")
        
        for symbol in symbols:
            st.subheader(f'{symbol} ë‰´ìŠ¤ ê°ì„± ë¶„ì„')
            
            with st.spinner(f'{symbol} ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘...'):
                # GPT ê¸°ë°˜ í–¥ìƒëœ ë¶„ì„
                enhanced_sentiment_data = SentimentAnalyzer.get_enhanced_news_sentiment(symbol, openai_api_key)
                
                # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
                if openai_api_key:
                    st.info(f"ğŸ”‘ API í‚¤ ì„¤ì •ë¨ - GPT ë¶„ì„ ì§„í–‰ ì¤‘...")
                    
                    # ë‰´ìŠ¤ ìˆ˜ì§‘ ìƒíƒœ í™•ì¸
                    news_count = len(enhanced_sentiment_data.get('news_articles', []))
                    st.info(f"ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {news_count}ê°œ")
                else:
                    st.warning("ğŸ”‘ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ - ê¸°ë³¸ ë¶„ì„ë§Œ ì§„í–‰")
                
                if enhanced_sentiment_data.get('gpt_analysis'):
                    if enhanced_sentiment_data['gpt_analysis'].get('error'):
                        # GPT ë¶„ì„ ì˜¤ë¥˜ í‘œì‹œ
                        st.error(f"ğŸ¤– GPT ë¶„ì„ ì˜¤ë¥˜: {enhanced_sentiment_data['gpt_analysis']['error']}")
                        st.info("ğŸ’¡ ê¸°ë³¸ ê°ì„± ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                    else:
                        # GPT ë¶„ì„ ì„±ê³µ
                        st.success("ğŸ¤– GPT ë¶„ì„ ì™„ë£Œ!")
                        gpt_analysis = enhanced_sentiment_data['gpt_analysis']
                        
                        # ê°ì„± ìƒíƒœ í‘œì‹œ
                        sentiment_label = gpt_analysis.get('sentiment_label', 'ì¤‘ë¦½ì ')
                        if 'ê¸ì •' in sentiment_label:
                            st.success(f"ğŸ“ˆ ì „ì²´ ê°ì„±: {sentiment_label}")
                        elif 'ë¶€ì •' in sentiment_label:
                            st.error(f"ğŸ“‰ ì „ì²´ ê°ì„±: {sentiment_label}")
                        else:
                            st.info(f"ğŸ“Š ì „ì²´ ê°ì„±: {sentiment_label}")
                        
                        # GPT ë¶„ì„ ë‚´ìš© í‘œì‹œ
                        st.markdown("### ğŸ“‹ ì „ë¬¸ê°€ ë¶„ì„ ìš”ì•½")
                        st.markdown(gpt_analysis['analysis'])
                        
                        st.markdown("---")
                
                elif openai_api_key:
                    # API í‚¤ëŠ” ìˆì§€ë§Œ GPT ë¶„ì„ì´ ì—†ëŠ” ê²½ìš°
                    st.warning("ğŸ¤– GPT ë¶„ì„ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                
                # ì‹¤ì œ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ í‘œì‹œ
                if enhanced_sentiment_data.get('news_articles'):
                    st.subheader('ğŸ“° ìµœì‹  ë‰´ìŠ¤ (ì‹¤ì‹œê°„ ìˆ˜ì§‘)')
                    
                    # ë‰´ìŠ¤ ê°œìˆ˜ì™€ ê¸°ë³¸ ê°ì„± ìš”ì•½
                    if enhanced_sentiment_data.get('basic_sentiment'):
                        summary = enhanced_sentiment_data['basic_sentiment']['summary']
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric('ì „ì²´ ê¸°ì‚¬', summary.get('total', 0))
                        
                        with col2:
                            st.metric('ê¸ì •', summary.get('positive', 0), delta_color='normal')
                        
                        with col3:
                            st.metric('ì¤‘ë¦½', summary.get('neutral', 0), delta_color='off')
                        
                        with col4:
                            st.metric('ë¶€ì •', summary.get('negative', 0), delta_color='inverse')
                    
                    # ê°ì„± ë¶„ì„ ì°¨íŠ¸ (ê¸°ë³¸ ë¶„ì„ ê¸°ì¤€)
                    if enhanced_sentiment_data.get('basic_sentiment'):
                        fig = create_sentiment_chart(enhanced_sentiment_data['basic_sentiment'])
                        st.plotly_chart(fig, use_container_width=True, key=f"sentiment_chart_{symbol}")
                    
                    # ê°œë³„ ë‰´ìŠ¤ ê¸°ì‚¬ í‘œì‹œ
                    st.subheader('ğŸ“„ ê°œë³„ ë‰´ìŠ¤ ê¸°ì‚¬')
                    
                    if enhanced_sentiment_data.get('basic_sentiment'):
                        sentiments = enhanced_sentiment_data['basic_sentiment']['sentiments']
                        
                        for i, item in enumerate(sentiments[:10]):  # ìµœëŒ€ 10ê°œ í‘œì‹œ
                            sentiment_color = 'green' if item['sentiment_category'] == 'Positive' else 'red' if item['sentiment_category'] == 'Negative' else 'gray'
                            
                            with st.expander(f"ğŸ“° {item['title'][:80]}{'...' if len(item['title']) > 80 else ''}"):
                                col1, col2 = st.columns([3, 1])
                                
                                with col1:
                                    st.markdown(f"**ì œëª©**: {item['title']}")
                                    st.markdown(f"**ì¶œì²˜**: {item.get('source', 'Unknown')} | **ì‹œê°„**: {item.get('time', 'Unknown')}")
                                    if item.get('link') and item['link'] != '#':
                                        st.markdown(f"**ë§í¬**: [ê¸°ì‚¬ ì½ê¸°]({item['link']})")
                                    else:
                                        st.markdown("**ë§í¬**: ë§í¬ ì—†ìŒ")
                                
                                with col2:
                                    st.markdown(f"**ê°ì„±**: <span style='color: {sentiment_color}'>{item['sentiment_category']}</span>", unsafe_allow_html=True)
                                    st.markdown(f"**ì ìˆ˜**: {item['sentiment_score']:.3f}")
                    
                else:
                    # ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
                    st.warning("ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ê°ì„± ë¶„ì„ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
                    sentiment_data = SentimentAnalyzer.get_news_sentiment(symbol)
                    
                    if sentiment_data:
                        # ê¸°ë³¸ ê°ì„± ë¶„ì„ ì°¨íŠ¸
                        fig = create_sentiment_chart(sentiment_data)
                        st.plotly_chart(fig, use_container_width=True, key=f"sentiment_chart_{symbol}")
                        
                        # ê°ì„± ìš”ì•½
                        summary = sentiment_data.get('summary', {})
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric('ì „ì²´ ê¸°ì‚¬', summary.get('total', 0))
                        
                        with col2:
                            st.metric('ê¸ì •', summary.get('positive', 0), delta_color='normal')
                        
                        with col3:
                            st.metric('ì¤‘ë¦½', summary.get('neutral', 0), delta_color='off')
                        
                        with col4:
                            st.metric('ë¶€ì •', summary.get('negative', 0), delta_color='inverse')
                        
                        # ê°œë³„ ê¸°ì‚¬ ê°ì„± (ë”ë¯¸ ë°ì´í„°)
                        st.subheader('ê°œë³„ ë‰´ìŠ¤ ê°ì„± (ìƒ˜í”Œ ë°ì´í„°)')
                        sentiments = sentiment_data.get('sentiments', [])
                        for i, item in enumerate(sentiments[:5]):
                            sentiment_color = 'green' if item['sentiment_category'] == 'Positive' else 'red' if item['sentiment_category'] == 'Negative' else 'gray'
                            st.markdown(f"**{item['title']}**")
                            st.markdown(f"ê°ì„±: <span style='color: {sentiment_color}'>{item['sentiment_category']}</span> (ì ìˆ˜: {item['sentiment_score']:.3f})", unsafe_allow_html=True)
                            st.markdown('---')
        
        # ì‚¬ìš©ë²• ì•ˆë‚´
        with st.expander('ğŸ’¡ GPT ë‰´ìŠ¤ ë¶„ì„ ì‚¬ìš©ë²•'):
            st.markdown("""
            **ğŸ”‘ OpenAI API í‚¤ ì„¤ì •**
            1. [OpenAI í™ˆí˜ì´ì§€](https://platform.openai.com/api-keys)ì—ì„œ API í‚¤ ë°œê¸‰
            2. ìœ„ì˜ ì…ë ¥ì°½ì— API í‚¤ ì…ë ¥
            3. ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° GPT ë¶„ì„ ìë™ ì‹¤í–‰
            
            **ğŸ“Š ì œê³µ ê¸°ëŠ¥**
            - **ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘**: Google ë‰´ìŠ¤ì—ì„œ ìµœì‹  ê¸°ì‚¬ ìˆ˜ì§‘
            - **GPT ì „ë¬¸ ë¶„ì„**: AI ê¸°ë°˜ ì‹¬ì¸µ ê°ì„± ë° ì‹œì¥ ë¶„ì„
            - **ê¸°ì‚¬ ë§í¬**: ì›ë¬¸ ê¸°ì‚¬ë¡œ ë°”ë¡œ ì´ë™ ê°€ëŠ¥
            - **ì¢…í•© íˆ¬ì ì¡°ì–¸**: ë‰´ìŠ¤ ê¸°ë°˜ íˆ¬ì ì‹œì‚¬ì  ì œê³µ
            
            **âš ï¸ ì£¼ì˜ì‚¬í•­**
            - API í‚¤ê°€ ì—†ì–´ë„ ê¸°ë³¸ ê°ì„± ë¶„ì„ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤
            - GPT ë¶„ì„ì€ OpenAI ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ê³¼ê¸ˆë©ë‹ˆë‹¤
            - ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ì€ ë„¤íŠ¸ì›Œí¬ ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
            """)
        
    
    with tab5:
        st.header('ğŸ’° ì¬ë¬´ ê±´ì „ì„± ë¶„ì„')
        
        if not symbols:
            st.warning('ì¢…ëª© ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
            return
        
        # OpenAI API í‚¤ ì…ë ¥ ì„¹ì…˜ ì¶”ê°€
        st.subheader('ğŸ”§ GPT ì¬ë¬´ ë¶„ì„ ì„¤ì • (ì„ íƒì‚¬í•­)')
        col1, col2 = st.columns([2, 1])
        
        with col1:
            financial_openai_api_key = st.text_input(
                "OpenAI API í‚¤ (GPT ê¸°ë°˜ ì¬ë¬´ ë¶„ì„ì„ ìœ„í•´ í•„ìš”)",
                type="password",
                help="GPTë¥¼ ì´ìš©í•œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ì¬ë¬´ ë¶„ì„ì„ ì›í•˜ì‹œë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
                key="financial_api_key"
            )
        
        with col2:
            if financial_openai_api_key:
                if financial_openai_api_key.startswith('sk-') and len(financial_openai_api_key) > 20:
                    st.success("âœ… API í‚¤ í™œì„±í™”")
                else:
                    st.error("âŒ ì˜ëª»ëœ API í‚¤")
        
        for symbol in symbols:
            st.subheader(f'{symbol} ì¬ë¬´ ë¶„ì„')
            
            with st.spinner(f'{symbol} ì¬ë¬´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘...'):
                financial_data = DataManager.get_financial_data(symbol)
                
                if financial_data:
                    metrics = FinancialAnalyzer.calculate_financial_metrics(financial_data)
                    
                    if metrics:
                        # 3ê°œë…„ ì¬ë¬´ ì‹¤ì  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                        financial_history = EconomicIndicatorAnalyzer.get_financial_history(symbol)
                        
                        # GPT ê¸°ë°˜ ì¬ë¬´ ë¶„ì„ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
                        if financial_openai_api_key:
                            st.subheader('ğŸ¤– AI ì¬ë¬´ ì „ë¬¸ê°€ ë¶„ì„')
                            
                            with st.spinner('GPTê°€ ì¬ë¬´ ì§€í‘œë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘...'):
                                gpt_analysis = FinancialAnalyzer.analyze_financial_metrics_with_gpt(
                                    metrics, financial_history, symbol, financial_openai_api_key
                                )
                            
                            if gpt_analysis.get('error'):
                                st.error(f"ğŸ¤– GPT ë¶„ì„ ì˜¤ë¥˜: {gpt_analysis['error']}")
                                st.info("ğŸ’¡ ê¸°ë³¸ ì¬ë¬´ ë¶„ì„ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                            else:
                                # GPT ë¶„ì„ ì„±ê³µ
                                score = gpt_analysis.get('score', 3.0)
                                grade_info = FinancialAnalyzer.get_financial_grade(score)
                                
                                # ì ìˆ˜ì™€ ë“±ê¸‰ í‘œì‹œ
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    st.metric(
                                        "ì¬ë¬´ ê±´ì „ì„± ì ìˆ˜",
                                        f"{score:.1f}/5.0",
                                        delta=f"{(score/5.0)*100:.0f}%"
                                    )
                                
                                with col2:
                                    if grade_info['color'] == 'success':
                                        st.success(f"ë“±ê¸‰: {grade_info['grade']} ({grade_info['description']})")
                                    elif grade_info['color'] == 'warning':
                                        st.warning(f"ë“±ê¸‰: {grade_info['grade']} ({grade_info['description']})")
                                    else:
                                        st.error(f"ë“±ê¸‰: {grade_info['grade']} ({grade_info['description']})")
                                
                                with col3:
                                    # ìƒíƒœì— ë”°ë¥¸ ì´ëª¨ì§€ í‘œì‹œ
                                    if score >= 4.0:
                                        st.success("ğŸ† ìš°ìˆ˜ ê¸°ì—…")
                                    elif score >= 3.0:
                                        st.info("ğŸ“Š ì–‘í˜¸í•œ ê¸°ì—…")
                                    elif score >= 2.0:
                                        st.warning("âš ï¸ ì£¼ì˜ í•„ìš”")
                                    else:
                                        st.error("ğŸš¨ ìœ„í—˜ ì‹ í˜¸")
                                
                                # GPT ë¶„ì„ ë‚´ìš© í‘œì‹œ
                                st.markdown("### ğŸ“‹ ì „ë¬¸ê°€ ì¬ë¬´ ë¶„ì„ ë¦¬í¬íŠ¸")
                                st.markdown(gpt_analysis['analysis'])
                                
                                st.markdown("---")
                        
                        # ê¸°ì¡´ ì¬ë¬´ ì§€í‘œ ì°¨íŠ¸ ë° ë°ì´í„° í‘œì‹œ
                        st.subheader('ğŸ“Š ì¬ë¬´ ì§€í‘œ ì‹œê°í™”')
                        fig = create_financial_metrics_chart(metrics)
                        st.plotly_chart(fig, use_container_width=True, key=f"financial_chart_{symbol}")
                        
                        # 3ê°œë…„ ì¬ë¬´ ì‹¤ì 
                        if financial_history and financial_history.get('years'):
                            st.subheader('ğŸ“ˆ ìµœê·¼ 3ê°œë…„ ì¬ë¬´ ì‹¤ì ')
                            fig_history = create_financial_history_chart(financial_history)
                            st.plotly_chart(fig_history, use_container_width=True, key=f"financial_history_{symbol}")
                            
                            # ì‹¤ì  ìš”ì•½ í…Œì´ë¸”
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.write('**ğŸ“ˆ ë§¤ì¶œ ì¶”ì´**')
                                for i, year in enumerate(financial_history['years']):
                                    revenue = financial_history['revenue'][i]
                                    if i > 0:
                                        prev_revenue = financial_history['revenue'][i-1]
                                        growth = ((revenue - prev_revenue) / prev_revenue * 100) if prev_revenue > 0 else 0
                                        st.write(f"â€¢ {year}: ${revenue:.1f}B ({growth:+.1f}%)")
                                    else:
                                        st.write(f"â€¢ {year}: ${revenue:.1f}B")
                            
                            with col2:
                                st.write('**ğŸ’¼ ì˜ì—…ì´ìµ ì¶”ì´**')
                                for i, year in enumerate(financial_history['years']):
                                    op_income = financial_history['operating_income'][i]
                                    if i > 0:
                                        prev_op = financial_history['operating_income'][i-1]
                                        growth = ((op_income - prev_op) / prev_op * 100) if prev_op > 0 else 0
                                        st.write(f"â€¢ {year}: ${op_income:.1f}B ({growth:+.1f}%)")
                                    else:
                                        st.write(f"â€¢ {year}: ${op_income:.1f}B")
                            
                            with col3:
                                st.write('**ğŸ’° ìˆœì´ìµ ì¶”ì´**')
                                for i, year in enumerate(financial_history['years']):
                                    net_income = financial_history['net_income'][i]
                                    if i > 0:
                                        prev_net = financial_history['net_income'][i-1]
                                        growth = ((net_income - prev_net) / prev_net * 100) if prev_net > 0 else 0
                                        st.write(f"â€¢ {year}: ${net_income:.1f}B ({growth:+.1f}%)")
                                    else:
                                        st.write(f"â€¢ {year}: ${net_income:.1f}B")
                        else:
                            st.info("3ê°œë…„ ì¬ë¬´ ì‹¤ì  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                        # ì£¼ìš” ì¬ë¬´ ì§€í‘œ ìš”ì•½
                        st.subheader('ğŸ“‹ ì£¼ìš” ì¬ë¬´ ì§€í‘œ ìš”ì•½')
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            pe_ratio = metrics.get('pe_ratio', 0)
                            pe_color = 'normal' if 10 <= pe_ratio <= 25 else 'inverse' if pe_ratio > 25 else 'off'
                            st.metric('P/E ë¹„ìœ¨', f"{pe_ratio:.2f}", delta="ì ì •" if pe_color == 'normal' else "ë†’ìŒ" if pe_ratio > 25 else "ë‚®ìŒ", delta_color=pe_color)
                            
                            roe = metrics.get('roe', 0)*100
                            roe_color = 'normal' if roe > 15 else 'inverse'
                            st.metric('ROE', f"{roe:.1f}%", delta="ìš°ìˆ˜" if roe > 15 else "ê°œì„ í•„ìš”", delta_color=roe_color)
                        
                        with col2:
                            pb_ratio = metrics.get('pb_ratio', 0)
                            pb_color = 'normal' if pb_ratio < 3 else 'inverse'
                            st.metric('P/B ë¹„ìœ¨', f"{pb_ratio:.2f}", delta="ì ì •" if pb_color == 'normal' else "ë†’ìŒ", delta_color=pb_color)
                            
                            debt_ratio = metrics.get('debt_to_equity', 0)
                            debt_color = 'normal' if debt_ratio < 0.5 else 'inverse'
                            st.metric('ë¶€ì±„ë¹„ìœ¨', f"{debt_ratio:.2f}", delta="ì•ˆì „" if debt_color == 'normal' else "ì£¼ì˜", delta_color=debt_color)
                        
                        with col3:
                            profit_margin = metrics.get('profit_margin', 0)*100
                            margin_color = 'normal' if profit_margin > 10 else 'inverse'
                            st.metric('ìˆœì´ìµë¥ ', f"{profit_margin:.1f}%", delta="ìš°ìˆ˜" if margin_color == 'normal' else "ê°œì„ í•„ìš”", delta_color=margin_color)
                            
                            current_ratio = metrics.get('current_ratio', 0)
                            current_color = 'normal' if current_ratio > 1.5 else 'inverse'
                            st.metric('ìœ ë™ë¹„ìœ¨', f"{current_ratio:.2f}", delta="ì•ˆì „" if current_color == 'normal' else "ì£¼ì˜", delta_color=current_color)
                        
                        with col4:
                            market_cap = metrics.get('market_cap', 0)
                            st.metric('ì‹œê°€ì´ì•¡', f"${market_cap/1e9:.1f}B" if market_cap > 0 else "N/A")
                            
                            dividend_yield = metrics.get('dividend_yield', 0)
                            st.metric('ë°°ë‹¹ìˆ˜ìµë¥ ', f"{dividend_yield:.1f}%" if dividend_yield > 0 else "0.0%")
                        
                        # ìƒì„¸ ì¬ë¬´ ì •ë³´ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
                        with st.expander('ğŸ“Š ìƒì„¸ ì¬ë¬´ ì •ë³´'):
                            info = financial_data.get('info', {})
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.write('**ğŸ¢ ê¸°ì—… ì •ë³´**')
                                st.write(f"â€¢ ê¸°ì—…ëª…: {info.get('longName', 'N/A')}")
                                st.write(f"â€¢ ì„¹í„°: {info.get('sector', 'N/A')}")
                                st.write(f"â€¢ ì‚°ì—…: {info.get('industry', 'N/A')}")
                                st.write(f"â€¢ ì§ì› ìˆ˜: {info.get('fullTimeEmployees', 'N/A'):,}" if info.get('fullTimeEmployees') else "â€¢ ì§ì› ìˆ˜: N/A")
                            
                            with col2:
                                st.write('**ğŸ’° ìƒì„¸ ì¬ë¬´ ì§€í‘œ**')
                                fcf = metrics.get('free_cash_flow', 0)
                                st.write(f"â€¢ ììœ í˜„ê¸ˆíë¦„: ${fcf/1e9:.2f}B" if fcf > 0 else "â€¢ ììœ í˜„ê¸ˆíë¦„: N/A")
                                revenue_growth = metrics.get('revenue_growth', 0)
                                st.write(f"â€¢ ë§¤ì¶œ ì„±ì¥ë¥ : {revenue_growth*100:.1f}%" if revenue_growth else "â€¢ ë§¤ì¶œ ì„±ì¥ë¥ : N/A")
                                st.write(f"â€¢ ì´ ë§¤ì¶œ: ${info.get('totalRevenue', 0)/1e9:.2f}B" if info.get('totalRevenue') else "â€¢ ì´ ë§¤ì¶œ: N/A")
                                st.write(f"â€¢ ì´ í˜„ê¸ˆ: ${info.get('totalCash', 0)/1e9:.2f}B" if info.get('totalCash') else "â€¢ ì´ í˜„ê¸ˆ: N/A")
                else:
                    st.error(f'{symbol}ì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        
        # ì‚¬ìš©ë²• ì•ˆë‚´
        with st.expander('ğŸ’¡ GPT ì¬ë¬´ ë¶„ì„ ì‚¬ìš©ë²•'):
            st.markdown("""
            **ğŸ”‘ OpenAI API í‚¤ ì„¤ì •**
            1. [OpenAI í™ˆí˜ì´ì§€](https://platform.openai.com/api-keys)ì—ì„œ API í‚¤ ë°œê¸‰
            2. ìœ„ì˜ ì…ë ¥ì°½ì— API í‚¤ ì…ë ¥
            3. AI ê¸°ë°˜ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ì¬ë¬´ ë¶„ì„ ìë™ ì‹¤í–‰
            
            **ğŸ“Š ì œê³µí•˜ëŠ” ë¶„ì„**
            - **ì¬ë¬´ ê±´ì „ì„± ì¢…í•© í‰ê°€**: 5ì  ë§Œì  ì ìˆ˜ ë° ë“±ê¸‰
            - **ì£¼ìš” ê°•ì  ë° ì•½ì **: êµ¬ì²´ì ì¸ ë¶„ì„ê³¼ ê°œì„ ì 
            - **ì—…ì¢… ëŒ€ë¹„ ê²½ìŸë ¥**: ìƒëŒ€ì  ìœ„ì¹˜ í‰ê°€
            - **íˆ¬ìì ê´€ì  ë¶„ì„**: ì¥ê¸°/ë‹¨ê¸° íˆ¬ì ì‹œê°
            - **ì¬ë¬´ ê°œì„  ê³¼ì œ**: ëª¨ë‹ˆí„°ë§ í•„ìš” ì§€í‘œ
            - **íˆ¬ì ì˜ê²¬**: ë§¤ìˆ˜/ë³´ìœ /ë§¤ë„ ì¶”ì²œ ë° ê·¼ê±°
            
            **ğŸ¯ ë¶„ì„ íŠ¹ì§•**
            - ì „ë¬¸ ì¬ë¬´ ë¶„ì„ê°€ ìˆ˜ì¤€ì˜ ì¸ì‚¬ì´íŠ¸
            - 3ê°œë…„ ì‹¤ì  íŠ¸ë Œë“œ ë°˜ì˜
            - ì—…ì¢…ë³„ ë²¤ì¹˜ë§ˆí‚¹
            - ì‹¤ìš©ì ì¸ íˆ¬ì ì¡°ì–¸
            
            **âš ï¸ ì£¼ì˜ì‚¬í•­**
            - API í‚¤ê°€ ì—†ì–´ë„ ê¸°ë³¸ ì¬ë¬´ ë¶„ì„ì€ ê°€ëŠ¥
            - GPT ë¶„ì„ì€ OpenAI ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ê³¼ê¸ˆ
            - AI ë¶„ì„ì€ ì°¸ê³ ìš©ì´ë©° ìµœì¢… íˆ¬ì ê²°ì •ì€ ë³¸ì¸ ì±…ì„
            """)
    
    with tab6:
        st.header('ğŸŒ ëŒ€ì™¸ ê²½ì œì§€í‘œ ë¶„ì„')
        
        with st.spinner('ê²½ì œì§€í‘œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
            indicators = EconomicIndicatorAnalyzer.get_economic_indicators()
            
            if indicators:
                # ê²½ì œì§€í‘œ ìš”ì•½ ì¹´ë“œ
                st.subheader('ğŸ“Š ì£¼ìš” ê²½ì œì§€í‘œ í˜„í™©')
                
                # 4ê°œì”© 2í–‰ìœ¼ë¡œ ë°°ì¹˜
                cols = st.columns(4)
                indicator_names = {
                    'sp500': 'S&P 500',
                    'nasdaq': 'ë‚˜ìŠ¤ë‹¥',
                    'dow': 'ë‹¤ìš°ì¡´ìŠ¤',
                    'gold': 'ê¸ˆ ê°€ê²©',
                    'oil': 'ì›ìœ  ê°€ê²©',
                    'dollar_index': 'ë‹¬ëŸ¬ ì¸ë±ìŠ¤',
                    'us_10yr': 'ë¯¸êµ­ 10ë…„ êµ­ì±„',
                    'vix': 'VIX ê³µí¬ì§€ìˆ˜'
                }
                
                for i, (key, display_name) in enumerate(indicator_names.items()):
                    if key in indicators:
                        with cols[i % 4]:
                            current_price = indicators[key]['current_price']
                            change_pct = indicators[key]['change_pct']
                            
                            # ë‹¨ìœ„ ì„¤ì •
                            if key in ['gold', 'oil']:
                                unit = ''
                            elif key in ['us_10yr', 'vix']:
                                unit = '%'
                            else:
                                unit = ''
                            
                            st.metric(
                                display_name,
                                f"{current_price:.2f}{unit}",
                                f"{change_pct:+.2f}%"
                            )
                
                st.markdown('---')
                
                # ì°¨íŠ¸ ìƒì„± ë° í‘œì‹œ
                charts = create_economic_indicators_dashboard(indicators)
                
                if 'indices' in charts:
                    st.subheader('ğŸ“ˆ ì£¼ìš” ì£¼ì‹ ì§€ìˆ˜ ì¶”ì´')
                    st.plotly_chart(charts['indices'], use_container_width=True, key="indices_chart")
                
                if 'bonds' in charts:
                    st.subheader('ğŸ’¹ ë¯¸êµ­ êµ­ì±„ ìˆ˜ìµë¥ ')
                    st.plotly_chart(charts['bonds'], use_container_width=True, key="bonds_chart")
                
                if 'commodities' in charts:
                    st.subheader('ğŸ¥‡ ì›ìì¬ ê°€ê²©')
                    st.plotly_chart(charts['commodities'], use_container_width=True, key="commodities_chart")
                
                # ì¶”ê°€ ì§€í‘œë“¤
                col1, col2 = st.columns(2)
                
                with col1:
                    if 'dollar_index' in indicators:
                        st.subheader('ğŸ’µ ë‹¬ëŸ¬ ì¸ë±ìŠ¤')
                        dollar_data = indicators['dollar_index']['data']
                        fig_dollar = go.Figure()
                        fig_dollar.add_trace(go.Scatter(
                            x=dollar_data.index,
                            y=dollar_data['Close'],
                            mode='lines',
                            name='ë‹¬ëŸ¬ ì¸ë±ìŠ¤',
                            line=dict(color='green', width=2)
                        ))
                        fig_dollar.update_layout(
                            xaxis_title='ë‚ ì§œ',
                            yaxis_title='ì§€ìˆ˜',
                            height=300
                        )
                        st.plotly_chart(fig_dollar, use_container_width=True, key="dollar_chart")
                
                with col2:
                    if 'vix' in indicators:
                        st.subheader('ğŸ˜° VIX ê³µí¬ì§€ìˆ˜')
                        vix_data = indicators['vix']['data']
                        current_vix = indicators['vix']['current_price']
                        
                        fig_vix = go.Figure()
                        fig_vix.add_trace(go.Scatter(
                            x=vix_data.index,
                            y=vix_data['Close'],
                            mode='lines',
                            name='VIX',
                            line=dict(color='red', width=2)
                        ))
                        
                        # VIX êµ¬ê°„ë³„ ìƒ‰ìƒ í‘œì‹œ
                        fig_vix.add_hline(y=30, line_dash="dash", line_color="red", 
                                         annotation_text="ê³µí¬ êµ¬ê°„ (30)")
                        fig_vix.add_hline(y=20, line_dash="dash", line_color="orange", 
                                         annotation_text="ê¸´ì¥ êµ¬ê°„ (20)")
                        fig_vix.add_hline(y=12, line_dash="dash", line_color="green", 
                                         annotation_text="ì•ˆì • êµ¬ê°„ (12)")
                        
                        fig_vix.update_layout(
                            xaxis_title='ë‚ ì§œ',
                            yaxis_title='ë³€ë™ì„± (%)',
                            height=300
                        )
                        st.plotly_chart(fig_vix, use_container_width=True, key="vix_chart")
                        
                        # VIX í•´ì„ í‘œì‹œ
                        vix_interpretation = EconomicIndicatorAnalyzer.interpret_vix(current_vix)
                        
                        if vix_interpretation['color'] == 'error':
                            st.error(f"""
                            **{vix_interpretation['emoji']} {vix_interpretation['level']}**: {vix_interpretation['message']}
                            
                            ğŸ’¡ **íˆ¬ì ì¡°ì–¸**: {vix_interpretation['advice']}
                            """)
                        elif vix_interpretation['color'] == 'warning':
                            st.warning(f"""
                            **{vix_interpretation['emoji']} {vix_interpretation['level']}**: {vix_interpretation['message']}
                            
                            ğŸ’¡ **íˆ¬ì ì¡°ì–¸**: {vix_interpretation['advice']}
                            """)
                        else:
                            st.success(f"""
                            **{vix_interpretation['emoji']} {vix_interpretation['level']}**: {vix_interpretation['message']}
                            
                            ğŸ’¡ **íˆ¬ì ì¡°ì–¸**: {vix_interpretation['advice']}
                            """)
                
                # ê²½ì œì§€í‘œ í•´ì„ ê°€ì´ë“œ
                with st.expander('ğŸ“š ê²½ì œì§€í‘œ í•´ì„ ê°€ì´ë“œ'):
                    st.markdown("""
                    **ì£¼ì‹ ì§€ìˆ˜**
                    - **S&P 500**: ë¯¸êµ­ ëŒ€í˜•ì£¼ 500ê°œ ê¸°ì—…ì˜ ì‹œê°€ì´ì•¡ ê°€ì¤‘ ì§€ìˆ˜
                    - **ë‚˜ìŠ¤ë‹¥**: ê¸°ìˆ ì£¼ ì¤‘ì‹¬ì˜ ì§€ìˆ˜, ì„±ì¥ì£¼ íˆ¬ì ê¸°ì¤€
                    - **ë‹¤ìš°ì¡´ìŠ¤**: ë¯¸êµ­ ìš°ëŸ‰ì£¼ 30ê°œ ê¸°ì—…ì˜ ì£¼ê°€ í‰ê· 
                    
                    **ì±„ê¶Œ ìˆ˜ìµë¥ **
                    - **10ë…„ êµ­ì±„**: ì¥ê¸° ê¸ˆë¦¬ ê¸°ì¤€, ê²½ì œ ì „ë§ ë°˜ì˜
                    - **2ë…„ êµ­ì±„**: ë‹¨ê¸° ê¸ˆë¦¬ ê¸°ì¤€, ì—°ì¤€ ì •ì±… ë°˜ì˜
                    
                    **ì›ìì¬**
                    - **ê¸ˆ**: ì•ˆì „ìì‚°, ì¸í”Œë ˆì´ì…˜ í—¤ì§€ ìˆ˜ë‹¨
                    - **ì›ìœ **: ê²½ê¸° ì„ í–‰ì§€í‘œ, ì—ë„ˆì§€ ë¹„ìš© ê¸°ì¤€
                    
                    **ê¸°íƒ€ ì§€í‘œ**
                    - **ë‹¬ëŸ¬ ì¸ë±ìŠ¤**: ë‹¬ëŸ¬ ê°•ì„¸/ì•½ì„¸ ì¸¡ì •
                    - **VIX**: ì‹œì¥ ë³€ë™ì„±ê³¼ íˆ¬ìì ë¶ˆì•ˆê° ì¸¡ì •
                    
                    **ğŸ“Š VIX ê³µí¬ì§€ìˆ˜ ìƒì„¸ í•´ì„**
                    
                    - **ğŸš¨ 50+ (ê·¹ë„ ê³µí¬)**: íŒ¨ë‹‰ ìƒíƒœ, ì—­ì„¤ì  ë§¤ìˆ˜ ê¸°íšŒ
                    - **ğŸ˜° 30-50 (ë†’ì€ ê³µí¬)**: ì‹œì¥ ë¶ˆì•ˆì •, ì£¼ì˜ ê¹Šì€ íˆ¬ì
                    - **âš ï¸ 20-30 (ë³´í†µ ê¸´ì¥)**: ì •ìƒì ì¸ ë³€ë™ì„± ìˆ˜ì¤€
                    - **ğŸ˜Œ 12-20 (ì•ˆì •)**: ì •ìƒì ì¸ íˆ¬ì í™˜ê²½
                    - **ğŸ˜´ 12 ë¯¸ë§Œ (ê·¹ë„ ì•ˆì •)**: ê³¼ë„í•œ ë‚™ê´€ë¡ , ì£¼ì˜ í•„ìš”
                    
                    **ì›Œë Œ ë²„í• ê´€ì ì—ì„œ VIX í™œìš©ë²•**
                    - VIX ë†’ìŒ = "ë‚¨ë“¤ì´ ë‘ë ¤ì›Œí•  ë•Œ" = ë§¤ìˆ˜ ê¸°íšŒ
                    - VIX ë‚®ìŒ = "ë‚¨ë“¤ì´ ìš•ì‹¬ë‚¼ ë•Œ" = ì‹ ì¤‘í•´ì•¼ í•  ë•Œ
                    """)
            else:
                st.error('ê²½ì œì§€í‘œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')

        st.markdown('---')

        # GPT ê¸°ë°˜ ì¢…í•© ê²½ì œ ë¶„ì„
        st.subheader('ğŸ¤– AI ê¸°ë°˜ ì¢…í•© ê²½ì œí™˜ê²½ ë¶„ì„')

        # API í‚¤ ì…ë ¥
        col1, col2 = st.columns([3, 1])

        with col1:
            economic_openai_api_key = st.text_input(
                "OpenAI API í‚¤ (GPT ê¸°ë°˜ ì¢…í•© ê²½ì œ ë¶„ì„ì„ ìœ„í•´ í•„ìš”)",
                type="password",
                help="GPTë¥¼ ì´ìš©í•œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ê²½ì œí™˜ê²½ ë¶„ì„ì„ ì›í•˜ì‹œë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
                key="economic_analysis_api_key"
            )

        with col2:
            if economic_openai_api_key:
                if economic_openai_api_key.startswith('sk-') and len(economic_openai_api_key) > 20:
                    st.success("âœ… API í‚¤ í™œì„±í™”")
                else:
                    st.error("âŒ ì˜ëª»ëœ API í‚¤")

        # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
        if economic_openai_api_key and indicators:
            if st.button("ğŸš€ ì¢…í•© ê²½ì œí™˜ê²½ ë¶„ì„ ì‹œì‘", use_container_width=True, type="primary"):
                with st.spinner('ğŸ“Š GPTê°€ ëª¨ë“  ê²½ì œì§€í‘œë¥¼ ì¢…í•© ë¶„ì„í•˜ëŠ” ì¤‘...'):
                    gpt_economic_analysis = EconomicIndicatorAnalyzer.analyze_economic_indicators_with_gpt(
                        indicators, economic_openai_api_key
                    )
                
                if gpt_economic_analysis.get('error'):
                    st.error(f"ğŸ¤– ë¶„ì„ ì˜¤ë¥˜: {gpt_economic_analysis['error']}")
                else:
                    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                    score = gpt_economic_analysis.get('score', 3.0)
                    environment = gpt_economic_analysis.get('environment', 'ì¤‘ë¦½ì ')
                    env_color = gpt_economic_analysis.get('environment_color', 'warning')
                    
                    # ì¢…í•© ì ìˆ˜ ë° í™˜ê²½ í‘œì‹œ
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric(
                            "ê²½ì œí™˜ê²½ ì ìˆ˜",
                            f"{score:.1f}/5.0",
                            delta=f"{(score/5.0)*100:.0f}%"
                        )
                    
                    with col2:
                        if env_color == 'success':
                            st.success(f"ğŸ“ˆ {environment}")
                        elif env_color == 'warning':
                            st.warning(f"ğŸ“Š {environment}")
                        else:
                            st.error(f"ğŸ“‰ {environment}")
                    
                    with col3:
                        # ìƒíƒœì— ë”°ë¥¸ íˆ¬ì ê°€ì´ë“œ
                        if score >= 4.0:
                            st.success("ğŸš€ ê³µê²©ì  íˆ¬ì í™˜ê²½")
                        elif score >= 3.0:
                            st.info("âš–ï¸ ê· í˜•ì¡íŒ íˆ¬ì")
                        else:
                            st.error("ğŸ›¡ï¸ ë°©ì–´ì  íˆ¬ì í™˜ê²½")
                    
                    # GPT ë¶„ì„ ë‚´ìš© í‘œì‹œ
                    st.markdown("### ğŸ“‹ ì¢…í•© ê²½ì œí™˜ê²½ ë¶„ì„ ë¦¬í¬íŠ¸")
                    st.markdown(gpt_economic_analysis['analysis'])

        elif not economic_openai_api_key:
            st.info("""
            ğŸ”‘ **OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì‹œë©´ ë‹¤ìŒê³¼ ê°™ì€ ê³ ê¸‰ ë¶„ì„ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:**
            
            â€¢ **ì¢…í•© ê²½ì œ ìƒí™© ì§„ë‹¨**: ëª¨ë“  ì§€í‘œë¥¼ ì¢…í•©í•œ 5ì  ë§Œì  ì ìˆ˜
            â€¢ **íˆ¬ì í™˜ê²½ ë¶„ë¥˜**: Risk-On/Risk-Off íŒë‹¨
            â€¢ **ì„¹í„°ë³„ ì˜í–¥ ë¶„ì„**: ì–´ë–¤ ì„¹í„°ê°€ ìœ ë¦¬/ë¶ˆë¦¬í•œì§€
            â€¢ **ìì‚°ë°°ë¶„ ê°€ì´ë“œ**: í˜„ì¬ ìƒí™©ì— ë§ëŠ” íˆ¬ì ì „ëµ
            â€¢ **ë¦¬ìŠ¤í¬ ìš”ì¸ ì§„ë‹¨**: ì£¼ì˜í•´ì•¼ í•  ìœ„í—˜ ìš”ì†Œë“¤
            â€¢ **ë‹¨ê¸° ì „ë§**: 1-3ê°œì›” ì‹œì¥ ì‹œë‚˜ë¦¬ì˜¤
            """)

        elif not indicators:
            st.warning("ê²½ì œì§€í‘œ ë°ì´í„°ë¥¼ ë¨¼ì € ë¶ˆëŸ¬ì™€ì•¼ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        # ê²½ì œì§€í‘œ í™œìš© ê°€ì´ë“œ
        with st.expander('ğŸ’¡ GPT ê²½ì œë¶„ì„ í™œìš©ë²•'):
            st.markdown("""
            **ğŸ¯ ì œê³µí•˜ëŠ” ë¶„ì„**
            - **ì¢…í•© ì ìˆ˜**: ëª¨ë“  ì§€í‘œë¥¼ ê³ ë ¤í•œ 5ì  ë§Œì  ì ìˆ˜
            - **íˆ¬ì í™˜ê²½**: Risk-On/Risk-Off ë¶„ë¥˜
            - **ìì‚°ë°°ë¶„ ê°€ì´ë“œ**: ì£¼ì‹/ì±„ê¶Œ/ì›ìì¬/í˜„ê¸ˆ ë¹„ì¤‘ ì¡°ì–¸
            - **ë¦¬ìŠ¤í¬ ì§„ë‹¨**: ì£¼ìš” ìœ„í—˜ ìš”ì¸ ì‹ë³„
            - **ì„¹í„° ì „ë§**: ìœ ë¦¬í•œ ì„¹í„°ì™€ ë¶ˆë¦¬í•œ ì„¹í„°
            - **ë‹¨ê¸° ì „ë§**: 1-3ê°œì›” ì‹œì¥ ì‹œë‚˜ë¦¬ì˜¤
            
            **ğŸ“Š ë¶„ì„ ê¸°ì¤€**
            - ì£¼ì‹ ì§€ìˆ˜: ì‹œì¥ ì‹¬ë¦¬ ë° ìœ„í—˜ì„ í˜¸ë„
            - êµ­ì±„ ìˆ˜ìµë¥ : ê¸ˆë¦¬ í™˜ê²½ ë° ê²½ê¸° ì „ë§
            - ì›ìì¬: ì¸í”Œë ˆì´ì…˜ ì••ë ¥ ë° ì‹¤ë¬¼ê²½ê¸°
            - ë‹¬ëŸ¬/VIX: ê¸€ë¡œë²Œ ìœ ë™ì„± ë° ë¦¬ìŠ¤í¬
            
            **ğŸš€ í™œìš© ë°©ë²•**
            1. API í‚¤ ì…ë ¥ í›„ ë¶„ì„ ì‹œì‘
            2. ì¢…í•© ì ìˆ˜ì™€ í™˜ê²½ ë¶„ë¥˜ í™•ì¸
            3. ìì‚°ë°°ë¶„ ê°€ì´ë“œ ì°¸ê³ 
            4. ë¦¬ìŠ¤í¬ ìš”ì¸ ëª¨ë‹ˆí„°ë§
            5. ê°œë³„ ì¢…ëª© ë¶„ì„ê³¼ ê²°í•©í•˜ì—¬ íˆ¬ì ê²°ì •
            
            **âš ï¸ ì£¼ì˜ì‚¬í•­**
            - AI ë¶„ì„ì€ ì°¸ê³ ìš©ì´ë©° íˆ¬ì ë³´ì¥í•˜ì§€ ì•ŠìŒ
            - ê¸‰ë³€í•˜ëŠ” ì‹œì¥ ìƒí™© ì‹¤ì‹œê°„ ë°˜ì˜ í•œê³„
            - ë‹¤ë¥¸ ë¶„ì„ê³¼ í•¨ê»˜ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨ í•„ìš”
            - ê°œì¸ íˆ¬ì ì„±í–¥ê³¼ ëª©í‘œ ê³ ë ¤ í•„ìˆ˜
            """)
    
    with tab7:
        st.header('ğŸ§  ì›Œë Œ ë²„í• ìŠ¤íƒ€ì¼ íˆ¬ì ì¡°ì–¸')
        
        if not symbols:
            st.warning('ì¢…ëª© ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
            return
        
        for symbol in symbols:
            st.subheader(f'{symbol} ë²„í• ìŠ¤íƒ€ì¼ ë¶„ì„')
            
            with st.spinner(f'{symbol}ì„ ì›Œë Œ ë²„í•ì˜ ê´€ì ì—ì„œ ë¶„ì„í•˜ëŠ” ì¤‘...'):
                # ë°ì´í„° ìˆ˜ì§‘
                financial_data = DataManager.get_financial_data(symbol)
                sentiment_data = SentimentAnalyzer.get_news_sentiment(symbol)
                
                if financial_data:
                    metrics = FinancialAnalyzer.calculate_financial_metrics(financial_data)
                    analysis = BuffettAnalyzer.buffett_analysis(metrics, sentiment_data)
                    
                    if analysis:
                        # íˆ¬ì ë“±ê¸‰ í‘œì‹œ
                        grade_class = analysis.get('grade_color', 'hold-signal')
                        st.markdown(f"""
                        <div class="{grade_class}">
                            <h3>íˆ¬ì ë“±ê¸‰: {analysis.get('grade', 'N/A')}</h3>
                            <p>{analysis.get('recommendation', '')}</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # ì ìˆ˜ í‘œì‹œ
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric(
                                'ë²„í• ì ìˆ˜',
                                f"{analysis.get('score', 0)}/{analysis.get('max_score', 100)}",
                                delta=f"{analysis.get('score', 0)}ì "
                            )
                        
                        with col2:
                            percentage = (analysis.get('score', 0) / analysis.get('max_score', 100)) * 100
                            st.metric(
                                'ì í•©ë„',
                                f"{percentage:.1f}%"
                            )
                        
                        with col3:
                            grade = analysis.get('grade', 'HOLD')
                            if grade == 'BUY':
                                st.success('ğŸš€ ë§¤ìˆ˜')
                            elif grade == 'SELL':
                                st.error('âš ï¸ ë§¤ë„')
                            else:
                                st.warning('ğŸ“Š ë³´ìœ ')
                        
                        # ë¶„ì„ ê·¼ê±°
                        st.subheader('ğŸ“‹ ë¶„ì„ ê·¼ê±°')
                        reasons = analysis.get('reasons', [])
                        
                        for reason in reasons:
                            if 'âœ…' in reason:
                                st.success(reason)
                            elif 'âš ï¸' in reason:
                                st.warning(reason)
                            elif 'âŒ' in reason:
                                st.error(reason)
                            else:
                                st.info(reason)
                        
                        # ì›Œë Œ ë²„í•ì˜ íˆ¬ì ì² í•™
                        with st.expander('ğŸ“š ì›Œë Œ ë²„í•ì˜ íˆ¬ì ì² í•™'):
                            st.markdown("""
                            **ì›Œë Œ ë²„í•ì˜ í•µì‹¬ íˆ¬ì ì›ì¹™:**
                            
                            1. **ì‚¬ì—… ì´í•´í•˜ê¸°**: ìì‹ ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‚¬ì—…ì—ë§Œ íˆ¬ì
                            2. **ê²½ì œì  í•´ì**: ê²½ìŸìš°ìœ„ë¥¼ ê°€ì§„ ê¸°ì—… ì„ í˜¸
                            3. **ìš°ìˆ˜í•œ ê²½ì˜ì§„**: ì£¼ì£¼ ê°€ì¹˜ë¥¼ ì¤‘ì‹œí•˜ëŠ” ê²½ì˜ì§„
                            4. **í•©ë¦¬ì  ê°€ê²©**: ë‚´ì¬ê°€ì¹˜ ëŒ€ë¹„ ì €í‰ê°€ëœ ì£¼ì‹
                            5. **ì¥ê¸° íˆ¬ì**: "ì˜ì›íˆ ë³´ìœ í•  ìˆ˜ ìˆëŠ” ì£¼ì‹"
                            
                            **ì£¼ìš” ì¬ë¬´ ì§€í‘œ:**
                            - ROE > 15%
                            - ê¾¸ì¤€í•œ ììœ í˜„ê¸ˆíë¦„
                            - ë‚®ì€ ë¶€ì±„ë¹„ìœ¨
                            - ì•ˆì •ì ì¸ ìˆ˜ìµì„±
                            - ì ì •í•œ P/E ë¹„ìœ¨ (10-20)
                            """)
                        
                        # ë¦¬ìŠ¤í¬ ìš”ì¸
                        st.subheader('âš ï¸ íˆ¬ì ë¦¬ìŠ¤í¬')
                        st.warning("""
                        **ì£¼ìš” ë¦¬ìŠ¤í¬ ìš”ì¸:**
                        - ì‹œì¥ ë³€ë™ì„±ì— ë”°ë¥¸ ì£¼ê°€ í•˜ë½ ìœ„í—˜
                        - ê¸°ì—… ì‹¤ì  ì•…í™” ê°€ëŠ¥ì„±
                        - ì‚°ì—… ì „ë°˜ì˜ êµ¬ì¡°ì  ë³€í™”
                        - ê±°ì‹œê²½ì œ ì•…í™” ì˜í–¥
                        - ì˜ˆì¸¡ ëª¨ë¸ì˜ í•œê³„
                        
                        **íˆ¬ì ì „ ê³ ë ¤ì‚¬í•­:**
                        - ê°œì¸ íˆ¬ì ëª©í‘œ ë° ìœ„í—˜ ì„±í–¥ í™•ì¸
                        - ì¶©ë¶„í•œ ì¶”ê°€ ì¡°ì‚¬ ë° ë¶„ì„ í•„ìš”
                        - ë¶„ì‚° íˆ¬ìë¥¼ í†µí•œ ë¦¬ìŠ¤í¬ ê´€ë¦¬
                        - ì •ê¸°ì ì¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë·°
                        """)
                else:
                    st.error(f'{symbol}ì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')

    # ìœ íŠœë¸Œ ë¶„ì„ íƒ­ ê°œì„  ì½”ë“œ (tab8 ë¶€ë¶„ë§Œ)
    with tab8:
        st.header('ğŸ“º ìœ íŠœë¸Œ ì˜ìƒ ë¶„ì„ (í–¥ìƒëœ ë²„ì „)')
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” - ë” ì•ˆì •ì ì¸ ë°©ë²•
        if 'selected_videos' not in st.session_state:
            st.session_state.selected_videos = {}
        if 'video_summaries' not in st.session_state:
            st.session_state.video_summaries = {}
        if 'search_results' not in st.session_state:
            st.session_state.search_results = []
        if 'last_search_query' not in st.session_state:
            st.session_state.last_search_query = ""
        if 'filtered_results' not in st.session_state:
            st.session_state.filtered_results = []
        
        # OpenAI API í‚¤ ì…ë ¥
        st.subheader('ğŸ”§ GPT ìš”ì•½ ì„¤ì • (ì„ íƒì‚¬í•­)')
        openai_api_key = st.text_input(
            "OpenAI API í‚¤ (ì˜ìƒ ìš”ì•½ì„ ìœ„í•´ í•„ìš”)",
            type="password",
            help="GPTë¥¼ ì´ìš©í•œ ì˜ìƒ ìš”ì•½ì„ ì›í•˜ì‹œë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
            key="youtube_api_key"
        )
        
        # ê²€ìƒ‰ ì„¹ì…˜
        st.subheader('ğŸ” ìœ íŠœë¸Œ ê²€ìƒ‰')
        
        # ê²€ìƒ‰ ì„¤ì •
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # ê²€ìƒ‰ í¼ ì‚¬ìš©í•˜ì—¬ ìë™ ì¬ë¡œë“œ ë°©ì§€
            with st.form("youtube_search_form"):
                search_query = st.text_input(
                    "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                    value=st.session_state.last_search_query,
                    placeholder="ì˜ˆ: AAPL ì£¼ì‹ ë¶„ì„, ì• í”Œ íˆ¬ì ì „ë§, í…ŒìŠ¬ë¼ ì‹¤ì  ë¶„ì„",
                    help="ì£¼ì‹ ì¢…ëª©ëª…ì´ë‚˜ íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
                )
                
                # ê²€ìƒ‰ ì˜µì…˜
                search_col1, search_col2 = st.columns(2)
                
                with search_col1:
                    max_results = st.selectbox(
                        "ê²€ìƒ‰ ê²°ê³¼ ìˆ˜",
                        [20, 30, 50, 100],
                        index=1,
                        help="ë” ë§ì€ ê²°ê³¼ë¥¼ ì›í•˜ì‹œë©´ í° ìˆ«ìë¥¼ ì„ íƒí•˜ì„¸ìš”"
                    )
                
                with search_col2:
                    initial_sort = st.selectbox(
                        "ì´ˆê¸° ì •ë ¬",
                        ["ê´€ë ¨ë„", "ìµœì‹ ìˆœ", "ì¡°íšŒìˆ˜ìˆœ", "í‰ì ìˆœ"],
                        help="ê²€ìƒ‰ ì‹œ ì ìš©í•  ê¸°ë³¸ ì •ë ¬ ë°©ì‹"
                    )
                
                search_button = st.form_submit_button("ğŸ” ê²€ìƒ‰", use_container_width=True)
        
        with col2:
            st.info("""
            **ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥:**
            â€¢ ê²€ìƒ‰ ê²°ê³¼ ìµœëŒ€ 100ê°œ
            â€¢ ì¡°íšŒìˆ˜/ì—…ë¡œë“œì¼/ì¬ìƒì‹œê°„ í•„í„°
            â€¢ ë‹¤ì–‘í•œ ì •ë ¬ ì˜µì…˜
            â€¢ ì‹¤ì‹œê°„ í•„í„°ë§
            """)
        
        # ì •ë ¬ ì˜µì…˜ ë§¤í•‘
        sort_mapping = {
            "ê´€ë ¨ë„": "relevance",
            "ìµœì‹ ìˆœ": "upload_date", 
            "ì¡°íšŒìˆ˜ìˆœ": "view_count",
            "í‰ì ìˆœ": "rating"
        }
        
        # ê²€ìƒ‰ ì‹¤í–‰
        if search_button and search_query:
            if search_query != st.session_state.last_search_query:
                with st.spinner('ìœ íŠœë¸Œ ì˜ìƒì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘...'):
                    videos = YouTubeAnalyzer.search_youtube_videos(
                        search_query, 
                        max_results=max_results,
                        sort_order=sort_mapping[initial_sort]
                    )
                    st.session_state.search_results = videos
                    st.session_state.filtered_results = videos  # ì´ˆê¸°ì—” í•„í„°ë§ ì•ˆ í•¨
                    st.session_state.last_search_query = search_query
                st.success(f"âœ… '{search_query}' ê²€ìƒ‰ ì™„ë£Œ! {len(videos)}ê°œ ì˜ìƒ ë°œê²¬")
        
        # í•„í„° ë° ì •ë ¬ ì„¹ì…˜
        if st.session_state.search_results:
            st.markdown("---")
            st.subheader('ğŸ›ï¸ ê³ ê¸‰ í•„í„° ë° ì •ë ¬')
            
            # í•„í„° ì»¨íŠ¸ë¡¤
            filter_col1, filter_col2, filter_col3, filter_col4 = st.columns(4)
            
            with filter_col1:
                st.write("**ğŸ“Š ì¡°íšŒìˆ˜ í•„í„°**")
                min_views = st.selectbox(
                    "ìµœì†Œ ì¡°íšŒìˆ˜",
                    [0, 1000, 10000, 100000, 1000000],
                    format_func=lambda x: f"{x:,}íšŒ" if x > 0 else "ì œí•œ ì—†ìŒ"
                )
            
            with filter_col2:
                st.write("**ğŸ“… ì—…ë¡œë“œ ê¸°ê°„**")
                max_days = st.selectbox(
                    "ìµœëŒ€ ì—…ë¡œë“œ ì „",
                    [999999, 1, 7, 30, 90, 365],
                    index=0,
                    format_func=lambda x: "ì „ì²´ ê¸°ê°„" if x == 999999 else f"{x}ì¼ ì „"
                )
            
            with filter_col3:
                st.write("**â±ï¸ ì¬ìƒì‹œê°„ ë²”ìœ„**")
                duration_range = st.selectbox(
                    "ì˜ìƒ ê¸¸ì´",
                    ["ì „ì²´", "ì§§ìŒ (4ë¶„ ì´í•˜)", "ë³´í†µ (4-20ë¶„)", "ê¹€ (20ë¶„ ì´ìƒ)"]
                )
                
                # ì¬ìƒì‹œê°„ ë²”ìœ„ë¥¼ ì´ˆë¡œ ë³€í™˜
                if duration_range == "ì§§ìŒ (4ë¶„ ì´í•˜)":
                    min_dur, max_dur = 0, 240
                elif duration_range == "ë³´í†µ (4-20ë¶„)":
                    min_dur, max_dur = 240, 1200
                elif duration_range == "ê¹€ (20ë¶„ ì´ìƒ)":
                    min_dur, max_dur = 1200, 999999
                else:
                    min_dur, max_dur = 0, 999999
            
            with filter_col4:
                st.write("**ğŸ”„ ì •ë ¬ ë°©ì‹**")
                sort_by = st.selectbox(
                    "ì •ë ¬ ê¸°ì¤€",
                    ["ê´€ë ¨ë„", "ì¡°íšŒìˆ˜ìˆœ", "ìµœì‹ ìˆœ", "ì¬ìƒì‹œê°„ìˆœ"],
                    help="í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì •ë ¬í•©ë‹ˆë‹¤"
                )
                
                sort_mapping_filter = {
                    "ê´€ë ¨ë„": "relevance",
                    "ì¡°íšŒìˆ˜ìˆœ": "view_count",
                    "ìµœì‹ ìˆœ": "upload_date", 
                    "ì¬ìƒì‹œê°„ìˆœ": "duration"
                }
            
            # í•„í„° ì ìš© ë²„íŠ¼
            if st.button("ğŸ¯ í•„í„° ì ìš©", use_container_width=True):
                with st.spinner("í•„í„°ë§ ì¤‘..."):
                    filtered_videos = YouTubeAnalyzer.filter_videos(
                        st.session_state.search_results,
                        min_views=min_views,
                        max_days_ago=max_days,
                        min_duration=min_dur,
                        max_duration=max_dur,
                        sort_by=sort_mapping_filter[sort_by]
                    )
                    st.session_state.filtered_results = filtered_videos
                
                st.success(f"âœ… í•„í„° ì ìš© ì™„ë£Œ! {len(st.session_state.filtered_results)}ê°œ ì˜ìƒ")
            
            # í•„í„° ìƒíƒœ í‘œì‹œ
            if st.session_state.filtered_results:
                original_count = len(st.session_state.search_results)
                filtered_count = len(st.session_state.filtered_results)
                
                st.info(f"ğŸ“Š **í•„í„° ê²°ê³¼**: {filtered_count}ê°œ ì˜ìƒ (ì „ì²´ {original_count}ê°œ ì¤‘)")
                
                # í˜„ì¬ í•„í„° ì¡°ê±´ í‘œì‹œ
                active_filters = []
                if min_views > 0:
                    active_filters.append(f"ì¡°íšŒìˆ˜ {min_views:,}íšŒ ì´ìƒ")
                if max_days < 999999:
                    active_filters.append(f"{max_days}ì¼ ì´ë‚´")
                if duration_range != "ì „ì²´":
                    active_filters.append(f"ì¬ìƒì‹œê°„ {duration_range}")
                if sort_by != "ê´€ë ¨ë„":
                    active_filters.append(f"{sort_by} ì •ë ¬")
                
                if active_filters:
                    st.caption(f"ğŸ›ï¸ í™œì„± í•„í„°: {' | '.join(active_filters)}")
            
            # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (í•„í„°ë§ëœ ê²°ê³¼ ì‚¬ìš©)
            videos = st.session_state.filtered_results if st.session_state.filtered_results else st.session_state.search_results
            
            st.markdown("---")
            st.subheader(f'ğŸ“¹ "{st.session_state.last_search_query}" ê²€ìƒ‰ ê²°ê³¼ ({len(videos)}ê°œ)')
            
            if not videos:
                st.warning("ğŸ˜… í•„í„° ì¡°ê±´ì— ë§ëŠ” ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
            else:
                # í˜ì´ì§€ë„¤ì´ì…˜ (í•œ í˜ì´ì§€ì— 9ê°œì”©)
                videos_per_page = 9
                total_pages = (len(videos) - 1) // videos_per_page + 1
                
                if total_pages > 1:
                    page_col1, page_col2, page_col3 = st.columns([1, 1, 1])
                    
                    with page_col2:
                        current_page = st.selectbox(
                            f"í˜ì´ì§€ ({total_pages}í˜ì´ì§€ ì¤‘)",
                            range(1, total_pages + 1),
                            key="video_page_selector"
                        )
                    
                    start_idx = (current_page - 1) * videos_per_page
                    end_idx = start_idx + videos_per_page
                    page_videos = videos[start_idx:end_idx]
                else:
                    page_videos = videos[:videos_per_page]
                
                # ê·¸ë¦¬ë“œ í˜•íƒœë¡œ ì˜ìƒ í‘œì‹œ (3ì—´)
                for i in range(0, len(page_videos), 3):
                    cols = st.columns(3)
                    
                    for j, col in enumerate(cols):
                        if i + j < len(page_videos):
                            video = page_videos[i + j]
                            
                            with col:
                                # ì»¨í…Œì´ë„ˆë¡œ ê°ì‹¸ì„œ ì•ˆì •ì„± í–¥ìƒ
                                with st.container():
                                    # ì¸ë„¤ì¼ í‘œì‹œ
                                    try:
                                        st.image(video['thumbnail_url'], use_container_width=True)
                                    except:
                                        st.error("ì¸ë„¤ì¼ ë¡œë“œ ì‹¤íŒ¨")
                                    
                                    # ì˜ìƒ ì •ë³´ - ë” ìƒì„¸í•˜ê²Œ
                                    st.markdown(f"**{video['title'][:45]}{'...' if len(video['title']) > 45 else ''}**")
                                    st.markdown(f"ğŸ“º {video['channel_name']}")
                                    
                                    # ìƒì„¸ ì •ë³´ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ì •ë¦¬
                                    info_col1, info_col2 = st.columns(2)
                                    with info_col1:
                                        st.markdown(f"ğŸ‘€ {video['view_count']}")
                                        st.markdown(f"â±ï¸ {video['duration']}")
                                    with info_col2:
                                        st.markdown(f"ğŸ“… {video['published_time']}")
                                        # ì¶”ê°€ í†µê³„ ì •ë³´
                                        if video['view_count_num'] >= 1000000:
                                            st.markdown("ğŸ”¥ **ì¸ê¸° ì˜ìƒ**")
                                        elif video['published_days_ago'] <= 7:
                                            st.markdown("ğŸ†• **ìµœì‹  ì˜ìƒ**")
                                    
                                    # ì˜ìƒ ë§í¬
                                    st.markdown(f"ğŸ”— [ì˜ìƒ ë³´ê¸°]({video['video_url']})")
                                    
                                    # ì´ë¯¸ ì„ íƒëœ ì˜ìƒì¸ì§€ í™•ì¸
                                    if video['video_id'] in st.session_state.selected_videos:
                                        st.success("âœ… ì´ë¯¸ ë¶„ì„ ëª©ë¡ì— ì¶”ê°€ë¨")
                                    else:
                                        # ì˜ìƒ ì¶”ê°€ ë²„íŠ¼ - ì½œë°± ëŒ€ì‹  ì„¸ì…˜ ìƒíƒœ ì§ì ‘ ì¡°ì‘
                                        button_key = f"add_video_{video['video_id']}_{i}_{j}_{current_page if 'current_page' in locals() else 1}"
                                        if st.button(f"ğŸ“ ë¶„ì„ ì¶”ê°€", key=button_key, use_container_width=True):
                                            # ì„¸ì…˜ ìƒíƒœì— ì˜ìƒ ì¶”ê°€
                                            st.session_state.selected_videos[video['video_id']] = video
                                            st.success(f"âœ… '{video['title'][:30]}...' ë¶„ì„ ëª©ë¡ì— ì¶”ê°€ë¨!")
                                            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•œ rerun í˜¸ì¶œ
                                            st.rerun()
                                    
                                    st.markdown("---")
        
        # ì„ íƒëœ ì˜ìƒë“¤ í‘œì‹œ ë° ìš”ì•½
        if st.session_state.selected_videos:
            st.markdown("---")
            st.subheader('ğŸ“‹ ì„ íƒëœ ì˜ìƒ ë¶„ì„')
            
            # ì„ íƒëœ ì˜ìƒ ê°œìˆ˜ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ì„ íƒëœ ì˜ìƒ", f"{len(st.session_state.selected_videos)}ê°œ")
            
            with col2:
                analyzed_count = len([k for k in st.session_state.video_summaries.keys() if k.startswith('summary_')])
                st.metric("ë¶„ì„ ì™„ë£Œ", f"{analyzed_count}ê°œ")
            
            with col3:
                pending_count = len(st.session_state.selected_videos) - analyzed_count
                st.metric("ë¶„ì„ ëŒ€ê¸°", f"{pending_count}ê°œ")
            
            # ì„ íƒëœ ì˜ìƒ ëª©ë¡
            video_ids = list(st.session_state.selected_videos.keys())
            
            for idx, video_id in enumerate(video_ids):
                video = st.session_state.selected_videos[video_id]
                
                # ê° ì˜ìƒì„ expandable ì„¹ì…˜ìœ¼ë¡œ ë§Œë“¤ì–´ ê´€ë¦¬ ìš©ì´ì„± í–¥ìƒ
                with st.expander(f"ğŸ“º {idx+1}. {video['title'][:60]}{'...' if len(video['title']) > 60 else ''}", expanded=True):
                    col1, col2, col3 = st.columns([1, 2, 1])
                    
                    with col1:
                        # ì˜ìƒ ì •ë³´
                        try:
                            st.image(video['thumbnail_url'], width=200)
                        except:
                            st.error("ì¸ë„¤ì¼ ë¡œë“œ ì‹¤íŒ¨")
                        
                        st.markdown(f"**ì±„ë„**: {video['channel_name']}")
                        st.markdown(f"**ì¡°íšŒìˆ˜**: {video['view_count']}")
                        st.markdown(f"**ê¸¸ì´**: {video['duration']}")
                        st.markdown(f"**ì—…ë¡œë“œ**: {video['published_time']}")
                        
                        # ì˜ìƒ í’ˆì§ˆ ì§€í‘œ
                        if video.get('view_count_num', 0) >= 1000000:
                            st.success("ğŸ”¥ ì¸ê¸° ì˜ìƒ")
                        elif video.get('view_count_num', 0) >= 100000:
                            st.info("ğŸ“ˆ ì¡°íšŒìˆ˜ ì–‘í˜¸")
                        
                        if video.get('published_days_ago', 999) <= 7:
                            st.success("ğŸ†• ìµœì‹  ì˜ìƒ")
                        elif video.get('published_days_ago', 999) <= 30:
                            st.info("ğŸ“… ìµœê·¼ ì˜ìƒ")
                        
                        st.markdown(f"ğŸ”— [ì›ë³¸ ì˜ìƒ]({video['video_url']})")
                    
                    with col2:
                        # ìš”ì•½ ê²°ê³¼ í‘œì‹œ
                        summary_key = f"summary_{video_id}"
                        
                        if summary_key in st.session_state.video_summaries:
                            # ì´ë¯¸ ìš”ì•½ëœ ê²°ê³¼ í‘œì‹œ
                            summary_data = st.session_state.video_summaries[summary_key]
                            
                            if summary_data['type'] == 'gpt_summary':
                                st.subheader("ğŸ¤– AI ìš”ì•½ ë¶„ì„")
                                if summary_data.get('error'):
                                    st.error(f"ìš”ì•½ ì‹¤íŒ¨: {summary_data['error']}")
                                else:
                                    st.markdown(summary_data['content'])
                                    
                                    # ìš”ì•½ì˜ í’ˆì§ˆ í‰ê°€
                                    if len(summary_data['content']) > 500:
                                        st.success("ğŸ“Š ìƒì„¸í•œ ë¶„ì„ ì™„ë£Œ")
                                    else:
                                        st.info("ğŸ“ ê¸°ë³¸ ìš”ì•½ ì™„ë£Œ")
                                        
                            elif summary_data['type'] == 'error':
                                st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {summary_data.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                                if summary_data.get('content'):
                                    st.text_area("ë¶€ë¶„ ë‚´ìš©", summary_data['content'], height=150, 
                                            key=f"error_content_{video_id}", disabled=True)
                            else:
                                st.subheader("ğŸ“ ì˜ìƒ ë‚´ìš© (ì¼ë¶€)")
                                st.text_area("ìë§‰ ë‚´ìš©", summary_data['content'], height=200, 
                                        key=f"transcript_display_{video_id}", disabled=True)
                                
                                if not summary_data.get('had_api_key'):
                                    st.info("ğŸ’¡ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì‹œë©´ AI ê¸°ë°˜ ìš”ì•½ ë¶„ì„ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        else:
                            # ì•„ì§ ìš”ì•½ë˜ì§€ ì•ŠìŒ
                            st.info("ğŸ”„ ìš”ì•½ì„ ì‹œì‘í•˜ë ¤ë©´ ì˜†ì˜ 'ğŸš€ ìš”ì•½ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                            
                            # ì˜ìƒ ì˜ˆìƒ ë¶„ì„ ì‹œê°„ í‘œì‹œ
                            duration_seconds = video.get('duration_seconds', 0)
                            if duration_seconds > 1800:  # 30ë¶„ ì´ìƒ
                                st.warning("â° ê¸´ ì˜ìƒì…ë‹ˆë‹¤. ë¶„ì„ì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                            elif duration_seconds > 0:
                                st.info(f"â±ï¸ ì˜ˆìƒ ë¶„ì„ ì‹œê°„: ì•½ {duration_seconds//60 + 1}ë¶„")
                    
                    with col3:
                        # ì•¡ì…˜ ë²„íŠ¼ë“¤ì„ formìœ¼ë¡œ ê°ì‹¸ì„œ ì•ˆì •ì„± í–¥ìƒ
                        if f"summary_{video_id}" not in st.session_state.video_summaries:
                            # ìš”ì•½ ì‹œì‘ ë²„íŠ¼
                            with st.form(f"analyze_form_{video_id}"):
                                analyze_button = st.form_submit_button(f"ğŸš€ ìš”ì•½ ì‹œì‘", use_container_width=True, type="primary")
                                
                                if analyze_button:
                                    with st.spinner('ì˜ìƒì„ ë¶„ì„í•˜ëŠ” ì¤‘...'):
                                        try:
                                            # ìë§‰ ì¶”ì¶œ
                                            transcript = YouTubeAnalyzer.get_video_transcript(video_id)
                                            
                                            if openai_api_key and transcript and len(transcript.strip()) > 50:
                                                # GPT ìš”ì•½
                                                summary_result = YouTubeAnalyzer.summarize_video_with_gpt(
                                                    transcript, video['title'], openai_api_key
                                                )
                                                
                                                if summary_result.get('error'):
                                                    st.session_state.video_summaries[f"summary_{video_id}"] = {
                                                        'type': 'error',
                                                        'content': transcript[:1000] + "..." if len(transcript) > 1000 else transcript,
                                                        'error': summary_result['error'],
                                                        'had_api_key': True
                                                    }
                                                else:
                                                    st.session_state.video_summaries[f"summary_{video_id}"] = {
                                                        'type': 'gpt_summary',
                                                        'content': summary_result['summary'],
                                                        'had_api_key': True
                                                    }
                                            else:
                                                # API í‚¤ê°€ ì—†ê±°ë‚˜ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨
                                                content = transcript[:1000] + "..." if transcript and len(transcript) > 1000 else transcript
                                                if not content or len(content.strip()) < 10:
                                                    content = "ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ ì˜ìƒì€ ìë§‰ì´ ì œê³µë˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤."
                                                
                                                st.session_state.video_summaries[f"summary_{video_id}"] = {
                                                    'type': 'basic',
                                                    'content': content,
                                                    'had_api_key': bool(openai_api_key)
                                                }
                                            
                                            st.success("âœ… ìš”ì•½ ì™„ë£Œ!")
                                            
                                        except Exception as e:
                                            st.session_state.video_summaries[f"summary_{video_id}"] = {
                                                'type': 'error',
                                                'content': '',
                                                'error': f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                                                'had_api_key': bool(openai_api_key)
                                            }
                                            st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                                        
                                        # ìƒíƒœ ë³€ê²½ í›„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                                        st.rerun()
                        else:
                            # ì´ë¯¸ ìš”ì•½ë¨ - ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
                            with st.form(f"refresh_form_{video_id}"):
                                refresh_button = st.form_submit_button(f"ğŸ”„ ë‹¤ì‹œ ìš”ì•½", use_container_width=True)
                                
                                if refresh_button:
                                    # ê¸°ì¡´ ìš”ì•½ ì‚­ì œ í›„ ë‹¤ì‹œ ìš”ì•½
                                    if f"summary_{video_id}" in st.session_state.video_summaries:
                                        del st.session_state.video_summaries[f"summary_{video_id}"]
                                    st.info("ğŸ”„ ìš”ì•½ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. 'ğŸš€ ìš”ì•½ ì‹œì‘' ë²„íŠ¼ì„ ë‹¤ì‹œ í´ë¦­í•˜ì„¸ìš”.")
                                    st.rerun()
                        
                        st.markdown("---")
                        
                        # ì‚­ì œ ë²„íŠ¼
                        with st.form(f"remove_form_{video_id}"):
                            remove_button = st.form_submit_button(f"ğŸ—‘ï¸ ëª©ë¡ì—ì„œ ì œê±°", use_container_width=True, type="secondary")
                            
                            if remove_button:
                                # ì˜ìƒê³¼ ìš”ì•½ ëª¨ë‘ ì‚­ì œ
                                if video_id in st.session_state.selected_videos:
                                    del st.session_state.selected_videos[video_id]
                                if f"summary_{video_id}" in st.session_state.video_summaries:
                                    del st.session_state.video_summaries[f"summary_{video_id}"]
                                st.success("âœ… ëª©ë¡ì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                st.rerun()
            
            # ì¼ê´„ ì‘ì—… ë²„íŠ¼ë“¤
            st.markdown("---")
            st.subheader("ğŸ”§ ì¼ê´„ ì‘ì—…")
            
            batch_col1, batch_col2, batch_col3 = st.columns(3)
            
            with batch_col1:
                with st.form("analyze_all_form"):
                    analyze_all_button = st.form_submit_button("ğŸš€ ì „ì²´ ì˜ìƒ ì¼ê´„ ë¶„ì„", use_container_width=True, type="primary")
                    
                    if analyze_all_button:
                        if not openai_api_key:
                            st.error("âš ï¸ ì¼ê´„ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        else:
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            unanalyzed_videos = [vid for vid in st.session_state.selected_videos.keys() 
                                            if f"summary_{vid}" not in st.session_state.video_summaries]
                            
                            for i, video_id in enumerate(unanalyzed_videos):
                                video = st.session_state.selected_videos[video_id]
                                status_text.text(f"ë¶„ì„ ì¤‘: {video['title'][:30]}... ({i+1}/{len(unanalyzed_videos)})")
                                
                                try:
                                    transcript = YouTubeAnalyzer.get_video_transcript(video_id)
                                    if transcript and len(transcript.strip()) > 50:
                                        summary_result = YouTubeAnalyzer.summarize_video_with_gpt(
                                            transcript, video['title'], openai_api_key
                                        )
                                        
                                        if summary_result.get('error'):
                                            st.session_state.video_summaries[f"summary_{video_id}"] = {
                                                'type': 'error',
                                                'content': transcript[:1000] + "..." if len(transcript) > 1000 else transcript,
                                                'error': summary_result['error'],
                                                'had_api_key': True
                                            }
                                        else:
                                            st.session_state.video_summaries[f"summary_{video_id}"] = {
                                                'type': 'gpt_summary',
                                                'content': summary_result['summary'],
                                                'had_api_key': True
                                            }
                                    else:
                                        st.session_state.video_summaries[f"summary_{video_id}"] = {
                                            'type': 'basic',
                                            'content': "ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                                            'had_api_key': True
                                        }
                                except Exception as e:
                                    st.session_state.video_summaries[f"summary_{video_id}"] = {
                                        'type': 'error',
                                        'content': '',
                                        'error': f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                                        'had_api_key': True
                                    }
                                
                                progress_bar.progress((i + 1) / len(unanalyzed_videos))
                            
                            progress_bar.empty()
                            status_text.empty()
                            st.success(f"âœ… {len(unanalyzed_videos)}ê°œ ì˜ìƒ ì¼ê´„ ë¶„ì„ ì™„ë£Œ!")
                            st.rerun()
            
            with batch_col2:
                # ë‚´ë³´ë‚´ê¸° ì¤€ë¹„ ë²„íŠ¼ (form ì•ˆì—)
                with st.form("export_form"):
                    export_button = st.form_submit_button("ğŸ“¤ ë¶„ì„ ê²°ê³¼ ì¤€ë¹„", use_container_width=True)
                    
                    if export_button:
                        # ì„¸ì…˜ ìƒíƒœì— ë‚´ë³´ë‚´ê¸° ë°ì´í„° ì €ì¥
                        from datetime import datetime
                        export_text = f"# ìœ íŠœë¸Œ ì˜ìƒ ë¶„ì„ ê²°ê³¼\n\nê²€ìƒ‰ì–´: {st.session_state.last_search_query}\në¶„ì„ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                        
                        for idx, (video_id, video) in enumerate(st.session_state.selected_videos.items()):
                            export_text += f"## {idx+1}. {video['title']}\n\n"
                            export_text += f"- **ì±„ë„**: {video['channel_name']}\n"
                            export_text += f"- **ì¡°íšŒìˆ˜**: {video['view_count']}\n"
                            export_text += f"- **ê¸¸ì´**: {video['duration']}\n"
                            export_text += f"- **ì—…ë¡œë“œ**: {video['published_time']}\n"
                            export_text += f"- **ë§í¬**: {video['video_url']}\n\n"
                            
                            summary_key = f"summary_{video_id}"
                            if summary_key in st.session_state.video_summaries:
                                summary_data = st.session_state.video_summaries[summary_key]
                                export_text += f"**ë¶„ì„ ê²°ê³¼:**\n{summary_data.get('content', 'ë¶„ì„ ì‹¤íŒ¨')}\n\n"
                            else:
                                export_text += "**ë¶„ì„ ê²°ê³¼:** ë¶„ì„ë˜ì§€ ì•ŠìŒ\n\n"
                            
                            export_text += "---\n\n"
                        
                        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                        st.session_state.export_ready = True
                        st.session_state.export_data = export_text
                        st.success("âœ… ë‚´ë³´ë‚´ê¸° íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (form ë°–ì—)
                if st.session_state.get('export_ready', False) and st.session_state.get('export_data'):
                    from datetime import datetime
                    st.download_button(
                        label="ğŸ“¥ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=st.session_state.export_data,
                        file_name=f"youtube_analysis_{st.session_state.last_search_query}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                        mime="text/markdown",
                        use_container_width=True
                    )
            
            with batch_col3:
                with st.form("clear_all_form"):
                    clear_all_button = st.form_submit_button("ğŸ—‘ï¸ ì „ì²´ ëª©ë¡ ì´ˆê¸°í™”", type="secondary", use_container_width=True)
                    
                    if clear_all_button:
                        st.session_state.selected_videos = {}
                        st.session_state.video_summaries = {}
                        st.session_state.search_results = []
                        st.session_state.filtered_results = []
                        st.session_state.last_search_query = ""
                        st.success("âœ… ì „ì²´ ëª©ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()

        else:
            st.info("ğŸ“ ìœ„ì—ì„œ ì˜ìƒì„ ê²€ìƒ‰í•˜ê³  'ğŸ“ ë¶„ì„ ì¶”ê°€' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¶„ì„í•  ì˜ìƒì„ ì„ íƒí•˜ì„¸ìš”.")
        
        # í†µê³„ ì •ë³´ í‘œì‹œ
        if st.session_state.search_results or st.session_state.selected_videos:
            st.markdown("---")
            st.subheader("ğŸ“Š ì„¸ì…˜ í†µê³„")
            
            stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
            
            with stat_col1:
                st.metric("ê²€ìƒ‰ëœ ì˜ìƒ", len(st.session_state.search_results))
            
            with stat_col2:
                st.metric("í•„í„°ë§ëœ ì˜ìƒ", len(st.session_state.filtered_results))
            
            with stat_col3:
                st.metric("ì„ íƒëœ ì˜ìƒ", len(st.session_state.selected_videos))
            
            with stat_col4:
                analyzed_count = len([k for k in st.session_state.video_summaries.keys() if k.startswith('summary_')])
                st.metric("ë¶„ì„ ì™„ë£Œ", analyzed_count)
        
        # í˜„ì¬ ì„¸ì…˜ ìƒíƒœ ë””ë²„ê¹… ì •ë³´ (ê°œë°œìš©)
        if st.checkbox("ğŸ”§ ë””ë²„ê¹… ì •ë³´ í‘œì‹œ", help="ê°œë°œììš© ì„¸ì…˜ ìƒíƒœ ì •ë³´"):
            st.write("**í˜„ì¬ ì„¸ì…˜ ìƒíƒœ:**")
            st.write(f"- ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(st.session_state.search_results)}")
            st.write(f"- í•„í„°ë§ëœ ê²°ê³¼ ìˆ˜: {len(st.session_state.filtered_results)}")
            st.write(f"- ì„ íƒëœ ì˜ìƒ ìˆ˜: {len(st.session_state.selected_videos)}")
            st.write(f"- ìš”ì•½ëœ ì˜ìƒ ìˆ˜: {len(st.session_state.video_summaries)}")
            st.write(f"- ë§ˆì§€ë§‰ ê²€ìƒ‰ì–´: {st.session_state.last_search_query}")
            
            if st.button("ğŸ”„ ì„¸ì…˜ ìƒíƒœ ê°•ì œ ì´ˆê¸°í™” (ë””ë²„ê¹…ìš©)"):
                for key in ['selected_videos', 'video_summaries', 'search_results', 'filtered_results', 'last_search_query']:
                    if key in st.session_state:
                        del st.session_state[key]
                st.success("ì„¸ì…˜ ìƒíƒœê°€ ê°•ì œë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
        
        # ì‚¬ìš©ë²• ì•ˆë‚´
        with st.expander('ğŸ’¡ ìœ íŠœë¸Œ ë¶„ì„ ì‚¬ìš©ë²• (í–¥ìƒëœ ê¸°ëŠ¥)'):
            st.markdown("""
            **ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥**
            - **ëŒ€ìš©ëŸ‰ ê²€ìƒ‰**: ìµœëŒ€ 100ê°œ ì˜ìƒ ê²€ìƒ‰ ê°€ëŠ¥
            - **ê³ ê¸‰ í•„í„°ë§**: ì¡°íšŒìˆ˜, ì—…ë¡œë“œì¼, ì¬ìƒì‹œê°„ìœ¼ë¡œ í•„í„°ë§
            - **ë‹¤ì–‘í•œ ì •ë ¬**: ê´€ë ¨ë„, ì¡°íšŒìˆ˜, ìµœì‹ ìˆœ, ì¬ìƒì‹œê°„ìˆœ ì •ë ¬
            - **ì¼ê´„ ë¶„ì„**: ì„ íƒëœ ëª¨ë“  ì˜ìƒì„ í•œ ë²ˆì— ë¶„ì„
            - **ê²°ê³¼ ë‚´ë³´ë‚´ê¸°**: ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
            - **í˜ì´ì§€ë„¤ì´ì…˜**: ë§ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í˜ì´ì§€ë¡œ ë‚˜ëˆ„ì–´ í‘œì‹œ
            - **í†µê³„ ëŒ€ì‹œë³´ë“œ**: ì„¸ì…˜ë³„ ë¶„ì„ í˜„í™© í‘œì‹œ
            
            **ğŸ” íš¨ê³¼ì ì¸ ê²€ìƒ‰ ë°©ë²•**
            - **ì¢…ëª© ì¤‘ì‹¬**: "AAPL stock analysis", "Tesla earnings review"
            - **ì‹œì  ì¤‘ì‹¬**: "2024 Q4 earnings", "latest market update"
            - **ë¶„ì„ ìœ í˜•**: "technical analysis", "fundamental analysis"
            - **ì „ë§ ì¤‘ì‹¬**: "price prediction", "investment outlook"
            
            **ğŸ›ï¸ í•„í„°ë§ í™œìš©ë²•**
            - **ì¸ê¸° ì˜ìƒ ì°¾ê¸°**: ì¡°íšŒìˆ˜ 100,000íšŒ ì´ìƒ í•„í„°
            - **ìµœì‹  ì •ë³´**: 7ì¼ ì´ë‚´ ì—…ë¡œë“œ í•„í„°
            - **ì‹¬ì¸µ ë¶„ì„**: 20ë¶„ ì´ìƒ ê¸´ ì˜ìƒ í•„í„°
            - **ë¹ ë¥¸ ì •ë³´**: 4ë¶„ ì´í•˜ ì§§ì€ ì˜ìƒ í•„í„°
            
            **ğŸš€ ë¶„ì„ íš¨ìœ¨ì„± íŒ**
            1. **ê²€ìƒ‰ â†’ í•„í„°ë§ â†’ ì„ íƒ â†’ ì¼ê´„ ë¶„ì„** ìˆœì„œë¡œ ì§„í–‰
            2. ê´€ì‹¬ ìˆëŠ” ì˜ìƒë§Œ ì„ ë³„í•´ì„œ API ë¹„ìš© ì ˆì•½
            3. ë¶„ì„ ê²°ê³¼ëŠ” ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë‚´ë³´ë‚´ì„œ ë³´ê´€
            4. ì—¬ëŸ¬ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ì„œ ë‹¤ì–‘í•œ ê´€ì  ìˆ˜ì§‘
            
            **âš ï¸ ì£¼ì˜ì‚¬í•­**
            - ìœ íŠœë¸Œ ê²€ìƒ‰ ì œí•œìœ¼ë¡œ ëª¨ë“  ì˜ìƒì„ ê°€ì ¸ì˜¤ì§€ ëª»í•  ìˆ˜ ìˆìŒ
            - ì¼ê´„ ë¶„ì„ì€ API ì‚¬ìš©ëŸ‰ì´ ë§ìœ¼ë‹ˆ ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©
            - ì˜ìƒ ìë§‰ì´ ì—†ëŠ” ê²½ìš° ë¶„ì„ì´ ì œí•œì ì¼ ìˆ˜ ìˆìŒ
            - ê¸´ ì˜ìƒì¼ìˆ˜ë¡ ë¶„ì„ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼
            
            **ğŸ’¡ ê³ ê¸‰ í™œìš©ë²•**
            - **ê²½ìŸ ë¶„ì„**: ê°™ì€ ì¢…ëª©ì— ëŒ€í•œ ì—¬ëŸ¬ ì±„ë„ ì˜ê²¬ ë¹„êµ
            - **ì‹œì ë³„ ë¶„ì„**: ì‹¤ì  ë°œí‘œ ì „í›„ ì˜ìƒë“¤ ë¹„êµ
            - **ì±„ë„ë³„ íŠ¹ì„±**: íŠ¹ì • ì±„ë„ì˜ ë¶„ì„ íŒ¨í„´ íŒŒì•…
            - **í‚¤ì›Œë“œ íŠ¸ë Œë“œ**: ì¸ê¸° ê²€ìƒ‰ì–´ ë³€í™” ì¶”ì 
            """)

    with tab9:
        st.header('ğŸ“ˆ êµ¬ê¸€ ê²€ìƒ‰ íŠ¸ë Œë“œ ë¶„ì„')
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” - í•œ ë²ˆë§Œ ì‹¤í–‰
        if 'trends_data_cache' not in st.session_state:
            st.session_state.trends_data_cache = None
        if 'trends_keywords_cache' not in st.session_state:
            st.session_state.trends_keywords_cache = ""
        if 'trends_analysis_done' not in st.session_state:
            st.session_state.trends_analysis_done = False
        if 'gpt_trends_result' not in st.session_state:
            st.session_state.gpt_trends_result = None
        
        # ì•ˆë‚´ ë©”ì‹œì§€
        st.info("""
        ğŸ“Š **êµ¬ê¸€ íŠ¸ë Œë“œ ë¶„ì„ì´ë€?**
        
        êµ¬ê¸€ì—ì„œ íŠ¹ì • í‚¤ì›Œë“œê°€ ì–¼ë§ˆë‚˜ ë§ì´ ê²€ìƒ‰ë˜ì—ˆëŠ”ì§€ë¥¼ ì‹œê°„ì— ë”°ë¼ ë¶„ì„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
        íˆ¬ììë“¤ì˜ ê´€ì‹¬ë„ì™€ ì‹œì¥ ì‹¬ë¦¬ë¥¼ íŒŒì•…í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.
        """)
        
        # ê²€ìƒ‰ì–´ ì„¤ì • ì„¹ì…˜
        st.subheader('ğŸ” ê²€ìƒ‰ì–´ ì„¤ì •')
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ìë™ í‚¤ì›Œë“œ ìƒì„± ì˜µì…˜
            if symbols:
                use_stock_keywords = st.checkbox(
                    f"ì…ë ¥ëœ ì¢…ëª© ê¸°ë°˜ í‚¤ì›Œë“œ ì‚¬ìš© ({', '.join(symbols)})",
                    value=True,
                    help="ë©”ì¸ì—ì„œ ì…ë ¥í•œ ì¢…ëª©ì„ ê¸°ë°˜ìœ¼ë¡œ ìë™ìœ¼ë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
                )
            else:
                use_stock_keywords = False
                st.info("ë©”ì¸ì—ì„œ ì¢…ëª©ì„ ë¨¼ì € ì…ë ¥í•˜ì‹œë©´ ìë™ í‚¤ì›Œë“œ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        with col2:
            # ë¶„ì„ ê¸°ê°„ ì„ íƒ
            timeframe_options = {
                'ì§€ë‚œ 1ì‹œê°„': 'now 1-H',
                'ì§€ë‚œ 4ì‹œê°„': 'now 4-H',
                'ì§€ë‚œ 1ì¼': 'now 1-d',
                'ì§€ë‚œ 7ì¼': 'now 7-d',
                'ì§€ë‚œ 1ê°œì›”': 'today 1-m',
                'ì§€ë‚œ 3ê°œì›”': 'today 3-m',
                'ì§€ë‚œ 12ê°œì›”': 'today 12-m',
                'ì§€ë‚œ 5ë…„': 'today 5-y',
                '2004ë…„~í˜„ì¬': 'all'
            }
            
            selected_timeframe_label = st.selectbox(
                'ë¶„ì„ ê¸°ê°„ ì„ íƒ',
                list(timeframe_options.keys()),
                index=6
            )
            selected_timeframe = timeframe_options[selected_timeframe_label]
        
        # í‚¤ì›Œë“œ ìë™ ìƒì„±
        default_keywords = ""
        if use_stock_keywords and symbols:
            auto_keywords = []
            for symbol in symbols:
                try:
                    financial_data = DataManager.get_financial_data(symbol)
                    if financial_data and 'info' in financial_data:
                        company_name = financial_data['info'].get('shortName', symbol)
                    else:
                        company_name = symbol
                except:
                    company_name = symbol
                
                try:
                    stock_keywords = GoogleTrendsAnalyzer.get_stock_related_keywords(symbol, company_name)
                    auto_keywords.extend(stock_keywords)
                except:
                    auto_keywords.append(symbol)
            
            auto_keywords = list(dict.fromkeys(auto_keywords))[:5]
            default_keywords = ', '.join(auto_keywords)
            
            if auto_keywords:
                st.success(f"ìë™ ìƒì„±ëœ í‚¤ì›Œë“œ: {default_keywords}")
        
        # í‚¤ì›Œë“œ ì…ë ¥
        manual_keywords = st.text_input(
            'ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„, ìµœëŒ€ 5ê°œ)',
            value=default_keywords,
            placeholder='ì˜ˆ: AAPL, Apple stock, iPhone, Tesla, TSLA stock',
            help='êµ¬ê¸€ì—ì„œ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì˜ì–´ í‚¤ì›Œë“œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.'
        )
        
        if manual_keywords:
            keywords = [k.strip() for k in manual_keywords.split(',') if k.strip()][:5]
            
            # ì§€ì—­ ì„¤ì •
            geo_options = {
                'ì „ ì„¸ê³„': '',
                'ë¯¸êµ­': 'US',
                'í•œêµ­': 'KR',
                'ì¼ë³¸': 'JP',
                'ì¤‘êµ­': 'CN',
                'ë…ì¼': 'DE',
                'ì˜êµ­': 'GB'
            }
            
            selected_geo_label = st.selectbox('ì§€ì—­ ì„ íƒ', list(geo_options.keys()))
            selected_geo = geo_options[selected_geo_label]
            
            # í‚¤ì›Œë“œê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
            current_keywords_string = f"{','.join(keywords)}_{selected_timeframe}_{selected_geo}"
            keywords_changed = (current_keywords_string != st.session_state.trends_keywords_cache)
            
            # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
            if st.button('ğŸ“Š íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘', type='primary', use_container_width=True) or keywords_changed:
                
                if not keywords:
                    st.error("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    # ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘
                    st.session_state.trends_analysis_done = False
                    st.session_state.gpt_trends_result = None
                    st.session_state.trends_keywords_cache = current_keywords_string
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    try:
                        status_text.text("ğŸ” êµ¬ê¸€ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘...")
                        progress_bar.progress(25)
                        
                        trends_data = GoogleTrendsAnalyzer.get_trends_data(
                            keywords, 
                            timeframe=selected_timeframe,
                            geo=selected_geo
                        )
                        
                        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                        st.session_state.trends_data_cache = trends_data
                        
                        progress_bar.progress(100)
                        status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
                        
                        st.session_state.trends_analysis_done = True
                        
                    except Exception as e:
                        st.error(f"âŒ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    finally:
                        progress_bar.empty()
                        status_text.empty()
            
            # ìºì‹œëœ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ìˆê³  ë¶„ì„ì´ ì™„ë£Œëœ ê²½ìš° ê²°ê³¼ í‘œì‹œ
            if st.session_state.trends_analysis_done and st.session_state.trends_data_cache:
                trends_data = st.session_state.trends_data_cache
                
                if trends_data.get('error'):
                    st.error(f"âŒ {trends_data['error']}")
                    st.markdown("**ğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ë²•:**")
                    st.info("â€¢ ë‹¤ë¥¸ í‚¤ì›Œë“œ ì‹œë„")
                    st.info("â€¢ ë¶„ì„ ê¸°ê°„ ë³€ê²½")
                    st.info("â€¢ ì§€ì—­ ì„¤ì • ë³€ê²½")
                    st.info("â€¢ ì˜ì–´ í‚¤ì›Œë“œ ì‚¬ìš©")
                else:
                    has_time_data = (trends_data.get('interest_over_time') is not None and 
                                not trends_data.get('interest_over_time').empty)
                    has_region_data = (trends_data.get('interest_by_region') is not None and 
                                    not trends_data.get('interest_by_region').empty)
                    has_related_data = trends_data.get('related_queries') is not None
                    
                    if not any([has_time_data, has_region_data, has_related_data]):
                        st.warning("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.success(f"ğŸ‰ '{', '.join(keywords)}' íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼")
                        
                        # ì‹œê°„ë³„ íŠ¸ë Œë“œ ì°¨íŠ¸
                        if has_time_data:
                            st.subheader('ğŸ“ˆ ì‹œê°„ë³„ ê²€ìƒ‰ íŠ¸ë Œë“œ')
                            trends_chart = GoogleTrendsAnalyzer.create_trends_chart(trends_data)
                            if trends_chart and hasattr(trends_chart, 'data') and trends_chart.data:
                                st.plotly_chart(trends_chart, use_container_width=True)
                                
                                # íŠ¸ë Œë“œ ìš”ì•½
                                interest_df = trends_data.get('interest_over_time')
                                if interest_df is not None and not interest_df.empty:
                                    st.subheader('ğŸ“Š íŠ¸ë Œë“œ ìš”ì•½')
                                    cols = st.columns(min(len(keywords), 4))
                                    for i, keyword in enumerate(keywords):
                                        if keyword in interest_df.columns and i < 4:
                                            with cols[i]:
                                                try:
                                                    keyword_data = interest_df[keyword].dropna()
                                                    if len(keyword_data) > 0:
                                                        recent_avg = keyword_data.tail(min(30, len(keyword_data))).mean()
                                                        max_val = keyword_data.max()
                                                        
                                                        if len(keyword_data) >= 14:
                                                            recent_trend = (keyword_data.tail(7).mean() - 
                                                                        keyword_data.tail(14).head(7).mean())
                                                        else:
                                                            recent_trend = 0
                                                        
                                                        st.metric(
                                                            keyword,
                                                            f"{recent_avg:.1f}",
                                                            delta=f"{recent_trend:+.1f}" if recent_trend != 0 else "0.0",
                                                            help=f"ìµœê³ ê°’: {max_val}, ìµœê·¼ í‰ê· : {recent_avg:.1f}"
                                                        )
                                                    else:
                                                        st.metric(keyword, "ë°ì´í„° ì—†ìŒ")
                                                except Exception as e:
                                                    st.warning(f"{keyword} ìš”ì•½ ìƒì„± ì‹¤íŒ¨")
                        
                        # ì§€ì—­ë³„ ê´€ì‹¬ë„ ì°¨íŠ¸
                        if has_region_data:
                            st.subheader('ğŸŒ êµ­ê°€ë³„ ê²€ìƒ‰ ê´€ì‹¬ë„')
                            try:
                                regional_chart = GoogleTrendsAnalyzer.create_regional_chart(trends_data)
                                if regional_chart and hasattr(regional_chart, 'data') and regional_chart.data:
                                    st.plotly_chart(regional_chart, use_container_width=True)
                            except Exception as e:
                                st.warning('ì§€ì—­ë³„ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨')
                        
                        # ê´€ë ¨ ê²€ìƒ‰ì–´ í‘œì‹œ
                        if has_related_data:
                            related_queries = trends_data.get('related_queries', {})
                            if related_queries:
                                st.subheader('ğŸ” ê´€ë ¨ ê²€ìƒ‰ì–´')
                                cols = st.columns(min(len(keywords), 2))
                                for i, keyword in enumerate(keywords[:2]):
                                    if keyword in related_queries:
                                        with cols[i]:
                                            st.write(f"**{keyword} ê´€ë ¨ ìƒìŠ¹ ê²€ìƒ‰ì–´:**")
                                            
                                            try:
                                                rising_data = related_queries[keyword].get('rising')
                                                if rising_data is not None and not rising_data.empty:
                                                    rising_df = rising_data.head(5)
                                                    for _, row in rising_df.iterrows():
                                                        value_str = str(row['value']) if pd.notna(row['value']) else 'N/A'
                                                        st.write(f"â€¢ {row['query']} (+{value_str})")
                                                else:
                                                    st.write("ìƒìŠ¹ ê²€ìƒ‰ì–´ ë°ì´í„° ì—†ìŒ")
                                            except:
                                                st.write("ìƒìŠ¹ ê²€ìƒ‰ì–´ í‘œì‹œ ì˜¤ë¥˜")
                                            
                                            st.write(f"**{keyword} ê´€ë ¨ ì¸ê¸° ê²€ìƒ‰ì–´:**")
                                            try:
                                                top_data = related_queries[keyword].get('top')
                                                if top_data is not None and not top_data.empty:
                                                    top_df = top_data.head(5)
                                                    for _, row in top_df.iterrows():
                                                        value_str = str(row['value']) if pd.notna(row['value']) else 'N/A'
                                                        st.write(f"â€¢ {row['query']} ({value_str})")
                                                else:
                                                    st.write("ì¸ê¸° ê²€ìƒ‰ì–´ ë°ì´í„° ì—†ìŒ")
                                            except:
                                                st.write("ì¸ê¸° ê²€ìƒ‰ì–´ í‘œì‹œ ì˜¤ë¥˜")
                        
                        # GPT ë¶„ì„ ì„¹ì…˜
                        st.markdown('---')
                        st.subheader('ğŸ¤– AI ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„')
                        
                        # GPT ë¶„ì„ ê²°ê³¼ê°€ ì´ë¯¸ ìˆëŠ” ê²½ìš° í‘œì‹œ
                        if st.session_state.gpt_trends_result:
                            gpt_result = st.session_state.gpt_trends_result
                            
                            if gpt_result.get('error'):
                                st.error(f"ğŸ¤– ë¶„ì„ ì˜¤ë¥˜: {gpt_result['error']}")
                            else:
                                st.success("ğŸ‰ GPT ë¶„ì„ ì™„ë£Œ!")
                                
                                # ë¶„ì„ ì ìˆ˜ í‘œì‹œ
                                score = gpt_result.get('score', 3.0)
                                
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    st.metric(
                                        "íŠ¸ë Œë“œ ì¢…í•© ì ìˆ˜",
                                        f"{score:.1f}/5.0",
                                        delta=f"{(score/5.0)*100:.0f}%"
                                    )
                                
                                with col2:
                                    if score >= 4.0:
                                        st.success("ğŸ”¥ ë†’ì€ ê´€ì‹¬ë„")
                                    elif score >= 3.0:
                                        st.info("ğŸ“Š ë³´í†µ ê´€ì‹¬ë„")
                                    else:
                                        st.warning("ğŸ“‰ ë‚®ì€ ê´€ì‹¬ë„")
                                
                                with col3:
                                    if score >= 4.0:
                                        st.success("ğŸ“ˆ ë†’ì€ ëŒ€ì¤‘ ê´€ì‹¬")
                                    elif score >= 2.5:
                                        st.info("âš–ï¸ ì¤‘ê°„ ê´€ì‹¬ë„")
                                    else:
                                        st.error("ğŸ˜´ ë‚®ì€ ê´€ì‹¬ë„")
                                
                                # GPT ë¶„ì„ ë‚´ìš© í‘œì‹œ
                                st.markdown("### ğŸ“‹ íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸")
                                st.markdown(gpt_result['analysis'])
                                
                                # ì¶”ê°€ ì•¡ì…˜ ì œì•ˆ
                                st.markdown("---")
                                st.subheader("ğŸ”„ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ")
                                
                                if score >= 4.0:
                                    st.success("""
                                    **ë†’ì€ ê´€ì‹¬ë„ í™œìš© ì „ëµ:**
                                    â€¢ ê´€ë ¨ ë‰´ìŠ¤ ë¶„ì„ íƒ­ì—ì„œ ìµœì‹  ë™í–¥ í™•ì¸
                                    â€¢ ì¬ë¬´ ê±´ì „ì„± íƒ­ì—ì„œ ê¸°ì—… ì‹¤ë ¥ ê²€ì¦
                                    â€¢ ì£¼ê°€ ì˜ˆì¸¡ íƒ­ì—ì„œ ì§„ì… íƒ€ì´ë° ë¶„ì„
                                    """)
                                elif score >= 2.5:
                                    st.info("""
                                    **ì¤‘ê°„ ê´€ì‹¬ë„ ëŒ€ì‘ ì „ëµ:**
                                    â€¢ ê²½ì œì§€í‘œ íƒ­ì—ì„œ ê±°ì‹œí™˜ê²½ ì ê²€
                                    â€¢ ìœ íŠœë¸Œ ë¶„ì„ íƒ­ì—ì„œ ì „ë¬¸ê°€ ì˜ê²¬ ìˆ˜ì§‘
                                    â€¢ ì„¹í„° íŠ¸ë¦¬ë§µì—ì„œ ì—…ì¢… ì „ì²´ ë™í–¥ í™•ì¸
                                    """)
                                else:
                                    st.warning("""
                                    **ë‚®ì€ ê´€ì‹¬ë„ ì£¼ì˜ì‚¬í•­:**
                                    â€¢ ì›Œë Œ ë²„í• ì¡°ì–¸ íƒ­ì—ì„œ ê°€ì¹˜ íˆ¬ì ê´€ì  í™•ì¸
                                    â€¢ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ íŠ¸ë Œë“œ ì¬ë¶„ì„
                                    â€¢ ì¥ê¸° íˆ¬ì ê´€ì ì—ì„œ ì ‘ê·¼ ê³ ë ¤
                                    """)
                        
                        else:
                            # GPT ë¶„ì„ì´ ì•„ì§ ì•ˆ ëœ ê²½ìš° - Formìœ¼ë¡œ ë¶„ì„ ì‹¤í–‰
                            with st.form("gpt_analysis_form", clear_on_submit=False):
                                st.info("ğŸ¤– AI ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„ì„ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                                
                                openai_api_key = st.text_input(
                                    "OpenAI API í‚¤",
                                    type="password",
                                    help="GPTë¥¼ ì´ìš©í•œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ íŠ¸ë Œë“œ ë¶„ì„"
                                )
                                
                                analyze_gpt = st.form_submit_button(
                                    "ğŸš€ AI ë¶„ì„ ì‹œì‘",
                                    type="primary",
                                    use_container_width=True
                                )
                                
                                if analyze_gpt:
                                    if not openai_api_key:
                                        st.error("âš ï¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                                    elif not openai_api_key.startswith('sk-'):
                                        st.error("âŒ ì˜¬ë°”ë¥¸ API í‚¤ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                                    else:
                                        try:
                                            with st.spinner('ğŸ¤– GPT ë¶„ì„ ì¤‘...'):
                                                gpt_analysis = GoogleTrendsAnalyzer.analyze_trends_with_gpt(
                                                    trends_data, openai_api_key
                                                )
                                            
                                            # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                                            st.session_state.gpt_trends_result = gpt_analysis
                                            
                                            st.success("âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì§€ ë§ˆì„¸ìš”.")
                                            st.rerun()  # ê²°ê³¼ë¥¼ ë°”ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•´ rerun
                                            
                                        except Exception as e:
                                            error_result = {"error": f"ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"}
                                            st.session_state.gpt_trends_result = error_result
                                            st.error(f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                            
                            # API í‚¤ ì—†ëŠ” ê²½ìš° ì•ˆë‚´
                            with st.expander('ğŸ”‘ GPT ë¶„ì„ ì—†ì´ë„ í™•ì¸ ê°€ëŠ¥í•œ ì •ë³´'):
                                st.info("""
                                **í˜„ì¬ í™•ì¸ ê°€ëŠ¥í•œ ë¶„ì„:**
                                â€¢ ğŸ“ˆ ì‹œê°„ë³„ íŠ¸ë Œë“œ íŒ¨í„´
                                â€¢ ğŸ“Š ìµœê·¼ ê´€ì‹¬ë„ ë³€í™”
                                â€¢ ğŸŒ ì§€ì—­ë³„ ê´€ì‹¬ ë¶„í¬
                                â€¢ ğŸ” ê´€ë ¨ ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ
                                
                                **GPT ë¶„ì„ ì¶”ê°€ í˜œíƒ:**
                                â€¢ íˆ¬ì ê´€ì  í•´ì„
                                â€¢ ì¢…í•© ì ìˆ˜ í‰ê°€
                                â€¢ ë‹¤ìŒ ë‹¨ê³„ ê°€ì´ë“œ
                                â€¢ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„
                                """)

        # ì‚¬ìš©ë²• ì•ˆë‚´
        with st.expander('ğŸ’¡ êµ¬ê¸€ íŠ¸ë Œë“œ ë¶„ì„ ì‚¬ìš©ë²•'):
            st.markdown("""
            **ğŸ” ê²€ìƒ‰ ë° ë¶„ì„**
            1. í‚¤ì›Œë“œ ì…ë ¥ (ì˜ì–´ ê¶Œì¥)
            2. ê¸°ê°„ ë° ì§€ì—­ ì„ íƒ
            3. "ğŸ“Š íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘" í´ë¦­
            4. ê²°ê³¼ í™•ì¸ í›„ GPT ë¶„ì„ ì„ íƒ
            
            **ğŸ’¡ íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ**
            - "AAPL stock" (ì¢…ëª©ì½”ë“œ + stock)
            - "Apple investment" (íšŒì‚¬ëª… + investment)
            - "Tesla earnings" (ì´ë²¤íŠ¸ ê´€ë ¨)
            
            **ğŸ“Š í•´ì„ ë°©ë²•**
            - ë†’ì€ ìˆ˜ì¹˜: í•´ë‹¹ ê¸°ê°„ ìµœê³  ê´€ì‹¬ë„
            - ìƒìŠ¹ íŠ¸ë Œë“œ: ê´€ì‹¬ë„ ì¦ê°€
            - ì§€ì—­ë³„ ì°¨ì´: ê¸€ë¡œë²Œ vs ë¡œì»¬ ê´€ì‹¬
            - ê´€ë ¨ ê²€ìƒ‰ì–´: ì¶”ê°€ ë¶„ì„ í¬ì¸íŠ¸
            
            **âš ï¸ ì£¼ì˜ì‚¬í•­**
            - ê²€ìƒ‰ëŸ‰ â‰  íˆ¬ì ìˆ˜ìµ
            - ë‹¤ë¥¸ ì§€í‘œì™€ í•¨ê»˜ ë¶„ì„
            - ê¸‰ì¦/ê¸‰ê° ì‹œ ì›ì¸ íŒŒì•… í•„ìš”
            """)
    
    # ì‚¬ì´ë“œë°” - ì¶”ê°€ ì •ë³´
    st.sidebar.markdown('---')
    st.sidebar.subheader('ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´')
    st.sidebar.markdown("""
    1. **ì¢…ëª© ì½”ë“œ ì…ë ¥**: ë¶„ì„í•˜ê³  ì‹¶ì€ ì¢…ëª© ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”
    2. **ì˜ˆì¸¡ ëª¨ë¸ ì„ íƒ**: Prophet ë˜ëŠ” ARIMA ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”
    3. **ê° íƒ­ í™•ì¸**: 
       - í™ˆ: ì„œë¹„ìŠ¤ ê°œìš”
       - ì„¹í„° íŠ¸ë¦¬ë§µ: ì‹¤ì‹œê°„ ì„¹í„°ë³„ ì‹œê°€ì´ì•¡ ì‹œê°í™”
       - ì£¼ê°€ ì˜ˆì¸¡: AI ëª¨ë¸ ê¸°ë°˜ ë¯¸ë˜ ì£¼ê°€ ì˜ˆì¸¡
       - ë‰´ìŠ¤ ë¶„ì„: ë‰´ìŠ¤ ê°ì„± ë¶„ì„
       - ì¬ë¬´ ê±´ì „ì„±: í˜„ì¬ ì¬ë¬´ìƒíƒœ + 3ê°œë…„ ì‹¤ì 
       - ê²½ì œì§€í‘œ: ê±°ì‹œê²½ì œ í™˜ê²½ ë¶„ì„
       - ë²„í• ì¡°ì–¸: ì¢…í•© íˆ¬ì íŒë‹¨
    4. **ì¢…í•© íŒë‹¨**: ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ íˆ¬ì ê²°ì •ì„ ë‚´ë¦¬ì„¸ìš”
    """)
    
    st.sidebar.markdown('---')
    st.sidebar.subheader('ğŸ†• ìƒˆë¡œ ì¶”ê°€ëœ ê¸°ëŠ¥')
    st.sidebar.markdown("""
    **ğŸ“Š ì„¹í„°ë³„ íŠ¸ë¦¬ë§µ**
    â€¢ S&P 500 ê¸°ë°˜ ì‹¤ì‹œê°„ ë°ì´í„°
    â€¢ ì‹œê°€ì´ì•¡ ìƒìœ„ 20ê°œ ì¢…ëª©
    â€¢ ì¼ì¼ ë³€ë™ë¥ ì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ
    â€¢ ì¸í„°ë™í‹°ë¸Œ í˜¸ë²„ ì •ë³´
    â€¢ ì„¹í„°ë³„ ì¢…í•© ë¹„êµ ì°¨íŠ¸
    
    **ğŸ¨ ì‹œê°í™” íŠ¹ì§•**
    â€¢ íŠ¸ë¦¬ë§µ í¬ê¸°: ì‹œê°€ì´ì•¡ ë¹„ë¡€
    â€¢ ìƒ‰ìƒ: ì¼ì¼ ë³€ë™ë¥  ê¸°ì¤€
    â€¢ í˜¸ë²„: ìƒì„¸ ì •ë³´ í‘œì‹œ
    â€¢ ë°˜ì‘í˜•: í´ë¦­ ë° í™•ëŒ€/ì¶•ì†Œ ê°€ëŠ¥
    """)
    
    st.sidebar.markdown('---')
    st.sidebar.subheader('ğŸ“Š ê¸°ì¡´ ê¸°ëŠ¥')
    st.sidebar.markdown("""
    **ğŸ“ˆ 3ê°œë…„ ì¬ë¬´ ì‹¤ì **
    â€¢ ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ ì¶”ì´
    â€¢ ì—°ë„ë³„ ì„±ì¥ íŒ¨í„´ ë¶„ì„
    â€¢ ìˆ˜ìµì„± ë³€í™” ì¶”ì 
    
    **ğŸŒ ëŒ€ì™¸ ê²½ì œì§€í‘œ**
    â€¢ ì£¼ìš” ì£¼ì‹ ì§€ìˆ˜ (S&P500, ë‚˜ìŠ¤ë‹¥, ë‹¤ìš°)
    â€¢ ë¯¸êµ­ êµ­ì±„ ìˆ˜ìµë¥  (2ë…„, 10ë…„)
    â€¢ ì›ìì¬ (ê¸ˆ, ì›ìœ )
    â€¢ ë‹¬ëŸ¬ ì¸ë±ìŠ¤, VIX ê³µí¬ì§€ìˆ˜
    """)
    
    st.sidebar.markdown('---')
    st.sidebar.subheader('ğŸ“Š ëª¨ë¸ ë¹„êµ')
    st.sidebar.markdown("""
    **Prophet**
    â€¢ Facebookì´ ê°œë°œí•œ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸
    â€¢ ê³„ì ˆì„±ê³¼ íŠ¸ë Œë“œë¥¼ ì˜ ê°ì§€
    â€¢ ë¹ ë¥¸ í•™ìŠµ ë° ì˜ˆì¸¡
    â€¢ ì ì€ ë°ì´í„°ë¡œë„ ì‘ë™
    
    **ARIMA**
    â€¢ ì „í†µì ì´ê³  ê²€ì¦ëœ í†µê³„ ëª¨ë¸
    â€¢ ìê¸°íšŒê·€í†µí•©ì´ë™í‰ê·  ëª¨ë¸
    â€¢ ì„ í˜• ê´€ê³„ì— ì í•©
    â€¢ ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
    """)
    
    st.sidebar.markdown('---')
    st.sidebar.subheader('âš ï¸ ë©´ì±… ê³ ì§€')
    st.sidebar.markdown("""
    - ë³¸ ë¶„ì„ì€ ì°¸ê³ ìš©ì´ë©° íˆ¬ì ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    - ëª¨ë“  íˆ¬ìëŠ” ë³¸ì¸ ì±…ì„ì…ë‹ˆë‹¤
    - ì¶©ë¶„í•œ ì¡°ì‚¬ í›„ íˆ¬ì ê²°ì •í•˜ì„¸ìš”
    - ë¶„ì‚° íˆ¬ìë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤
    """)
    
    # í‘¸í„°
    st.markdown('---')
    st.markdown(
        '<div style="text-align: center; color: gray; font-size: 0.8rem;">'
        'Â© 2025 ì„œí•™ê°œë¯¸ì˜ íˆ¬ì íƒêµ¬ìƒí™œ. ì›Œë Œ ë²„í•ì˜ íˆ¬ì ì² í•™ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ AI ë¶„ì„ í”Œë«í¼'
        '</div>',
        unsafe_allow_html=True
    )


if __name__ == '__main__':
    main()